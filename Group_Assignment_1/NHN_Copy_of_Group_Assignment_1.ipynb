{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee3cf149345246a4967ab032e77b1338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d272f2312fdf4eecb6aa27333bab2e17",
              "IPY_MODEL_72e1781a8d844330aedf16126f303bf9",
              "IPY_MODEL_4da4aad6a69948c9a879b19a06d3aeb1"
            ],
            "layout": "IPY_MODEL_f66ab6918e634489989b15daa35ced1f"
          }
        },
        "d272f2312fdf4eecb6aa27333bab2e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f786244ee1434e8370ddf800b727fb",
            "placeholder": "​",
            "style": "IPY_MODEL_69a20dc6564e4fef973e377b5975ce70",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "72e1781a8d844330aedf16126f303bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_243030bbf7bc4e9b9541aee948782338",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1b536eb5ef84a8285c16caf29bd2c97",
            "value": 1208
          }
        },
        "4da4aad6a69948c9a879b19a06d3aeb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1d2e114bed48b59115b266c49b67f7",
            "placeholder": "​",
            "style": "IPY_MODEL_1039405b95044ba2bd180434a17244b8",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 12.7kB/s]"
          }
        },
        "f66ab6918e634489989b15daa35ced1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f786244ee1434e8370ddf800b727fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a20dc6564e4fef973e377b5975ce70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "243030bbf7bc4e9b9541aee948782338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b536eb5ef84a8285c16caf29bd2c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac1d2e114bed48b59115b266c49b67f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1039405b95044ba2bd180434a17244b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5792f697166e429eb7ebcc9db9e8893f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9c937d52dcb47aa873891e69449625f",
              "IPY_MODEL_a739f6bd1e494f0b9f3560966ff87f9f",
              "IPY_MODEL_bc02930319a54b968af270c78b6d6da8"
            ],
            "layout": "IPY_MODEL_234e52c1b2104b509633b79f1ee87efa"
          }
        },
        "e9c937d52dcb47aa873891e69449625f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4f615d8b68409a96c96a1413a75950",
            "placeholder": "​",
            "style": "IPY_MODEL_9a09dd4448bf4e2f9fe1f511f99f3cc7",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "a739f6bd1e494f0b9f3560966ff87f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24677e910be74266aacf1cdbb08d0427",
            "max": 892146080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d3bf71dd9f44f1e97577de78a266462",
            "value": 892146080
          }
        },
        "bc02930319a54b968af270c78b6d6da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dc8aa45d73643c295ee23326b4823d2",
            "placeholder": "​",
            "style": "IPY_MODEL_cac9914ab48a40a1b18573488ffc0a67",
            "value": " 892M/892M [00:29&lt;00:00, 36.4MB/s]"
          }
        },
        "234e52c1b2104b509633b79f1ee87efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4f615d8b68409a96c96a1413a75950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a09dd4448bf4e2f9fe1f511f99f3cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24677e910be74266aacf1cdbb08d0427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3bf71dd9f44f1e97577de78a266462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dc8aa45d73643c295ee23326b4823d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac9914ab48a40a1b18573488ffc0a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8228171217894192882c1d8ed92231ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_291d05b3af1a42549111f7b52d34ce9d",
              "IPY_MODEL_4dad684348034fa080107d447719266b",
              "IPY_MODEL_08c5e7e149e741feac5df6959d1a27c6"
            ],
            "layout": "IPY_MODEL_e8c2788d0fac402c90094b7b38c86d2e"
          }
        },
        "291d05b3af1a42549111f7b52d34ce9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ec84da9ad4243f9a237e3237451d02f",
            "placeholder": "​",
            "style": "IPY_MODEL_9677940311764ab0b3297f0787702d84",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "4dad684348034fa080107d447719266b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d648e97624d451ab911df872617e4de",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58f1b825382f4fd99db6b0a40a914cac",
            "value": 147
          }
        },
        "08c5e7e149e741feac5df6959d1a27c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8206a5df8444e11a20763863d2f13b0",
            "placeholder": "​",
            "style": "IPY_MODEL_83074933adb546c99eebf8dc93703c02",
            "value": " 147/147 [00:00&lt;00:00, 6.95kB/s]"
          }
        },
        "e8c2788d0fac402c90094b7b38c86d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ec84da9ad4243f9a237e3237451d02f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9677940311764ab0b3297f0787702d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d648e97624d451ab911df872617e4de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f1b825382f4fd99db6b0a40a914cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8206a5df8444e11a20763863d2f13b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83074933adb546c99eebf8dc93703c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4eab168a3b64c0189d0a5a0ee426d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bfd0bd3bf964df2ae82f3ee91d10a57",
              "IPY_MODEL_e15cb8963a1f4e1b80818e221554d483",
              "IPY_MODEL_7f55865fc0504150b82d9ddc0baaf093"
            ],
            "layout": "IPY_MODEL_51e611a824ba4a9498407a85893e06a5"
          }
        },
        "9bfd0bd3bf964df2ae82f3ee91d10a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cd52caf84741b58d85f73ddf2a27d1",
            "placeholder": "​",
            "style": "IPY_MODEL_7aa8f32e5b124c8090b9117d72648792",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "e15cb8963a1f4e1b80818e221554d483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201eaabc3b5e488180484f8837755729",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46c9cc602d4a40588cd3363db0c827ba",
            "value": 791656
          }
        },
        "7f55865fc0504150b82d9ddc0baaf093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca147384f63349de9e90b00c9d70cc7b",
            "placeholder": "​",
            "style": "IPY_MODEL_74bd28beb6d8425a8bab15f9b40fd627",
            "value": " 792k/792k [00:00&lt;00:00, 7.83MB/s]"
          }
        },
        "51e611a824ba4a9498407a85893e06a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cd52caf84741b58d85f73ddf2a27d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa8f32e5b124c8090b9117d72648792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "201eaabc3b5e488180484f8837755729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c9cc602d4a40588cd3363db0c827ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca147384f63349de9e90b00c9d70cc7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74bd28beb6d8425a8bab15f9b40fd627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80adc81ab12f4e8090f0399a9ae4f16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2352cbb3815b4c5881ed2e2f7ae125d8",
              "IPY_MODEL_e7abbd679d054875971e254e208a31d1",
              "IPY_MODEL_caee6c85171e46d39438cd6902ec8b12"
            ],
            "layout": "IPY_MODEL_c4c1b6c9f3a942b4bf6be1a15372136b"
          }
        },
        "2352cbb3815b4c5881ed2e2f7ae125d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c5bcaa851b04668afac45618ce5f600",
            "placeholder": "​",
            "style": "IPY_MODEL_22a96b35e2264dfd88801a5c7f5c0de6",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "e7abbd679d054875971e254e208a31d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef003c33094c46b4a8dccae39c32069f",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf03d5ca1a3d4618b35d317c4dc6f13b",
            "value": 1389353
          }
        },
        "caee6c85171e46d39438cd6902ec8b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb5a90ce57c44cfa48240e7c99fad81",
            "placeholder": "​",
            "style": "IPY_MODEL_e4120e62d6a443ab9d46493efce2d8dc",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 12.1MB/s]"
          }
        },
        "c4c1b6c9f3a942b4bf6be1a15372136b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5bcaa851b04668afac45618ce5f600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a96b35e2264dfd88801a5c7f5c0de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef003c33094c46b4a8dccae39c32069f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf03d5ca1a3d4618b35d317c4dc6f13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cb5a90ce57c44cfa48240e7c99fad81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4120e62d6a443ab9d46493efce2d8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaHolmlund/M6_Group_Assignments/blob/main/Group_Assignment_1/NHN_Copy_of_Group_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "\n",
        "Develop a Proof-of-Concept version of an application that is querying a database to come provide an output to the user."
      ],
      "metadata": {
        "id": "F3ikmcc-cxcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be for example:\n",
        "- Selecting observations from database, performing prediction with a (beforehand fitted) SML model.\n",
        "- Perform a UML procedure on observations queried from a database.\n",
        "- Perform a semantic/similarity search for an user input, retrieve most similar docs from a database.\n",
        "\n",
        "The data used should be non-trivial (eg.: enough observations,´maybe multiple tables, different types of data…)\n",
        " - The solution has to be self-contained. This can be done:\n",
        " - Within a colab using for grad.io. (Hint: An option is to save the database on github, and then load it in the colab).)\n",
        " - As a streamlit app (figure out how to make it self-contained).\n",
        "… (sky is the limit.)\n",
        "\n",
        "Possible databases:\n",
        "- SQL DB (eg. SQL-lite)\n",
        "- NoSQL DB\n",
        " - Document (eg. tinyDB)\n",
        " - Vector (Eg. Faiss, Chroma)"
      ],
      "metadata": {
        "id": "WKpF6HMlttyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution\n",
        "\n",
        "In the following, we have created a SQLite database containing the 2.000 most cited documents on Scopus within the topic of Natural Language Processing.\n",
        "\n",
        "Subsequently, a summarization pipeline from HuggingFace has been applied to generate very brief summaries of document abstracts in order for users to quickkly get an overview of the contents of the document. This application is demonstrated in Grad.io."
      ],
      "metadata": {
        "id": "W1sJ5DUEdD9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a Pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv('https://raw.githubusercontent.com/NadiaHolmlund/M6_Group_Assignments/main/Group_Assignment_1/Scopus_NLP.csv')"
      ],
      "metadata": {
        "id": "CL4kda0PSoS4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "Vybb_EdiSxPP",
        "outputId": "9cd2076e-42bf-48e8-f1a3-e243977f1b71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Authors  \\\n",
              "0             Pennington J., Socher R., Manning C.D.   \n",
              "1       Devlin J., Chang M.-W., Lee K., Toutanova K.   \n",
              "2  Cho K., Van Merriënboer B., Gulcehre C., Bahda...   \n",
              "3                  Pang B., Lee L., Vaithyanathan S.   \n",
              "4  Collobert R., Weston J., Bottou L., Karlen M.,...   \n",
              "\n",
              "                                        Author(s) ID  \\\n",
              "0               22953926600;24766896100;35280197500;   \n",
              "1    54879967400;25925685700;56349980800;6506107920;   \n",
              "2  55722769200;57188495900;56006846900;5718843470...   \n",
              "3                  8644537200;7404389769;6603253116;   \n",
              "4  14064641400;8865128200;6701721644;25651854400;...   \n",
              "\n",
              "                                               Title  Year  \\\n",
              "0      GloVe: Global vectors for word representation  2014   \n",
              "1  BERT: Pre-training of deep bidirectional trans...  2019   \n",
              "2  Learning phrase representations using RNN enco...  2014   \n",
              "3  Thumbs up? Sentiment Classification using Mach...  2002   \n",
              "4  Natural language processing (almost) from scratch  2011   \n",
              "\n",
              "                                        Source title Volume Issue Art. No.  \\\n",
              "0  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "1  NAACL HLT 2019 - 2019 Conference of the North ...      1   NaN      NaN   \n",
              "2  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "3  Proceedings of the 2002 Conference on Empirica...    NaN   NaN      NaN   \n",
              "4               Journal of Machine Learning Research     12   NaN      NaN   \n",
              "\n",
              "  Page start Page end  ...           ISBN  CODEN PubMed ID  \\\n",
              "0       1532     1543  ...  9781937284961    NaN       NaN   \n",
              "1       4171     4186  ...  9781950737130    NaN       NaN   \n",
              "2       1724     1734  ...  9781937284961    NaN       NaN   \n",
              "3         79       86  ...            NaN    NaN       NaN   \n",
              "4       2493     2537  ...            NaN    NaN       NaN   \n",
              "\n",
              "  Language of Original Document  \\\n",
              "0                       English   \n",
              "1                       English   \n",
              "2                       English   \n",
              "3                       English   \n",
              "4                       English   \n",
              "\n",
              "                            Abbreviated Source Title     Document Type  \\\n",
              "0  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "1  NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...  Conference Paper   \n",
              "2  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "3  Proc. Conf. Empir. Methods Nat. Lang. Process....  Conference Paper   \n",
              "4                               J. Mach. Learn. Res.           Article   \n",
              "\n",
              "  Publication Stage             Open Access  Source                 EID  \n",
              "0             Final                     NaN  Scopus  2-s2.0-84961289992  \n",
              "1             Final                     NaN  Scopus  2-s2.0-85083815650  \n",
              "2             Final  All Open Access, Green  Scopus  2-s2.0-84961291190  \n",
              "3             Final                     NaN  Scopus  2-s2.0-85141803251  \n",
              "4             Final                     NaN  Scopus  2-s2.0-80053558787  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7d8df53-15dc-4ccb-b258-3917a4095afa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Authors</th>\n",
              "      <th>Author(s) ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Source title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Art. No.</th>\n",
              "      <th>Page start</th>\n",
              "      <th>Page end</th>\n",
              "      <th>...</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>CODEN</th>\n",
              "      <th>PubMed ID</th>\n",
              "      <th>Language of Original Document</th>\n",
              "      <th>Abbreviated Source Title</th>\n",
              "      <th>Document Type</th>\n",
              "      <th>Publication Stage</th>\n",
              "      <th>Open Access</th>\n",
              "      <th>Source</th>\n",
              "      <th>EID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pennington J., Socher R., Manning C.D.</td>\n",
              "      <td>22953926600;24766896100;35280197500;</td>\n",
              "      <td>GloVe: Global vectors for word representation</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1532</td>\n",
              "      <td>1543</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961289992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Devlin J., Chang M.-W., Lee K., Toutanova K.</td>\n",
              "      <td>54879967400;25925685700;56349980800;6506107920;</td>\n",
              "      <td>BERT: Pre-training of deep bidirectional trans...</td>\n",
              "      <td>2019</td>\n",
              "      <td>NAACL HLT 2019 - 2019 Conference of the North ...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4171</td>\n",
              "      <td>4186</td>\n",
              "      <td>...</td>\n",
              "      <td>9781950737130</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85083815650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cho K., Van Merriënboer B., Gulcehre C., Bahda...</td>\n",
              "      <td>55722769200;57188495900;56006846900;5718843470...</td>\n",
              "      <td>Learning phrase representations using RNN enco...</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1724</td>\n",
              "      <td>1734</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>All Open Access, Green</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961291190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pang B., Lee L., Vaithyanathan S.</td>\n",
              "      <td>8644537200;7404389769;6603253116;</td>\n",
              "      <td>Thumbs up? Sentiment Classification using Mach...</td>\n",
              "      <td>2002</td>\n",
              "      <td>Proceedings of the 2002 Conference on Empirica...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Proc. Conf. Empir. Methods Nat. Lang. Process....</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85141803251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Collobert R., Weston J., Bottou L., Karlen M.,...</td>\n",
              "      <td>14064641400;8865128200;6701721644;25651854400;...</td>\n",
              "      <td>Natural language processing (almost) from scratch</td>\n",
              "      <td>2011</td>\n",
              "      <td>Journal of Machine Learning Research</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2493</td>\n",
              "      <td>2537</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>J. Mach. Learn. Res.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-80053558787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7d8df53-15dc-4ccb-b258-3917a4095afa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7d8df53-15dc-4ccb-b258-3917a4095afa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7d8df53-15dc-4ccb-b258-3917a4095afa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.rename(columns=lambda x: x.replace(\" \", \"_\"), inplace=True)"
      ],
      "metadata": {
        "id": "ZOSNqVyQUMF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "r5cCJNl0W5f-",
        "outputId": "cb58a2c0-2e98-44e5-afdb-4fe097524068"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Authors  \\\n",
              "0             Pennington J., Socher R., Manning C.D.   \n",
              "1       Devlin J., Chang M.-W., Lee K., Toutanova K.   \n",
              "2  Cho K., Van Merriënboer B., Gulcehre C., Bahda...   \n",
              "3                  Pang B., Lee L., Vaithyanathan S.   \n",
              "4  Collobert R., Weston J., Bottou L., Karlen M.,...   \n",
              "\n",
              "                                        Author(s)_ID  \\\n",
              "0               22953926600;24766896100;35280197500;   \n",
              "1    54879967400;25925685700;56349980800;6506107920;   \n",
              "2  55722769200;57188495900;56006846900;5718843470...   \n",
              "3                  8644537200;7404389769;6603253116;   \n",
              "4  14064641400;8865128200;6701721644;25651854400;...   \n",
              "\n",
              "                                               Title  Year  \\\n",
              "0       GloVe Global vectors for word representation  2014   \n",
              "1  BERT Pretraining of deep bidirectional transfo...  2019   \n",
              "2  Learning phrase representations using RNN enco...  2014   \n",
              "3  Thumbs up Sentiment Classification using Machi...  2002   \n",
              "4    Natural language processing almost from scratch  2011   \n",
              "\n",
              "                                        Source_title Volume Issue Art._No.  \\\n",
              "0  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "1  NAACL HLT 2019 - 2019 Conference of the North ...      1   NaN      NaN   \n",
              "2  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "3  Proceedings of the 2002 Conference on Empirica...    NaN   NaN      NaN   \n",
              "4               Journal of Machine Learning Research     12   NaN      NaN   \n",
              "\n",
              "  Page_start Page_end  ...           ISBN  CODEN PubMed_ID  \\\n",
              "0       1532     1543  ...  9781937284961    NaN       NaN   \n",
              "1       4171     4186  ...  9781950737130    NaN       NaN   \n",
              "2       1724     1734  ...  9781937284961    NaN       NaN   \n",
              "3         79       86  ...            NaN    NaN       NaN   \n",
              "4       2493     2537  ...            NaN    NaN       NaN   \n",
              "\n",
              "  Language_of_Original_Document  \\\n",
              "0                       English   \n",
              "1                       English   \n",
              "2                       English   \n",
              "3                       English   \n",
              "4                       English   \n",
              "\n",
              "                            Abbreviated_Source_Title     Document_Type  \\\n",
              "0  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "1  NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...  Conference Paper   \n",
              "2  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "3  Proc. Conf. Empir. Methods Nat. Lang. Process....  Conference Paper   \n",
              "4                               J. Mach. Learn. Res.           Article   \n",
              "\n",
              "  Publication_Stage             Open_Access  Source                 EID  \n",
              "0             Final                     NaN  Scopus  2-s2.0-84961289992  \n",
              "1             Final                     NaN  Scopus  2-s2.0-85083815650  \n",
              "2             Final  All Open Access, Green  Scopus  2-s2.0-84961291190  \n",
              "3             Final                     NaN  Scopus  2-s2.0-85141803251  \n",
              "4             Final                     NaN  Scopus  2-s2.0-80053558787  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b2f8588-48a0-4461-ac07-825495f9208b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Authors</th>\n",
              "      <th>Author(s)_ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Source_title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Art._No.</th>\n",
              "      <th>Page_start</th>\n",
              "      <th>Page_end</th>\n",
              "      <th>...</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>CODEN</th>\n",
              "      <th>PubMed_ID</th>\n",
              "      <th>Language_of_Original_Document</th>\n",
              "      <th>Abbreviated_Source_Title</th>\n",
              "      <th>Document_Type</th>\n",
              "      <th>Publication_Stage</th>\n",
              "      <th>Open_Access</th>\n",
              "      <th>Source</th>\n",
              "      <th>EID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pennington J., Socher R., Manning C.D.</td>\n",
              "      <td>22953926600;24766896100;35280197500;</td>\n",
              "      <td>GloVe Global vectors for word representation</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1532</td>\n",
              "      <td>1543</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961289992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Devlin J., Chang M.-W., Lee K., Toutanova K.</td>\n",
              "      <td>54879967400;25925685700;56349980800;6506107920;</td>\n",
              "      <td>BERT Pretraining of deep bidirectional transfo...</td>\n",
              "      <td>2019</td>\n",
              "      <td>NAACL HLT 2019 - 2019 Conference of the North ...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4171</td>\n",
              "      <td>4186</td>\n",
              "      <td>...</td>\n",
              "      <td>9781950737130</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85083815650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cho K., Van Merriënboer B., Gulcehre C., Bahda...</td>\n",
              "      <td>55722769200;57188495900;56006846900;5718843470...</td>\n",
              "      <td>Learning phrase representations using RNN enco...</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1724</td>\n",
              "      <td>1734</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>All Open Access, Green</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961291190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pang B., Lee L., Vaithyanathan S.</td>\n",
              "      <td>8644537200;7404389769;6603253116;</td>\n",
              "      <td>Thumbs up Sentiment Classification using Machi...</td>\n",
              "      <td>2002</td>\n",
              "      <td>Proceedings of the 2002 Conference on Empirica...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Proc. Conf. Empir. Methods Nat. Lang. Process....</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85141803251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Collobert R., Weston J., Bottou L., Karlen M.,...</td>\n",
              "      <td>14064641400;8865128200;6701721644;25651854400;...</td>\n",
              "      <td>Natural language processing almost from scratch</td>\n",
              "      <td>2011</td>\n",
              "      <td>Journal of Machine Learning Research</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2493</td>\n",
              "      <td>2537</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>J. Mach. Learn. Res.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-80053558787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b2f8588-48a0-4461-ac07-825495f9208b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b2f8588-48a0-4461-ac07-825495f9208b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b2f8588-48a0-4461-ac07-825495f9208b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Creating a SQLite database\n",
        "In a new cell, create a new SQLite database and table to store the CSV data:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y7VmxnYzRwd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uph5Yq02QIk2"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# Add a column for the sentiment labels\n",
        "df_csv['summary'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Loading the CSV file into the SQLite table\n",
        "In a new cell, load the CSV file into the SQLite table:\n",
        "\n"
      ],
      "metadata": {
        "id": "aqCMZdRoTMt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DataFrame into the SQLite table\n",
        "df_csv.to_sql('data', conn, if_exists='append', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAsy2_rGSLja",
        "outputId": "f912ff59-1cb6-4b58-bd14-8e0114b54d39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Running SQL commands\n",
        "Now we'll run four main SQL commands: \n",
        "> - SELECT\n",
        "- INSERT \n",
        "- UPDATE\n",
        "- DELETE\n",
        "\n"
      ],
      "metadata": {
        "id": "6HHG6bwcYrnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select all records from the 'data' table\n",
        "select_query = \"SELECT * FROM data limit 5;\"\n",
        "cursor = conn.execute(select_query)\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "# Print the records\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7tEVYPcWoZr",
        "outputId": "0d720c8f-5188-450c-8a29-f42a238a8529"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Pennington J., Socher R., Manning C.D.', '22953926600;24766896100;35280197500;', 'GloVe Global vectors for word representation', 2014, 'EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference', None, None, None, '1532', '1543', None, 19507, '10.3115/v1/d14-1162', 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961289992&doi=10.3115%2fv1%2fd14-1162&partnerID=40&md5=53f2b22fdb7676d7ea744a3676c76cc8', 'Computer Science Department, Stanford University, Stanford, CA  94305, United States', 'Pennington, J., Computer Science Department, Stanford University, Stanford, CA  94305, United States; Socher, R., Computer Science Department, Stanford University, Stanford, CA  94305, United States; Manning, C.D., Computer Science Department, Stanford University, Stanford, CA  94305, United States', 'Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition. © 2014 Association for Computational Linguistics.', None, 'Factorization; Matrix algebra; Natural language processing systems; Regression analysis; Semantics; Vectors; Learning vectors; Model properties; Named entity recognition; Regression model; Sparse matrices; Statistical information; Word co-occurrence; Word representations; Vector spaces', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Apostol, T.M., (1976) Introduction to Analytic Number Theory, , Introduction to Analytic Number Theory; Baroni, M., Dinu, G., Kruszewski, G., (2014) Don't Count, Predict! A Systematic Comparison of Context-counting Vs. Context-predicting Semantic Vectors, , ACL; Bengio, Y., Learning deep architectures for AI (2009) Foundations and Trends in Machine Learning; Bengio, Y., Ducharme, R., Vincent, P., Janvin, C., A neural probabilistic language model (2003) JMLR, 3, pp. 1137-1155; Bullinaria, J.A., Levy, J.P., Extracting semantic representations from word cooccurrence statistics: A computational study (2007) Behavior Research Methods, 39 (3), pp. 510-526; Ciresan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J., Deep neural networks segment neuronal membranes in electron microscopy images (2012) NIPS, pp. 2852-2860; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of ICML, pp. 160-167; Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P., Natural language processing (Almost) from scratch (2011) JMLR, 12, pp. 2493-2537; Deerwester, S., Dumais, S.T., Furnas, G.W., Landauer, T.K., Harshman, R., Indexing by latent semantic analysis (1990) Journal of the American Society for Information Science, p. 41; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) JMLR, p. 12; Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., Ruppin, E., Placing search in context: The concept revisited (2001) Proceedings of the 10th International Conference on World Wide Web, pp. 406-414. , ACM; Huang, E.H., Socher, R., Manning, C.D., Ng, A.Y., (2012) Improving Word Representations via Global Context and Multiple Word Prototypes, , ACL; Lebret, R., Collobert, R., Word embeddings through hellinger PCA (2014) EACL; Levy, O., Goldberg, Y., Ramat-Gan, I., Linguistic regularities in sparse and explicit word representations (2014) CoNLL-2014; Lund, K., Burgess, C., Producing high-dimensional semantic spaces from lexical co-occurrence (1996) Behavior Research Methods, Instrumentation, and Computers, 28, pp. 203-208; Luong, M.-T., Socher, R., Manning, C.D., Better word representations with recursive neural networks for morphology (2013) CoNLL-2013; Mikolov, T., Chen, K., Corrado, G., Dean, J., Efficient estimation of word representations in vector space (2013) ICLR Workshop Papers; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., Distributed representations of words and phrases and their compositionality (2013) NIPS, pp. 3111-3119; Mikolov, T., Yih, W.T., Zweig, G., Linguistic regularities in continuous space word representations (2013) HLTNAACL; Miller, G.A., Charles, W.G., Contextual correlates of semantic similarity (1991) Language and Cognitive Processes, 6 (1), pp. 1-28; Mnih, A., Kavukcuoglu, K., Learning word embeddings efficiently with noise-contrastive estimation (2013) NIPS; Rohde, D.L.T., Gonnerman, L.M., Plaut, D.C., An improved model of semantic similarity based on lexical co-occurence (2006) Communications of the ACM, 8, pp. 627-633; Rubenstein, H., Goodenough, J.B., Contextual correlates of synonymy (1965) Communications of the ACM, 8 (10), pp. 627-633; Sebastiani, F., Machine learning in automated text categorization (2002) ACM Computing Surveys, 34, pp. 1-47; Socher, R., Bauer, J., Manning, C.D., Ng, A.Y., (2013) Parsing with Compositional Vector Grammars, , ACL; Tellex, S., Katz, B., Lin, J., Fernandes, A., Marton, G., Quantitative evaluation of passage retrieval algorithms for question answering (2003) Proceedings of the SIGIR Conference on Research and Development in Informaion Retrieval; Tjong, E.F., Sang, K., De Meulder, F., Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition (2003) CoNLL-2003; Turian, J., Ratinov, L., Bengio, Y., Word representations: A simple and general method for semi-supervised learning (2010) Proceedings of ACL, pp. 384-394; Wang, M., Manning, C.D., Effect of non-linear deep architecture in sequence labeling (2013) Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP)\", None, None, 'Carnegie Mellon University Qatar;Facebook;iHorizons;Qatar Computing Research Institute;Qatar National Research Fund (QNRF);Yandex', 'Association for Computational Linguistics (ACL)', '2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014', '25 October 2014 through 29 October 2014', None, 111414.0, None, '9781937284961', None, None, 'English', 'EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.', 'Conference Paper', 'Final', None, 'Scopus', '2-s2.0-84961289992', '')\n",
            "('Devlin J., Chang M.-W., Lee K., Toutanova K.', '54879967400;25925685700;56349980800;6506107920;', 'BERT Pretraining of deep bidirectional transformers for language understanding', 2019, 'NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference', '1', None, None, '4171', '4186', None, 19042, None, 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083815650&partnerID=40&md5=4986c6d6076c0c91df84d17216b47216', 'Google AI Language', 'Devlin, J., Google AI Language; Chang, M.-W., Google AI Language; Lee, K., Google AI Language; Toutanova, K., Google AI Language', 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement). © 2019 Association for Computational Linguistics', None, 'Computational linguistics; Language inference; Language understanding; NAtural language processing; Output layer; Pre-training; Question Answering; Representation model; State of the art; Natural language processing systems', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Akbik, A., Blythe, D., Vollgraf, R., Contextual string embeddings for sequence labeling (2018) Proceedings of the 27th International Conference on Computational Linguistics, pp. 1638-1649; Al-Rfou, R., Choe, D., Constant, N., Guo, M., Jones, L., (2018) Character-Level Language Modeling with Deeper Self-Attention; Ando, R.K., Zhang, T., A framework for learning predictive structures from multiple tasks and unlabeled data (2005) Journal of Machine Learning Research, 6, pp. 1817-1853. , Nov; Bentivogli, L., Magnini, B., Dagan, I., Dang, H.T., Giampiccolo, D., The fifth PASCAL recognizing textual entailment challenge (2009) TAC. NIST.; Blitzer, J., McDonald, R., Pereira, F., Domain adaptation with structural correspondence learning (2006) Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pp. 120-128. , Association for Computational Linguistics; Bowman, S.R., Angeli, G., Potts, C., Manning, C.D., A large annotated corpus for learning natural language inference (2015) EMNLP, , Association for Computational Linguistics; Brown, P.F., Desouza, P.V., Mercer, R.L., della Pietra, V.J., Lai, J.C., Class-based n-gram models of natural language (1992) Computational Linguistics, 18 (4), pp. 467-479; Cer, D., Diab, M., Agirre, E., Lopez-Gazpio, I., Specia, L., Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation (2017) Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), pp. 1-14. , Vancouver, Canada. Association for Computational Linguistics; Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., Koehn, P., Robinson, T., (2013) One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling; Chen, Z., Zhang, H., Zhang, X., Zhao, L., (2018) Quora Question Pairs; Clark, C., Gardner, M., Simple and effective multi-paragraph reading comprehension (2018) ACL; Clark, K., Luong, M.-T., Manning, C.D., Le, Q., Semi-supervised sequence modeling with cross-view training (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1914-1925; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 160-167; Conneau, A., Kiela, D., Schwenk, H., Barrault, L., Bordes, A., Supervised learning of universal sentence representations from natural language inference data (2017) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 670-680. , Copenhagen, Denmark. Association for Computational Linguistics; Dai, A.M., Le, Q.V., Semi-supervised sequence learning (2015) Advances in Neural Information Processing Systems, pp. 3079-3087; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR09; Dolan, W.B., Brockett, C., Automatically constructing a corpus of sentential paraphrases (2005) Proceedings of the Third International Workshop on Paraphrasing (IWP2005); Fedus, W., Goodfellow, I., Dai, A.M., (2018) Maskgan: Better Text Generation Via Filling in the; Hendrycks, D., Gimpel, K., (2016) Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units, , CoRR, abs/1606.08415; Hill, F., Cho, K., Korhonen, A., Learning distributed representations of sentences from unlabelled data (2016) Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, , Association for Computational Linguistics; Howard, J., Ruder, S., Universal language model fine-tuning for text classification (2018) ACL, , Association for Computational Linguistics; Hu, M., Peng, Y., Huang, Z., Qiu, X., Wei, F., Zhou, M., Reinforced mnemonic reader for machine reading comprehension (2018) IJCAI; Jernite, Y., Bowman, S.R., Sontag, D., (2017) Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning, , CoRR, abs/1705.00557; Joshi, M., Choi, E., Weld, D.S., Zettlemoyer, L., Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension (2017) ACL; Kiros, R., Zhu, Y., Salakhutdinov, R.R., Zemel, R., Urtasun, R., Torralba, A., Fidler, S., Skip-thought vectors (2015) Advances in Neural Information Processing Systems, pp. 3294-3302; Le, Q., Mikolov, T., Distributed representations of sentences and documents (2014) International Conference on Machine Learning, pp. 1188-1196; Levesque, H.J., Davis, E., Morgenstern, L., The winograd schema challenge (2011) Aaai Spring Symposium: Logical Formalizations of Commonsense Reasoning, 46, p. 47; Logeswaran, L., Lee, H., An efficient framework for learning sentence representations (2018) International Conference on Learning Representations; McCann, B., Bradbury, J., Xiong, C., Socher, R., Learned in translation: Contextualized word vectors (2017) NIPS; Melamud, O., Goldberger, J., Dagan, I., Context2Vec: Learning generic context embedding with bidirectional LSTM (2016) CoNLL; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, 26, pp. 3111-3119. , Curran Associates, Inc; Mnih, A., Hinton, G.E., A scalable hierarchical distributed language model (2009) Advances in Neural Information Processing Systems, 21, pp. 1081-1088. , D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Curran Associates, Inc; Parikh, A.P., Täckström, O., Das, D., Uszkoreit, J., A decomposable attention model for natural language inference (2016) EMNLP; Pennington, J., Socher, R., Manning, C.D., Glove: Global vectors for word representation (2014) Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543; Peters, M., Ammar, W., Bhagavatula, C., Power, R., Semi-supervised sequence tagging with bidirectional language models (2017) ACL; Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L., Deep contextualized word representations (2018) NAACL; Peters, M., Neumann, M., Zettlemoyer, L., Yih, W.-T., Dissecting contextual word embeddings: Architecture and representation (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1499-1509; Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., (2018) Improving Language Understanding with Unsupervised Learning, , Technical report, OpenAI; Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P., Squad: 100,000+ questions for machine comprehension of text (2016) Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 2383-2392; Seo, M., Kembhavi, A., Farhadi, A., Hajishirzi, H., Bidirectional attention flow for machine comprehension (2017) ICLR; Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.D., Ng, A., Potts, C., Recursive deep models for semantic compositionality over a sentiment tree-bank (2013) Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 1631-1642; Sun, F., Li, L., Qiu, X., Liu, Y., (2018) U-Net: Machine Reading Comprehension with Unanswerable Questions; Taylor, W.L., Cloze procedure: A new tool for measuring readability (1953) Journalism Bulletin, 30 (4), pp. 415-433; Tjong Kim Sang, E.F., de Meulder, F., Introduction to the conll-2003 shared task: Language-independent named entity recognition (2003) CoNLL; Turian, J., Ratinov, L., Bengio, Y., Word representations: A simple and general method for semi-supervised learning (2010) Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL'10, pp. 384-394; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) Advances in Neural Information Processing Systems, pp. 6000-6010; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 1096-1103; Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S., Glue: A multi-task benchmark and analysis platform for natural language understanding (2018) Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pp. 353-355; Wang, W., Yan, M., Wu, C., Multigranularity hierarchical attention fusion networks for reading comprehension and question answering (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), , Association for Computational Linguistics; Warstadt, A., Singh, A., Bowman, S.R., (2018) Neural Network Acceptability Judgments; Williams, A., Nangia, N., Bowman, S.R., A broad-coverage challenge corpus for sentence understanding through inference (2018) NAACL; Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., Macherey, K., (2016) Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Yu, A.W., Dohan, D., Luong, M.-T., Zhao, R., Chen, K., Norouzi, M., Le, Q.V., QaNet: Combining local convolution with global self-attention for reading comprehension (2018) ICLR; Zellers, R., Bisk, Y., Schwartz, R., Choi, Y., SWAG: A large-scale adversarial dataset for grounded commonsense inference (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP); Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., Fidler, S., Aligning books and movies: Towards story-like visual explanations by watching movies and reading books (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 19-27\", None, None, 'Amazon;ASAPP;Bloomberg Engineering;et al.;facebook;Google', 'Association for Computational Linguistics (ACL)', '2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019', '2 June 2019 through 7 June 2019', None, 159851.0, None, '9781950737130', None, None, 'English', 'NAACL HLT - Conf. N. Am. Chapter Assoc. Comput. Linguistics: Hum. Lang. Technol. - Proc. Conf.', 'Conference Paper', 'Final', None, 'Scopus', '2-s2.0-85083815650', '')\n",
            "('Cho K., Van Merriënboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y.', '55722769200;57188495900;56006846900;57188434700;42061073000;7005072756;7003958245;', 'Learning phrase representations using RNN encoderdecoder for statistical machine translation', 2014, 'EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference', None, None, None, '1724', '1734', None, 8169, '10.3115/v1/d14-1179', 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961291190&doi=10.3115%2fv1%2fd14-1179&partnerID=40&md5=c2352cbf63baff24b33f2291e0016bad', 'Université de Montréal, Canada; Jacobs University, Germany; Université du Maine, France', 'Cho, K., Université de Montréal, Canada; Van Merriënboer, B., Université de Montréal, Canada; Gulcehre, C., Université de Montréal, Canada; Bahdanau, D., Jacobs University, Germany; Bougares, F., Université du Maine, France; Schwenk, H., Université du Maine, France; Bengio, Y., Université de Montréal, Canada', 'In this paper, we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases. © 2014 Association for Computational Linguistics.', None, 'Computational linguistics; Decoding; Natural language processing systems; Recurrent neural networks; Regression analysis; Signal encoding; Conditional probabilities; Loglinear model; Novel neural network; Recurrent neural network (RNN); Statistical machine translation; Statistical machine translation system; Target sequences; Vector representations; Computer aided language translation', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Auli, M., Galley, M., Quirk, C., Zweig, G., Joint language and translation modeling with recurrent neural networks (2013) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1044-1054. , Auli et al.2013; Axelrod, A., He, X., Gao, J., Domain adaptation via pseudo in-domain data selection (2011) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 355-362. , Axelrod et al.2011; Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I.J., Bergeron, A., Bouchard, N., Bengio, Y., Theano: New features and speed improvements (2012) Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop, , Bastien et al.2012; Bengio, Y., Ducharme, R., Vincent, P., Janvin, C., A neural probabilistic language model (2003) J. Mach. Learn. Res., 3, pp. 1137-1155. , [Bengio et al.2003], ., March; Bengio, Y., Boulanger-Lewandowski, N., Pascanu, R., Advances in optimizing recurrent networks (2013) Proceedings of the 38th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2013), , [Bengio et al.2013], May; Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Bengio, Y., Theano: A CPU and GPU math expression compiler (2010) Proceedings of the Python for Scientific Computing Conference (SciPy), , [Bergstra et al.2010],June. Oral Presentation; Chandar, S., Lauly, S., Larochelle, H., Khapra, M., Ravindran, B., Raykar, V., Saha, A., (2014) An Autoencoder Approach to Learning Bilingual Word Representations, , [Chandar et al.2014], . arXiv:1402.1454 [cs.CL], February; Dahl, G.E., Yu, D., Deng, L., Acero, A., Context-dependent pretrained deep neural networks for large vocabulary speech recognition (2012) IEEE Transactions on Audio, Speech, and Language Processing, 20 (1), pp. 33-42. , Dahl et al.2012; Devlin, J., Zbib, R., Huang, Z., Lamar, T., Schwartz, R., Makhoul, J., Fast and robust neural network joint models for statistical machine translation (2014) Proceedings of the ACL 2014 Conference, ACL '14, pp. 1370-1380. , Devlin et al.2014; Gao, J., He, X., Tau Yih, W., Deng, L., Learning semantic representations for the phrase translation model (2013) Technical Report, Microsoft Research, , Gao et al.2013; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier neural networks (2011) AISTATS'2011, , Glorot et al.2011; Goodfellow, I.J., Warde-Farley, D., Mirza, M., Courville, A., Bengio, Y., Maxout networks (2013) ICML'2013, , Goodfellow et al.2013; Graves, A., Supervised sequence labelling with recurrent neural networks (2012) Studies in Computational Intelligence, , [Graves2012], . Springer; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780. , Hochreiter and Schmidhuber1997; Kalchbrenner, N., Blunsom, P., Two recurrent continuous translation models (2013) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1700-1709. , Kalchbrenner and Blunsom2013; Koehn, P., Josef Och, F., Marcu, D., Statistical phrase-based translation (2003) Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, NAACL '03, 1, pp. 48-54. , [Koehn et al.2003]; Koehn, P., Europarl: A parallel corpus for statistical machine translation (2005) Machine Translation Summit, 10, pp. 79-86. , [Koehn2005], .Phuket, Thailand; Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS'2012), 25. , Krizhevsky et al.2012; Marcu, D., Wong, W., A phrase-based, joint probability model for statistical machine translation (2002) Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing- EMNLP '02, 10, pp. 133-139. , [Marcu and Wong2002]; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, 26, pp. 3111-3119. , Mikolov et al.2013; Moore, R.C., Lewis, W., Intelligent selection of language model training data (2010) Proceedings of the ACL 2010 Conference Short Papers, ACLShort '10, pp. 220-224. , [Moore and Lewis2010], Stroudsburg, PA, USA; Pascanu, R., Gulcehre, C., Cho, K., Bengio, Y., How to construct deep recurrent neural networks (2014) Proceedings of the Second International Conference on Learning Representations (ICLR 2014), , [Pascanu et al.2014], April; Saxe, A.M., McClelland, J.L., Ganguli, S., Exact solutions to the nonlinear dynamics of learning in deep linear neural networks (2014) Proceedings of the Second International Conference on Learning Representations (ICLR 2014), , [Saxe et al.2014], ., April; Schwenk, H., Costa-Jussa, M.R., Fonollosa, J.A.R., Continuous space language models for the iwslt 2006 task (2006) IWSLT, pp. 166-173. , Schwenk et al.2006; Schwenk, H., Continuous space language models (2007) Comput. Speech Lang., 21 (3), pp. 492-518. , [Schwenk2007], July; Schwenk, H., Continuous space translation models for phrase-based statistical machine translation (2012) Proceedings of the 24th International Conference on Computational Linguistics (COLIN), pp. 1071-1080. , [Schwenk2012], . In Martin Kay and Christian Boitet, editors; Socher, R., Huang, E.H., Pennington, J., Ng, A.Y., Manning, C.D., Dynamic pooling and unfolding recursive autoencoders for paraphrase detection (2011) Advances in Neural Information Processing Systems, p. 24. , Socher et al.2011; Hai Son, L., Allauzen, A., Yvon, F., Continuous space translation models with neural networks (2012) Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT '12, pp. 39-48. , Son et al.2012], ., Stroudsburg, PA, USA; Van Der Maaten, L., Barnes-hut-sne (2013) Proceedings of the First International Conference on Learning Representations (ICLR 2013), , van der Maaten2013], ., May; Vaswani, A., Zhao, Y., Fossum, V., Chiang, D., Decoding with large-scale neural language models improves translation (2013) Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1387-1392. , Vaswani et al.2013; Zeiler, M.D., (2012) ADADELTA: An Adaptive Learning Rate Method, , [Zeiler2012], Technical report, arXiv 1212.5701; Zou, W.Y., Socher, R., Cer, D.M., Manning, C.D., Bilingual word embeddings for phrase-based machine translation (2013) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1393-1398. , Zou et al.2013\", None, None, 'Carnegie Mellon University Qatar;Facebook;iHorizons;Qatar Computing Research Institute;Qatar National Research Fund (QNRF);Yandex', 'Association for Computational Linguistics (ACL)', '2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014', '25 October 2014 through 29 October 2014', None, 111414.0, None, '9781937284961', None, None, 'English', 'EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.', 'Conference Paper', 'Final', 'All Open Access, Green', 'Scopus', '2-s2.0-84961291190', '')\n",
            "('Pang B., Lee L., Vaithyanathan S.', '8644537200;7404389769;6603253116;', 'Thumbs up Sentiment Classification using Machine Learning Techniques', 2002, 'Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, EMNLP 2002', None, None, None, '79', '86', None, 5835, None, 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141803251&partnerID=40&md5=2540bafede5003618f9b2d3bd685f49a', 'Department of Computer Science, Cornell University, Ithaca, NY  14853, United States; IBM Almaden Research Center, 650 Harry Rd., San Jose, CA  95120, United States', 'Pang, B., Department of Computer Science, Cornell University, Ithaca, NY  14853, United States; Lee, L., Department of Computer Science, Cornell University, Ithaca, NY  14853, United States; Vaithyanathan, S., IBM Almaden Research Center, 650 Harry Rd., San Jose, CA  95120, United States', 'We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging. © 2002 Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, EMNLP 2002. All rights reserved.', None, 'Learning algorithms; Maximum entropy methods; Natural language processing systems; Machine learning techniques; Maximum-entropy; Movie reviews; Naive bayes; Sentiment classification; Standard machines; Support vectors machine; Three machine learning methods; Support vector machines', None, None, None, None, 'National Science Foundation,\\xa0NSF: IIS-0081334', 'We thank Joshua Goodman, Thorsten Joachims, Jon Kleinberg, Vikas Krishna, John Lafferty, Jussi Myllymaki, Phoebe Sengers, Richard Tong, Peter Turney, and the anonymous reviewers for many valuable comments and helpful suggestions, and Hubie Chen and Tony Faradjian for participating in our baseline experiments. Portions of this work were done while the first author was visiting IBM Almaden. This paper is based upon work supported in part by the National Science Foundation under ITR/IM grant IIS-0081334. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation.', 'We thank Joshua Goodman, Thorsten Joachims, Jon Kleinberg, Vikas Krishna, John Lafferty, Jussi Myl-lymaki, Phoebe Sengers, Richard Tong, Peter Turney, and the anonymous reviewers for many valuable comments and helpful suggestions, and Hubie Chen and Tony Faradjian for participating in our baseline experiments. Portions of this work were done while the first author was visiting IBM Almaden. This paper is based upon work supported in part by the National Science Foundation under ITR/IM grant IIS-0081334. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation.', None, None, None, None, None, None, None, None, 'Argamon-Engelson, Shlomo, Koppel, Moshe, Avneri, Galit, Style-based text categorization: What newspaper am I reading? (1998) Proc. of the AAAI Workshop on Text Categorization, pp. 1-4; Berger, Adam L., Della Pietra, Stephen A., Della Pietra, Vincent J., A maximum entropy approach to natural language processing (1996) Computational Linguistics, 22 (1), pp. 39-71; Biber, Douglas, (1988) Variation across Speech and Writing, , Cambridge University Press; Chen, Stanley, Rosenfeld, Ronald, A survey of smoothing techniques for ME models (2000) IEEE Trans. Speech and Audio Processing, 8 (1), pp. 37-50; Das, Sanjiv, Chen, Mike, Yahoo! for Amazon: Extracting market sentiment from stock message boards (2001) Proc. of the 8th Asia Pacific Finance Association Annual Conference (APFA 2001); Pietra, Stephen Della, Pietra, Vincent Della, Lafferty, John, Inducing features of random fields (1997) IEEE Transactions on Pattern Analysis and Machine Intelligence, 19 (4), pp. 380-393; Domingos, Pedro, Pazzani, Michael J., On the optimality of the simple Bayesian classifier under zero-one loss (1997) Machine Learning, 29 (2-3), pp. 103-130; Finn, Aidan, Kushmerick, Nicholas, Smyth, Barry, Genre classification and domain transfer for information filtering (2002) Proc. of the European Colloquium on Information Retrieval Research, pp. 353-362. , Glasgow; Hatzivassiloglou, Vasileios, McKeown, Kathleen, Predicting the semantic orientation of adjectives (1997) Proc. of the 35th ACL/8th EACL, pp. 174-181; Hatzivassiloglou, Vasileios, Wiebe, Janyce, Effects of adjective orientation and gradability on sentence subjectivity (2000) Proc. of COLING.; Hearst, Marti, Direction-based text interpretation as an information access refinement (1992) Text-Based Intelligent Systems, , Paul Jacobs, editor, Lawrence Erlbaum Associates; Huettner, Alison, Subasic, Pero, Fuzzy typing for document management (2000) ACL 2000 Companion Volume: Tutorial Abstracts and Demonstration Notes, pp. 26-27; Joachims, Thorsten, Text categorization with support vector machines: Learning with many relevant features (1998) Proc. of the European Conference on Machine Learning (ECML), pp. 137-142; Joachims, Thorsten, Making large-scale SVM learning practical (1999) Advances in Kernel Methods - Support Vector Learning, pp. 44-56. , Bernhard Schölkopf and Alexander Smola, editors, pages MIT Press; Karlgren, Jussi, Cutting, Douglass, Recognizing text genres with simple metrics using discriminant analysis (1994) Proc. of COLING.; Kessler, Brett, Nunberg, Geoffrey, Schütze, Hinrich, Automatic detection of text genre (1997) Proc. of the 35th ACL/8th EACL, pp. 32-38; Lewis, David D., Naive (Bayes) at forty: The independence assumption in information retrieval (1998) Proc. of the European Conference on Machine Learning (ECML), pp. 4-15. , Invited talk; McCallum, Andrew, Nigam, Kamal, A comparison of event models for Naive Bayes text classification (1998) Proc. of the AAAI-98 Workshop on Learning for Text Categorization, pp. 41-48; Mosteller, Frederick, Wallace, David L., (1984) Applied Bayesian and Classical Inference: The Case of the Federalist Papers, , Springer-Verlag; Nigam, Kamal, Lafferty, John, McCallum, Andrew, Using maximum entropy for text classification (1999) Proc. of the IJCAI-99 Workshop on Machine Learning for Information Filtering, pp. 61-67; Pedersen, Ted, A decision tree of bigrams is an accurate predictor of word sense (2001) Proc. of the Second NAACL, pp. 79-86; Sack, Warren, On the computation of point of view (1994) Proc. of the Twelfth AAAI, p. 1488. , page Student abstract; Spertus, Ellen, Smokey: Automatic recognition of hostile messages (1997) Proc. of Innovative Applications of Artificial Intelligence (IAAI), pp. 1058-1065; Tatemura, Junichi, Virtual reviewers for collaborative exploration of movie reviews (2000) Proc. of the 5th International Conference on Intelligent User Interfaces, pp. 272-275; Terveen, Loren, Hill, Will, Amento, Brian, McDonald, David, Creter, Josh, PHOAKS: A system for sharing recommendations (1997) Communications of the ACM, 40 (3), pp. 59-62; Tomokiyo, Laura Mayfield, Jones, Rosie, You’re not from round here, are you? Naive Bayes detection of non-native utterance text (2001) Proc. of the Second NAACL, pp. 239-246; Tong, Richard M., An operational system for detecting and tracking opinions in on-line discussion (2001) Workshop note, SIGIR 2001 Workshop on Operational Text Classification; Turney, Peter D., Littman, Michael L., (2002) Unsupervised learning of semantic orientation from a hundred-billion-word corpus, , Technical Report EGB-1094, National Research Council Canada; Turney, Peter, Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews (2002) Proc. of the ACL.; Wiebe, Janyce M., Wilson, Theresa, Bell, Matthew, Identifying collocations for recognizing opinions (2001) Proc. of the ACL/EACL Workshop on Collocation; Wilks, Yorick, Stevenson, Mark, The grammar of sense: Using part-of-speech tags as a first step in semantic disambiguation (1998) Journal of Natural Language Engineering, 4 (2), pp. 135-144', None, None, None, 'Association for Computational Linguistics (ACL)', '7th Conference on Empirical Methods in Natural Language Processing, EMNLP 2002', '6 July 2002 through 7 July 2002', None, 185794.0, None, None, None, None, 'English', 'Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP', 'Conference Paper', 'Final', None, 'Scopus', '2-s2.0-85141803251', '')\n",
            "('Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P.', '14064641400;8865128200;6701721644;25651854400;25646533000;57221708009;', 'Natural language processing almost from scratch', 2011, 'Journal of Machine Learning Research', '12', None, None, '2493', '2537', None, 5302, None, 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053558787&partnerID=40&md5=1b7772fde7b09dee07bd4731149fb1c8', 'NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States; Idiap Research Institute, Switzerland; Google, New York, NY, United States; Microsoft, Redmond, WA, United States; New York University, New York, NY, United States; Rutgers University, New Brunswick, NJ, United States', 'Collobert, R., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Idiap Research Institute, Switzerland; Weston, J., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Google, New York, NY, United States; Bottou, L., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Microsoft, Redmond, WA, United States; Karlen, M., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States; Kavukcuoglu, K., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, New York University, New York, NY, United States; Kuksa, P., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Rutgers University, New Brunswick, NJ, United States', 'We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements. © 2011 Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu and Pavel Kuksa.', 'Natural language processing; Neural networks', 'Computational requirements; Input features; Internal representation; Named entity recognition; NAtural language processing; Part of speech tagging; Prior knowledge; Semantic role labeling; Tagging systems; Training data; Unified neural networks; Computational linguistics; Learning algorithms; Network architecture; Neural networks; Semantics; Speech recognition; Natural language processing systems', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Ando, R.K., Zhang, T., A framework for learning predictive structures from multiple tasks and unlabeled data (2005) Journal of Machine Learning Research (JMLR), 6, pp. 1817-1953; Bell, R.M., Koren, Y., Volinsky, C., The BellKor solution to the netflix prize (2007) Technical Report, , http://www.research.att.com/~volinsky/netflix, AT&T Labs; Bengio, Y., Ducharme, R., A neural probabilistic language model (2001) Advances in Neural Information Processing Systems (NIPS 13); Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) Advances in Neural Information Processing Systems (NIPS 19); Bengio, Y., Louradour, J., Collobert, R., Weston, J., Curriculum learning (2009) International Conference on Machine Learning (ICML); Bottou, L., Stochastic gradient learning in neural networks (1991) Proceedings of Neuro-Nîmes, EC2; Bottou, L., Online algorithms and stochastic approximations (1998) Online Learning and Neural Networks, , David Saad, editor, Cambridge University Press, Cambridge, UK; Bottou, L., Gallinari, P., A framework for the cooperation of learning algorithms (1991) Advances in Neural Information Processing Systems (NIPS 3); Bottou, L., Le Cun, Y., Bengio, Y., Global training of document processing systems using graph transformer networks (1997) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 489-493; Bridle, J.S., Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition (1990) Neurocomputing: Algorithms, Architectures and Applications, pp. 227-236. , F. Fogelman Soulié and J. Hérault, editors, NATO ASI Series; Brown, P.F., De Souza, P.V., Mercer, R.L., Pietra, V.J.D., Lai, J.C., Class-based n-gram models of natural language (1992) Computational Linguistics, 18 (4), pp. 467-479; Brown, P.F., Della Pietra, V.J., Mercer, R.L., Della Pietra, S.A., Lai, J.C., An estimate of an upper bound for the entropy of english (1992) Computational Linguistics, 18 (1), pp. 31-41; Burges, C.J.C., Ragno, R., Le, Q.V., Learning to rank with nonsmooth cost functions (2007) Advances in Neural Information Processing Systems (NIPS 19), pp. 193-200; Caruana, R., Multitask Learning (1997) Machine Learning, 28 (1), pp. 41-75; Chapelle, O., Schlkopf, B., Zien, A., Semi-supervised learning (2006) Adaptive Computation and Machine Learning, , MIT Press, Cambridge, Mass., USA, September; Charniak, E., A maximum-entropy-inspired parser (2000) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 132-139; Chieu, H.L., Named entity recognition with a maximum entropy approach (2003) Conference on Natural Language Learning (CoNLL), pp. 160-163; Chomsky, N., Three models for the description of language (1956) IRE Transactions on Information Theory, 2 (3), pp. 113-124. , September; Clémençon, S., Vayatis, N., Ranking the best instances (2007) Journal of Machine Learning Research (JMLR), 8, pp. 2671-2699; Cohen, W.W., Schapire, R.E., Singer, Y., Learning to order things (1999) Journal of Artificial Intelligence Research, 10, pp. 243-270; Cohn, T., Blunsom, P., Semantic role labelling with tree conditional random fields (2005) Conference on Computational Natural Language (CoNLL); Collins, M., (1999) Head-driven Statistical Models for Natural Language Parsing, , PhD thesis, University of Pennsylvania; Collobert, R., (2004) Large Scale Machine Learning, , PhD thesis, Université Paris VI; Collobert, R., Deep learning for efficient discriminative parsing (2011) International Conference on Artificial Intelligence and Statistics (AISTATS); Cover Thomas, M., King Roger, C., Convergent gambling estimate of the entropy of english (1978) IEEE Transactions on Information Theory, IT-24 (4), pp. 413-421; Florian, R., Ittycheriah, A., Jing, H., Zhang, T., Named entity recognition through classifier combination (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 168-171; Gildea, D., Jurafsky, D., Automatic labeling of semantic roles (2002) Computational Linguistics, 28 (3), pp. 245-288; Gildea, D., Palmer, M., The necessity of parsing for predicate argument recognition (2002) Meeting of the Association for Computational Linguistics (ACL), pp. 239-246; Giménez, J., Màrquez, L., SVMTool: A general POS tagger generator based on support vector machines (2004) Conference on Language Resources and Evaluation (LREC); Haghighi, A., Toutanova, K., Manning, C.D., A joint model for semantic role labeling (2005) Conference on Computational Natural Language Learning (CoNLL), , June; Harris, Z.S., (1968) Mathematical Structures of Language, , John Wiley & Sons Inc; Heckerman, D., Chickering, D.M., Meek, C., Rounthwaite, R., Kadie, C., Dependency networks for inference, collaborative filtering, and data visualization (2001) Journal of Machine Learning Research, 1 (1), pp. 49-75; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554. , http://www.mitpressjournals.org/doi/pdf/10.1162/neco.2006.18.7.1527, DOI 10.1162/neco.2006.18.7.1527; Hollingshead, K., Fisher, S., Roark, B., Comparing and combining finite-state and context-free parsers (2005) Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP), pp. 787-794; Huang, F., Yates, A., Distributional representations for handling sparsity in supervised sequencelabeling (2009) Meeting of the Association for Computational Linguistics (ACL), pp. 495-503; Jelinek, F., Continuous speech recognition by statistical methods (1976) Proceedings of the IEEE, 64 (4), pp. 532-556; Joachims, T., Transductive inference for text classification using support vector machines (1999) International Conference on Machine Learning (ICML); Klein, D., Manning, C.D., Natural language grammar induction using a constituent-context model (2002) Advances in Neural Information Processing Systems (NIPS 14), pp. 35-42; Koo, T., Carreras, X., Collins, M., Simple semi-supervised dependency parsing (2008) Meeting of the Association for Computational Linguistics (ACL), pp. 595-603; Koomen, P., Punyakanok, V., Roth, D., Yih, W., Generalized inference with multiple semantic role labeling systems (shared task paper) (2005) Conference on Computational Natural Language Learning (CoNLL), pp. 181-184; Kudo, T., Matsumoto, Y., Chunking with support vector machines (2001) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 1-8; Kudoh, T., Matsumoto, Y., Use of support vector learning for chunk identification (2000) Conference on Natural Language Learning (CoNLL) and Second Learning Language in Logic Workshop (LLL), pp. 142-144; Lafferty, J., McCallum, A., Pereira, F., Conditional random fields: Probabilistic models for segmenting and labeling sequence data (2001) International Conference on Machine Learning (ICML); Le Cun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient based learning applied to document recognition (1998) Proceedings of IEEE, 86 (11), pp. 2278-2324; Le Cun, Y., A learning scheme for asymmetric threshold networks (1985) Proceedings of Cognitiva, pp. 599-604. , Paris, France; LeCun, Y., Bottou, L., Orr, G.B., Mueller, K.-R., Efficient BackProp (1998) Lecture Notes in Computer Science, (1524), pp. 9-50. , Neural Networks: Tricks of the Trade; Lewis, D.D., Yang, Y., Rose, T.G., Li, F., Rcv1: A new benchmark collection for text categorization research (2004) Journal of Machine Learning Research (JMLR), 5, pp. 361-397; Liang, P., (2005) Semi-supervised Learning for Natural Language, , Master's thesis, Massachusetts Institute of Technology; Liang, P., Daumé III, H., Klein, D., Structure compilation: Trading structure for features (2008) International Conference on Machine Learning (ICML), pp. 592-599; Lin, D., Wu, X., Phrase clustering for discriminative learning (2009) Meeting of the Association for Computational Linguistics (ACL), pp. 1030-1038; Littlestone, N., Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm (1988) Machine Learning, pp. 285-318; McCallum, A., Li, W., Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 188-191; McClosky, D., Charniak, E., Johnson, M., Effective self-training for parsing (2006) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT); McDonald, R., Crammer, K., Pereira, F., Flexible text segmentation with structured multilabel classification (2005) Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP), pp. 987-994; Miller, S., Fox, H., Ramshaw, L., Weischedel, R., A novel use of statistical parsing to extract information from text (2000) Applied Natural Language Processing Conference (ANLP); Miller, S., Guinness, J., Zamanian, A., Name tagging with word clusters and discriminative training (2004) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 337-342; Mnih, A., Hinton, G.E., Three new graphical models for statistical language modelling (2007) International Conference on Machine Learning (ICML), pp. 641-648; Musillo, G., Merlo, P., Robust parsing of the proposition bank (2006) ROMAND 2006: Robust Methods in Analysis of Natural Language Data; Neal, R.M., (1996) Bayesian Learning for Neural Networks, , Number 118 in Lecture Notes in Statistics. Springer-Verlag, New York; Okanohara, D., Tsujii, J., A discriminative language model with pseudo-negative samples (2007) Meeting of the Association for Computational Linguistics (ACL), pp. 73-80; Palmer, M., Gildea, D., Kingsbury, P., The proposition bank: An annotated corpus of semantic roles (2005) Computational Linguistics, 31 (1), pp. 71-106; Pearl, J., (1988) Probabilistic Reasoning in Intelligent Systems, , Morgan Kaufman, San Mateo; Plaut, D.C., Hinton, G.E., Learning sets of filters using back-propagation (1987) Computer Speech and Language, 2, pp. 35-61; Porter, M.F., An algorithm for suffix stripping (1980) Program, 14 (3), pp. 130-137; Pradhan, S., Ward, W., Hacioglu, K., Martin, J., Jurafsky, D., Shallow semantic parsing using support vector machines (2004) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT); Pradhan, S., Hacioglu, K., Ward, W., Martin, J.H., Jurafsky, D., Semantic role chunking combining complementary syntactic views (2005) Conference on Computational Natural Language Learning (CoNLL), pp. 217-220; Punyakanok, V., Roth, D., Yih, W., The necessity of syntactic parsing for semantic role labeling (2005) International Joint Conference on Artificial Intelligence (IJCAI), pp. 1117-1123; Rabiner, L.R., A tutorial on hidden Markov models and selected applications in speech recognition (1989) Proceedings of the IEEE, 77 (2), pp. 257-286; Ratinov, L., Roth, D., Design challenges and misconceptions in named entity recognition (2009) Conference on Computational Natural Language Learning (CoNLL), pp. 147-155. , Association for Computational Linguistics; Ratnaparkhi, A., A maximum entropy model for part-of-speech tagging (1996) Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 133-142; Rosenfeld, B., Feldman, R., Using corpus statistics on entities to improve semi-supervised relation extraction from the web (2007) Meeting of the Association for Computational Linguistics (ACL), pp. 600-607; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning internal representations by backpropagating errors (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, 1, pp. 318-362. , D. E. Rumelhart and J. L. McClelland, editors, MIT Press; Schütze, H., Distributional part-of-speech tagging (1995) Meeting of the Association for Computational Linguistics (ACL), pp. 141-148; Schwenk, H., Gauvain, J.L., Connectionist language modeling for large vocabulary continuous speech recognition (2002) International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pp. 765-768; Sha, F., Pereira, F., Shallow parsing with conditional random fields (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 134-141; Shannon, C.E., Prediction and entropy of printed english (1951) Bell Systems Technical Journal, 30, pp. 50-64; Shen, H., Sarkar, A., Voting between multiple data representations for text chunking (2005) Advances in Artificial Intelligence, pp. 389-400; Shen, L., Satta, G., Joshi, A.K., Guided learning for bidirectional sequence classification (2007) Meeting of the Association for Computational Linguistics (ACL); Smith, N.A., Eisner, J., Contrastive estimation: Training log-linear models on unlabeled data (2005) Meeting of the Association for Computational Linguistics (ACL), pp. 354-362; Suddarth, S.C., Holden, A.D.C., Symbolic-neural systems and the use of hints for developing complex systems (1991) International Journal of Man-machine Studies, 35 (3), pp. 291-311; Sun, X., Morency, L.-P., Okanohara, D., Tsujii, J., Modeling latent-dynamic in shallow parsing: A latent conditional model with improved inference (2008) International Conference on Computational Linguistics (COLING), pp. 841-848; Sutton, C., McCallum, A., Joint parsing and semantic role labeling (2005) Conference on Computational Natural Language (CoNLL), pp. 225-228; Sutton, C., McCallum, A., Composition of conditional random fields for transfer learning (2005) Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP), pp. 748-754; Sutton, C., McCallum, A., Rohanimanesh, K., Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data (2007) Journal of Machine Learning Research, 8, pp. 693-723. , http://jmlr.csail.mit.edu/papers/volume8/sutton07a/sutton07a.pdf; Suzuki, J., Isozaki, H., Semi-supervised sequential labeling and segmentation using giga-word scale unlabeled data (2008) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 665-673; Teahan, W.J., Cleary, J.G., The entropy of english using ppm-based models (1996) Data Compression Conference (DCC), pp. 53-62. , IEEE Computer Society Press; Toutanova, K., Klein, D., Manning, C.D., Singer, Y., Feature-rich part-of-speech tagging with a cyclic dependency network (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT); Turian, J., Ratinov, L., Bengio, Y., Word representations: A simple and general method for semisupervised learning (2010) Meeting of the Association for Computational Linguistics (ACL), pp. 384-392; Ueffing, N., Haffari, G., Sarkar, A., Transductive learning for statistical machine translation (2007) Meeting of the Association for Computational Linguistics (ACL), pp. 25-32; Waibel, A., Hanazawa, T., Hinton, G., Shikano, K., Lang, K.J., Phoneme recognition using time-delay neural networks (1989) IEEE Transactions on Acoustics, Speech, and Signal Processing, 37 (3), pp. 328-339. , DOI 10.1109/29.21701; Weston, J., Ratle, F., Collobert, R., Deep learning via semi-supervised embedding (2008) International Conference on Machine Learning (ICML), pp. 1168-1175\", 'Collobert, R.; NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States; email: RONAN@COLLOBERT.COM', None, None, None, None, None, None, None, '15324435', None, None, None, 'English', 'J. Mach. Learn. Res.', 'Article', 'Final', None, 'Scopus', '2-s2.0-80053558787', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hands on project for using SQLite in ML"
      ],
      "metadata": {
        "id": "0falMMadvxTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a tutorial on how to use the transformers library in Python to perform sentiment analysis on movie reviews stored in a SQLite database"
      ],
      "metadata": {
        "id": "Cduaz-mksuwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymaDKz8isvqo",
        "outputId": "c1254782-9e10-4f73-ce45-58fbb10ef7ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Load the sentiment analysis model"
      ],
      "metadata": {
        "id": "QzTwOJgxx3V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the pre-trained text-summarization model\n",
        "summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "ee3cf149345246a4967ab032e77b1338",
            "d272f2312fdf4eecb6aa27333bab2e17",
            "72e1781a8d844330aedf16126f303bf9",
            "4da4aad6a69948c9a879b19a06d3aeb1",
            "f66ab6918e634489989b15daa35ced1f",
            "93f786244ee1434e8370ddf800b727fb",
            "69a20dc6564e4fef973e377b5975ce70",
            "243030bbf7bc4e9b9541aee948782338",
            "e1b536eb5ef84a8285c16caf29bd2c97",
            "ac1d2e114bed48b59115b266c49b67f7",
            "1039405b95044ba2bd180434a17244b8",
            "5792f697166e429eb7ebcc9db9e8893f",
            "e9c937d52dcb47aa873891e69449625f",
            "a739f6bd1e494f0b9f3560966ff87f9f",
            "bc02930319a54b968af270c78b6d6da8",
            "234e52c1b2104b509633b79f1ee87efa",
            "9d4f615d8b68409a96c96a1413a75950",
            "9a09dd4448bf4e2f9fe1f511f99f3cc7",
            "24677e910be74266aacf1cdbb08d0427",
            "1d3bf71dd9f44f1e97577de78a266462",
            "4dc8aa45d73643c295ee23326b4823d2",
            "cac9914ab48a40a1b18573488ffc0a67",
            "8228171217894192882c1d8ed92231ca",
            "291d05b3af1a42549111f7b52d34ce9d",
            "4dad684348034fa080107d447719266b",
            "08c5e7e149e741feac5df6959d1a27c6",
            "e8c2788d0fac402c90094b7b38c86d2e",
            "4ec84da9ad4243f9a237e3237451d02f",
            "9677940311764ab0b3297f0787702d84",
            "0d648e97624d451ab911df872617e4de",
            "58f1b825382f4fd99db6b0a40a914cac",
            "a8206a5df8444e11a20763863d2f13b0",
            "83074933adb546c99eebf8dc93703c02",
            "d4eab168a3b64c0189d0a5a0ee426d9a",
            "9bfd0bd3bf964df2ae82f3ee91d10a57",
            "e15cb8963a1f4e1b80818e221554d483",
            "7f55865fc0504150b82d9ddc0baaf093",
            "51e611a824ba4a9498407a85893e06a5",
            "c8cd52caf84741b58d85f73ddf2a27d1",
            "7aa8f32e5b124c8090b9117d72648792",
            "201eaabc3b5e488180484f8837755729",
            "46c9cc602d4a40588cd3363db0c827ba",
            "ca147384f63349de9e90b00c9d70cc7b",
            "74bd28beb6d8425a8bab15f9b40fd627",
            "80adc81ab12f4e8090f0399a9ae4f16c",
            "2352cbb3815b4c5881ed2e2f7ae125d8",
            "e7abbd679d054875971e254e208a31d1",
            "caee6c85171e46d39438cd6902ec8b12",
            "c4c1b6c9f3a942b4bf6be1a15372136b",
            "9c5bcaa851b04668afac45618ce5f600",
            "22a96b35e2264dfd88801a5c7f5c0de6",
            "ef003c33094c46b4a8dccae39c32069f",
            "cf03d5ca1a3d4618b35d317c4dc6f13b",
            "6cb5a90ce57c44cfa48240e7c99fad81",
            "e4120e62d6a443ab9d46493efce2d8dc"
          ]
        },
        "id": "x7XjnDCrsuLV",
        "outputId": "3c345c22-0750-4447-efa2-911eae39b616"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee3cf149345246a4967ab032e77b1338"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5792f697166e429eb7ebcc9db9e8893f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8228171217894192882c1d8ed92231ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4eab168a3b64c0189d0a5a0ee426d9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80adc81ab12f4e8090f0399a9ae4f16c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Extract text for movie reviews\n",
        "Next, we need to extract the movie reviews from our SQLite database and analyze their sentiment using the classifier pipeline."
      ],
      "metadata": {
        "id": "bU_GleUGx7rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract sentiment reviews for the movie reviews\n",
        "abstracts = conn.execute('SELECT Abstract FROM data limit 10')"
      ],
      "metadata": {
        "id": "4unW87qFx8EV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have extracted the movie reviews, we can iterate over them using a for loop and use the classifier pipeline to analyze their sentiment. We will also update the reviews table in our database with the sentiment label."
      ],
      "metadata": {
        "id": "2z_Cm2ryypnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the movie reviews and update the summary for each one\n",
        "for i, row in enumerate(abstracts):\n",
        "    # Extract the text of the current review\n",
        "    abstract = row[0]\n",
        "    \n",
        "    # Summarize the review using the pre-trained summarizer\n",
        "    summary = summarizer(abstract, max_length=30, min_length=0, do_sample=False)[0]['summary_text']\n",
        "    \n",
        "    # Update the 'summary' column in the 'reviews' table with the summary for the current review\n",
        "    conn.execute('UPDATE data SET summary = ? WHERE rowid = ?', (summary, i+1))\n",
        "    \n",
        "# Commit the changes to the database\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "Fomc32lTs6Wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0995ee8-bc4b-4821-f017-742f84f46768"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/tf_utils.py:745: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('max_colwidth', 1000)\n",
        "pd.describe_option('max_colwidth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckM81pViNxHY",
        "outputId": "8b627b7b-c7d1-4979-b680-51efad09cb42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "display.max_colwidth : int or None\n",
            "    The maximum width in characters of a column in the repr of\n",
            "    a pandas data structure. When the column overflows, a \"...\"\n",
            "    placeholder is embedded in the output. A 'None' value means unlimited.\n",
            "    [default: 50] [currently: 1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SQL query\n",
        "query = 'SELECT * FROM data LIMIT 10'\n",
        "\n",
        "# Execute the query and convert the result to a DataFrame\n",
        "df_q = pd.read_sql_query(query, conn)"
      ],
      "metadata": {
        "id": "BRz3jMbYvO_I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_q['Abstract'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "N6XefZQkTVRY",
        "outputId": "e150ee78-8cc0-471d-953c-0c1eb1b07173"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition. © 2014 Association for Computational Linguistics.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_q['summary'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "VXi3QRNoTWx9",
        "outputId": "45f85e68-b211-4ad1-e1d6-f6f013e6d309"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a new global logbilinear regression model is developed . it combines the advantages of global matrix factorization and local context window methods'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Clean up\n",
        "\n",
        "In a new cell, close the database connection:"
      ],
      "metadata": {
        "id": "8u-uo-BqdclO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "wziYz9SD9i8J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad.io"
      ],
      "metadata": {
        "id": "njQND0oKdqaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --q\n",
        "!pip install transformers --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1btrqTVSgb0P",
        "outputId": "eeb0cfb9-1002-4f0b-bae6-7901dcff543a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import gradio as gr\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "EzlEHkiyhJ0d"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a summary of titles available in our Scopus Database"
      ],
      "metadata": {
        "id": "Y3U0MZTfkGJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST"
      ],
      "metadata": {
        "id": "avnM1Yj2s8ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import sqlite3\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# Define the dropdown options\n",
        "c = conn.cursor()\n",
        "c.execute(\"SELECT DISTINCT Title FROM data\")\n",
        "dropdown_options = [row[0] for row in c.fetchall()]\n",
        "\n",
        "def summary(selected_option):\n",
        "    c.execute(\"SELECT summary FROM data WHERE Title = ?\", (selected_option,))\n",
        "    summary = c.fetchone()[0]\n",
        "    return summary\n",
        "\n",
        "# Create the Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=summary,\n",
        "    inputs=gr.inputs.Dropdown(choices=dropdown_options, label=\"Select a Title from Scopus\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Generated Summary\"),\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "Lf7tG_fWsszP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import sqlite3\n",
        "\n",
        "summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# Define the dropdown options\n",
        "c = conn.cursor()\n",
        "c.execute(\"SELECT DISTINCT Title FROM data\")\n",
        "dropdown_options = [row[0] for row in c.fetchall()]\n",
        "\n",
        "def summary(selected_option):\n",
        "    c.execute(\"SELECT Abstract FROM data WHERE Title = ?\", (selected_option,))\n",
        "    abstract = c.fetchone()[0]\n",
        "    summary = summarizer(abstract, max_length=30, min_length=0, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "# Create the Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=summary,\n",
        "    inputs=gr.inputs.Dropdown(choices=dropdown_options, label=\"Select a Title from Scopus\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Generated Summary\"),\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "TOY9CjHuf1tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a summary of your own abstract/abstracts not available in our Scopus Database"
      ],
      "metadata": {
        "id": "3tpT500aj7-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
        "\n",
        "def summary(abstract):\n",
        "    summary = summarizer(abstract, max_length=30, min_length=0, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "examples = [\n",
        "    [\"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition. © 2014 Association for Computational Linguistics.\"],\n",
        "    [\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement). © 2019 Association for Computational Linguistics\"],\n",
        "    [\"In this paper, we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases. © 2014 Association for Computational Linguistics.\"],\n",
        "]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=summary,\n",
        "    inputs=gr.inputs.Textbox(lines=5, label=\"Input Abstract\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Generated Summary\"),\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "jrm4fFSdgVbE",
        "outputId": "260f3e00-41df-434c-b8a3-a87f7ea0a2e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ih4Y-2K2v3Yo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}