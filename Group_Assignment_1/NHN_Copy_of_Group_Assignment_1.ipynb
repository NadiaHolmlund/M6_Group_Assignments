{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaHolmlund/M6_Group_Assignments/blob/main/Group_Assignment_1/NHN_Copy_of_Group_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ikmcc-cxcv"
      },
      "source": [
        "# Task\n",
        "\n",
        "Develop a Proof-of-Concept version of an application that is querying a database to come provide an output to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKpF6HMlttyC"
      },
      "source": [
        "This can be for example:\n",
        "- Selecting observations from database, performing prediction with a (beforehand fitted) SML model.\n",
        "- Perform a UML procedure on observations queried from a database.\n",
        "- Perform a semantic/similarity search for an user input, retrieve most similar docs from a database.\n",
        "\n",
        "The data used should be non-trivial (eg.: enough observations,´maybe multiple tables, different types of data…)\n",
        " - The solution has to be self-contained. This can be done:\n",
        " - Within a colab using for grad.io. (Hint: An option is to save the database on github, and then load it in the colab).)\n",
        " - As a streamlit app (figure out how to make it self-contained).\n",
        "… (sky is the limit.)\n",
        "\n",
        "Possible databases:\n",
        "- SQL DB (eg. SQL-lite)\n",
        "- NoSQL DB\n",
        " - Document (eg. tinyDB)\n",
        " - Vector (Eg. Faiss, Chroma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1sJ5DUEdD9q"
      },
      "source": [
        "# Solution\n",
        "\n",
        "In the following, we have created a SQLite database containing the 2.000 most cited documents on Scopus within the topic of Natural Language Processing.\n",
        "\n",
        "Subsequently, a summarization pipeline from HuggingFace has been applied to generate very brief summaries of document abstracts in order for users to quickkly get an overview of the contents of the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcoEbKypQYWC"
      },
      "source": [
        "In this part, we will learn:\n",
        "> 1. How to load a CSV file into a SQLite database \n",
        "> 2. How to run four main SQL commands\n",
        "> 3. Utilizing this database for machine learning projects\n",
        "\n",
        "We will be using Python and the SQLite module to perform this task. Finally, we will create an exercise in Google Colab to practice the concepts learned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CL4kda0PSoS4"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file into a Pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv('https://raw.githubusercontent.com/NadiaHolmlund/M6_Group_Assignments/main/Group_Assignment_1/Scopus_NLP.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "Vybb_EdiSxPP",
        "outputId": "71f735b5-5923-400d-b02f-5ed93c22d521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Authors  \\\n",
              "0             Pennington J., Socher R., Manning C.D.   \n",
              "1       Devlin J., Chang M.-W., Lee K., Toutanova K.   \n",
              "2  Cho K., Van Merriënboer B., Gulcehre C., Bahda...   \n",
              "3                  Pang B., Lee L., Vaithyanathan S.   \n",
              "4  Collobert R., Weston J., Bottou L., Karlen M.,...   \n",
              "\n",
              "                                        Author(s) ID  \\\n",
              "0               22953926600;24766896100;35280197500;   \n",
              "1    54879967400;25925685700;56349980800;6506107920;   \n",
              "2  55722769200;57188495900;56006846900;5718843470...   \n",
              "3                  8644537200;7404389769;6603253116;   \n",
              "4  14064641400;8865128200;6701721644;25651854400;...   \n",
              "\n",
              "                                               Title  Year  \\\n",
              "0      GloVe: Global vectors for word representation  2014   \n",
              "1  BERT: Pre-training of deep bidirectional trans...  2019   \n",
              "2  Learning phrase representations using RNN enco...  2014   \n",
              "3  Thumbs up? Sentiment Classification using Mach...  2002   \n",
              "4  Natural language processing (almost) from scratch  2011   \n",
              "\n",
              "                                        Source title Volume Issue Art. No.  \\\n",
              "0  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "1  NAACL HLT 2019 - 2019 Conference of the North ...      1   NaN      NaN   \n",
              "2  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "3  Proceedings of the 2002 Conference on Empirica...    NaN   NaN      NaN   \n",
              "4               Journal of Machine Learning Research     12   NaN      NaN   \n",
              "\n",
              "  Page start Page end  ...           ISBN  CODEN PubMed ID  \\\n",
              "0       1532     1543  ...  9781937284961    NaN       NaN   \n",
              "1       4171     4186  ...  9781950737130    NaN       NaN   \n",
              "2       1724     1734  ...  9781937284961    NaN       NaN   \n",
              "3         79       86  ...            NaN    NaN       NaN   \n",
              "4       2493     2537  ...            NaN    NaN       NaN   \n",
              "\n",
              "  Language of Original Document  \\\n",
              "0                       English   \n",
              "1                       English   \n",
              "2                       English   \n",
              "3                       English   \n",
              "4                       English   \n",
              "\n",
              "                            Abbreviated Source Title     Document Type  \\\n",
              "0  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "1  NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...  Conference Paper   \n",
              "2  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "3  Proc. Conf. Empir. Methods Nat. Lang. Process....  Conference Paper   \n",
              "4                               J. Mach. Learn. Res.           Article   \n",
              "\n",
              "  Publication Stage             Open Access  Source                 EID  \n",
              "0             Final                     NaN  Scopus  2-s2.0-84961289992  \n",
              "1             Final                     NaN  Scopus  2-s2.0-85083815650  \n",
              "2             Final  All Open Access, Green  Scopus  2-s2.0-84961291190  \n",
              "3             Final                     NaN  Scopus  2-s2.0-85141803251  \n",
              "4             Final                     NaN  Scopus  2-s2.0-80053558787  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f511aa3-e0ed-4fa5-9745-fc4be0cce4bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Authors</th>\n",
              "      <th>Author(s) ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Source title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Art. No.</th>\n",
              "      <th>Page start</th>\n",
              "      <th>Page end</th>\n",
              "      <th>...</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>CODEN</th>\n",
              "      <th>PubMed ID</th>\n",
              "      <th>Language of Original Document</th>\n",
              "      <th>Abbreviated Source Title</th>\n",
              "      <th>Document Type</th>\n",
              "      <th>Publication Stage</th>\n",
              "      <th>Open Access</th>\n",
              "      <th>Source</th>\n",
              "      <th>EID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pennington J., Socher R., Manning C.D.</td>\n",
              "      <td>22953926600;24766896100;35280197500;</td>\n",
              "      <td>GloVe: Global vectors for word representation</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1532</td>\n",
              "      <td>1543</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961289992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Devlin J., Chang M.-W., Lee K., Toutanova K.</td>\n",
              "      <td>54879967400;25925685700;56349980800;6506107920;</td>\n",
              "      <td>BERT: Pre-training of deep bidirectional trans...</td>\n",
              "      <td>2019</td>\n",
              "      <td>NAACL HLT 2019 - 2019 Conference of the North ...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4171</td>\n",
              "      <td>4186</td>\n",
              "      <td>...</td>\n",
              "      <td>9781950737130</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85083815650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cho K., Van Merriënboer B., Gulcehre C., Bahda...</td>\n",
              "      <td>55722769200;57188495900;56006846900;5718843470...</td>\n",
              "      <td>Learning phrase representations using RNN enco...</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1724</td>\n",
              "      <td>1734</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>All Open Access, Green</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961291190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pang B., Lee L., Vaithyanathan S.</td>\n",
              "      <td>8644537200;7404389769;6603253116;</td>\n",
              "      <td>Thumbs up? Sentiment Classification using Mach...</td>\n",
              "      <td>2002</td>\n",
              "      <td>Proceedings of the 2002 Conference on Empirica...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Proc. Conf. Empir. Methods Nat. Lang. Process....</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85141803251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Collobert R., Weston J., Bottou L., Karlen M.,...</td>\n",
              "      <td>14064641400;8865128200;6701721644;25651854400;...</td>\n",
              "      <td>Natural language processing (almost) from scratch</td>\n",
              "      <td>2011</td>\n",
              "      <td>Journal of Machine Learning Research</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2493</td>\n",
              "      <td>2537</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>J. Mach. Learn. Res.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-80053558787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f511aa3-e0ed-4fa5-9745-fc4be0cce4bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f511aa3-e0ed-4fa5-9745-fc4be0cce4bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f511aa3-e0ed-4fa5-9745-fc4be0cce4bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZOSNqVyQUMF8"
      },
      "outputs": [],
      "source": [
        "df_csv.rename(columns=lambda x: x.replace(\" \", \"_\"), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K3ZurPFRqhdz"
      },
      "outputs": [],
      "source": [
        "# Replace special characters in the Title column\n",
        "df_csv['Title'] = df_csv['Title'].replace('[:\\(\\)\\?\\-]', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "r5cCJNl0W5f-",
        "outputId": "0781b850-24e7-43bf-f577-7ca849c22fbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Authors  \\\n",
              "0             Pennington J., Socher R., Manning C.D.   \n",
              "1       Devlin J., Chang M.-W., Lee K., Toutanova K.   \n",
              "2  Cho K., Van Merriënboer B., Gulcehre C., Bahda...   \n",
              "3                  Pang B., Lee L., Vaithyanathan S.   \n",
              "4  Collobert R., Weston J., Bottou L., Karlen M.,...   \n",
              "\n",
              "                                        Author(s)_ID  \\\n",
              "0               22953926600;24766896100;35280197500;   \n",
              "1    54879967400;25925685700;56349980800;6506107920;   \n",
              "2  55722769200;57188495900;56006846900;5718843470...   \n",
              "3                  8644537200;7404389769;6603253116;   \n",
              "4  14064641400;8865128200;6701721644;25651854400;...   \n",
              "\n",
              "                                               Title  Year  \\\n",
              "0       GloVe Global vectors for word representation  2014   \n",
              "1  BERT Pretraining of deep bidirectional transfo...  2019   \n",
              "2  Learning phrase representations using RNN enco...  2014   \n",
              "3  Thumbs up Sentiment Classification using Machi...  2002   \n",
              "4    Natural language processing almost from scratch  2011   \n",
              "\n",
              "                                        Source_title Volume Issue Art._No.  \\\n",
              "0  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "1  NAACL HLT 2019 - 2019 Conference of the North ...      1   NaN      NaN   \n",
              "2  EMNLP 2014 - 2014 Conference on Empirical Meth...    NaN   NaN      NaN   \n",
              "3  Proceedings of the 2002 Conference on Empirica...    NaN   NaN      NaN   \n",
              "4               Journal of Machine Learning Research     12   NaN      NaN   \n",
              "\n",
              "  Page_start Page_end  ...           ISBN  CODEN PubMed_ID  \\\n",
              "0       1532     1543  ...  9781937284961    NaN       NaN   \n",
              "1       4171     4186  ...  9781950737130    NaN       NaN   \n",
              "2       1724     1734  ...  9781937284961    NaN       NaN   \n",
              "3         79       86  ...            NaN    NaN       NaN   \n",
              "4       2493     2537  ...            NaN    NaN       NaN   \n",
              "\n",
              "  Language_of_Original_Document  \\\n",
              "0                       English   \n",
              "1                       English   \n",
              "2                       English   \n",
              "3                       English   \n",
              "4                       English   \n",
              "\n",
              "                            Abbreviated_Source_Title     Document_Type  \\\n",
              "0  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "1  NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...  Conference Paper   \n",
              "2  EMNLP - Conf. Empir. Methods Nat. Lang. Proces...  Conference Paper   \n",
              "3  Proc. Conf. Empir. Methods Nat. Lang. Process....  Conference Paper   \n",
              "4                               J. Mach. Learn. Res.           Article   \n",
              "\n",
              "  Publication_Stage             Open_Access  Source                 EID  \n",
              "0             Final                     NaN  Scopus  2-s2.0-84961289992  \n",
              "1             Final                     NaN  Scopus  2-s2.0-85083815650  \n",
              "2             Final  All Open Access, Green  Scopus  2-s2.0-84961291190  \n",
              "3             Final                     NaN  Scopus  2-s2.0-85141803251  \n",
              "4             Final                     NaN  Scopus  2-s2.0-80053558787  \n",
              "\n",
              "[5 rows x 54 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23581ed1-9a08-4ab8-a6df-f2e3546ed5f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Authors</th>\n",
              "      <th>Author(s)_ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Source_title</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Art._No.</th>\n",
              "      <th>Page_start</th>\n",
              "      <th>Page_end</th>\n",
              "      <th>...</th>\n",
              "      <th>ISBN</th>\n",
              "      <th>CODEN</th>\n",
              "      <th>PubMed_ID</th>\n",
              "      <th>Language_of_Original_Document</th>\n",
              "      <th>Abbreviated_Source_Title</th>\n",
              "      <th>Document_Type</th>\n",
              "      <th>Publication_Stage</th>\n",
              "      <th>Open_Access</th>\n",
              "      <th>Source</th>\n",
              "      <th>EID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pennington J., Socher R., Manning C.D.</td>\n",
              "      <td>22953926600;24766896100;35280197500;</td>\n",
              "      <td>GloVe Global vectors for word representation</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1532</td>\n",
              "      <td>1543</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961289992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Devlin J., Chang M.-W., Lee K., Toutanova K.</td>\n",
              "      <td>54879967400;25925685700;56349980800;6506107920;</td>\n",
              "      <td>BERT Pretraining of deep bidirectional transfo...</td>\n",
              "      <td>2019</td>\n",
              "      <td>NAACL HLT 2019 - 2019 Conference of the North ...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4171</td>\n",
              "      <td>4186</td>\n",
              "      <td>...</td>\n",
              "      <td>9781950737130</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>NAACL HLT - Conf. N. Am. Chapter Assoc. Comput...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85083815650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cho K., Van Merriënboer B., Gulcehre C., Bahda...</td>\n",
              "      <td>55722769200;57188495900;56006846900;5718843470...</td>\n",
              "      <td>Learning phrase representations using RNN enco...</td>\n",
              "      <td>2014</td>\n",
              "      <td>EMNLP 2014 - 2014 Conference on Empirical Meth...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1724</td>\n",
              "      <td>1734</td>\n",
              "      <td>...</td>\n",
              "      <td>9781937284961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>EMNLP - Conf. Empir. Methods Nat. Lang. Proces...</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>All Open Access, Green</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-84961291190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pang B., Lee L., Vaithyanathan S.</td>\n",
              "      <td>8644537200;7404389769;6603253116;</td>\n",
              "      <td>Thumbs up Sentiment Classification using Machi...</td>\n",
              "      <td>2002</td>\n",
              "      <td>Proceedings of the 2002 Conference on Empirica...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>Proc. Conf. Empir. Methods Nat. Lang. Process....</td>\n",
              "      <td>Conference Paper</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-85141803251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Collobert R., Weston J., Bottou L., Karlen M.,...</td>\n",
              "      <td>14064641400;8865128200;6701721644;25651854400;...</td>\n",
              "      <td>Natural language processing almost from scratch</td>\n",
              "      <td>2011</td>\n",
              "      <td>Journal of Machine Learning Research</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2493</td>\n",
              "      <td>2537</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>J. Mach. Learn. Res.</td>\n",
              "      <td>Article</td>\n",
              "      <td>Final</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scopus</td>\n",
              "      <td>2-s2.0-80053558787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23581ed1-9a08-4ab8-a6df-f2e3546ed5f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23581ed1-9a08-4ab8-a6df-f2e3546ed5f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23581ed1-9a08-4ab8-a6df-f2e3546ed5f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_csv.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7VmxnYzRwd7"
      },
      "source": [
        "### Step 1: Creating a SQLite database\n",
        "In a new cell, create a new SQLite database and table to store the CSV data:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uph5Yq02QIk2"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# Add a column for the sentiment labels\n",
        "df_csv['summary'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqCMZdRoTMt0"
      },
      "source": [
        "### Step 2: Loading the CSV file into the SQLite table\n",
        "In a new cell, load the CSV file into the SQLite table:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAsy2_rGSLja",
        "outputId": "47ffd8ed-82d6-4e2b-82a3-0bdaf68acf90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Load the DataFrame into the SQLite table\n",
        "df_csv.to_sql('data', conn, if_exists='append', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HHG6bwcYrnW"
      },
      "source": [
        "###Step 3: Running SQL commands\n",
        "Now we'll run four main SQL commands: \n",
        "> - SELECT\n",
        "- INSERT \n",
        "- UPDATE\n",
        "- DELETE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7tEVYPcWoZr",
        "outputId": "3f4b03d4-1b1e-444e-8217-6778cf43139f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Pennington J., Socher R., Manning C.D.', '22953926600;24766896100;35280197500;', 'GloVe Global vectors for word representation', 2014, 'EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference', None, None, None, '1532', '1543', None, 19507, '10.3115/v1/d14-1162', 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961289992&doi=10.3115%2fv1%2fd14-1162&partnerID=40&md5=53f2b22fdb7676d7ea744a3676c76cc8', 'Computer Science Department, Stanford University, Stanford, CA  94305, United States', 'Pennington, J., Computer Science Department, Stanford University, Stanford, CA  94305, United States; Socher, R., Computer Science Department, Stanford University, Stanford, CA  94305, United States; Manning, C.D., Computer Science Department, Stanford University, Stanford, CA  94305, United States', 'Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition. © 2014 Association for Computational Linguistics.', None, 'Factorization; Matrix algebra; Natural language processing systems; Regression analysis; Semantics; Vectors; Learning vectors; Model properties; Named entity recognition; Regression model; Sparse matrices; Statistical information; Word co-occurrence; Word representations; Vector spaces', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Apostol, T.M., (1976) Introduction to Analytic Number Theory, , Introduction to Analytic Number Theory; Baroni, M., Dinu, G., Kruszewski, G., (2014) Don't Count, Predict! A Systematic Comparison of Context-counting Vs. Context-predicting Semantic Vectors, , ACL; Bengio, Y., Learning deep architectures for AI (2009) Foundations and Trends in Machine Learning; Bengio, Y., Ducharme, R., Vincent, P., Janvin, C., A neural probabilistic language model (2003) JMLR, 3, pp. 1137-1155; Bullinaria, J.A., Levy, J.P., Extracting semantic representations from word cooccurrence statistics: A computational study (2007) Behavior Research Methods, 39 (3), pp. 510-526; Ciresan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J., Deep neural networks segment neuronal membranes in electron microscopy images (2012) NIPS, pp. 2852-2860; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of ICML, pp. 160-167; Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P., Natural language processing (Almost) from scratch (2011) JMLR, 12, pp. 2493-2537; Deerwester, S., Dumais, S.T., Furnas, G.W., Landauer, T.K., Harshman, R., Indexing by latent semantic analysis (1990) Journal of the American Society for Information Science, p. 41; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) JMLR, p. 12; Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., Ruppin, E., Placing search in context: The concept revisited (2001) Proceedings of the 10th International Conference on World Wide Web, pp. 406-414. , ACM; Huang, E.H., Socher, R., Manning, C.D., Ng, A.Y., (2012) Improving Word Representations via Global Context and Multiple Word Prototypes, , ACL; Lebret, R., Collobert, R., Word embeddings through hellinger PCA (2014) EACL; Levy, O., Goldberg, Y., Ramat-Gan, I., Linguistic regularities in sparse and explicit word representations (2014) CoNLL-2014; Lund, K., Burgess, C., Producing high-dimensional semantic spaces from lexical co-occurrence (1996) Behavior Research Methods, Instrumentation, and Computers, 28, pp. 203-208; Luong, M.-T., Socher, R., Manning, C.D., Better word representations with recursive neural networks for morphology (2013) CoNLL-2013; Mikolov, T., Chen, K., Corrado, G., Dean, J., Efficient estimation of word representations in vector space (2013) ICLR Workshop Papers; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., Distributed representations of words and phrases and their compositionality (2013) NIPS, pp. 3111-3119; Mikolov, T., Yih, W.T., Zweig, G., Linguistic regularities in continuous space word representations (2013) HLTNAACL; Miller, G.A., Charles, W.G., Contextual correlates of semantic similarity (1991) Language and Cognitive Processes, 6 (1), pp. 1-28; Mnih, A., Kavukcuoglu, K., Learning word embeddings efficiently with noise-contrastive estimation (2013) NIPS; Rohde, D.L.T., Gonnerman, L.M., Plaut, D.C., An improved model of semantic similarity based on lexical co-occurence (2006) Communications of the ACM, 8, pp. 627-633; Rubenstein, H., Goodenough, J.B., Contextual correlates of synonymy (1965) Communications of the ACM, 8 (10), pp. 627-633; Sebastiani, F., Machine learning in automated text categorization (2002) ACM Computing Surveys, 34, pp. 1-47; Socher, R., Bauer, J., Manning, C.D., Ng, A.Y., (2013) Parsing with Compositional Vector Grammars, , ACL; Tellex, S., Katz, B., Lin, J., Fernandes, A., Marton, G., Quantitative evaluation of passage retrieval algorithms for question answering (2003) Proceedings of the SIGIR Conference on Research and Development in Informaion Retrieval; Tjong, E.F., Sang, K., De Meulder, F., Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition (2003) CoNLL-2003; Turian, J., Ratinov, L., Bengio, Y., Word representations: A simple and general method for semi-supervised learning (2010) Proceedings of ACL, pp. 384-394; Wang, M., Manning, C.D., Effect of non-linear deep architecture in sequence labeling (2013) Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP)\", None, None, 'Carnegie Mellon University Qatar;Facebook;iHorizons;Qatar Computing Research Institute;Qatar National Research Fund (QNRF);Yandex', 'Association for Computational Linguistics (ACL)', '2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014', '25 October 2014 through 29 October 2014', None, 111414.0, None, '9781937284961', None, None, 'English', 'EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.', 'Conference Paper', 'Final', None, 'Scopus', '2-s2.0-84961289992', '')\n",
            "('Devlin J., Chang M.-W., Lee K., Toutanova K.', '54879967400;25925685700;56349980800;6506107920;', 'BERT Pretraining of deep bidirectional transformers for language understanding', 2019, 'NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference', '1', None, None, '4171', '4186', None, 19042, None, 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083815650&partnerID=40&md5=4986c6d6076c0c91df84d17216b47216', 'Google AI Language', 'Devlin, J., Google AI Language; Chang, M.-W., Google AI Language; Lee, K., Google AI Language; Toutanova, K., Google AI Language', 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement). © 2019 Association for Computational Linguistics', None, 'Computational linguistics; Language inference; Language understanding; NAtural language processing; Output layer; Pre-training; Question Answering; Representation model; State of the art; Natural language processing systems', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Akbik, A., Blythe, D., Vollgraf, R., Contextual string embeddings for sequence labeling (2018) Proceedings of the 27th International Conference on Computational Linguistics, pp. 1638-1649; Al-Rfou, R., Choe, D., Constant, N., Guo, M., Jones, L., (2018) Character-Level Language Modeling with Deeper Self-Attention; Ando, R.K., Zhang, T., A framework for learning predictive structures from multiple tasks and unlabeled data (2005) Journal of Machine Learning Research, 6, pp. 1817-1853. , Nov; Bentivogli, L., Magnini, B., Dagan, I., Dang, H.T., Giampiccolo, D., The fifth PASCAL recognizing textual entailment challenge (2009) TAC. NIST.; Blitzer, J., McDonald, R., Pereira, F., Domain adaptation with structural correspondence learning (2006) Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pp. 120-128. , Association for Computational Linguistics; Bowman, S.R., Angeli, G., Potts, C., Manning, C.D., A large annotated corpus for learning natural language inference (2015) EMNLP, , Association for Computational Linguistics; Brown, P.F., Desouza, P.V., Mercer, R.L., della Pietra, V.J., Lai, J.C., Class-based n-gram models of natural language (1992) Computational Linguistics, 18 (4), pp. 467-479; Cer, D., Diab, M., Agirre, E., Lopez-Gazpio, I., Specia, L., Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation (2017) Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), pp. 1-14. , Vancouver, Canada. Association for Computational Linguistics; Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., Koehn, P., Robinson, T., (2013) One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling; Chen, Z., Zhang, H., Zhang, X., Zhao, L., (2018) Quora Question Pairs; Clark, C., Gardner, M., Simple and effective multi-paragraph reading comprehension (2018) ACL; Clark, K., Luong, M.-T., Manning, C.D., Le, Q., Semi-supervised sequence modeling with cross-view training (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1914-1925; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 160-167; Conneau, A., Kiela, D., Schwenk, H., Barrault, L., Bordes, A., Supervised learning of universal sentence representations from natural language inference data (2017) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 670-680. , Copenhagen, Denmark. Association for Computational Linguistics; Dai, A.M., Le, Q.V., Semi-supervised sequence learning (2015) Advances in Neural Information Processing Systems, pp. 3079-3087; Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L., ImageNet: A large-scale hierarchical image database (2009) CVPR09; Dolan, W.B., Brockett, C., Automatically constructing a corpus of sentential paraphrases (2005) Proceedings of the Third International Workshop on Paraphrasing (IWP2005); Fedus, W., Goodfellow, I., Dai, A.M., (2018) Maskgan: Better Text Generation Via Filling in the; Hendrycks, D., Gimpel, K., (2016) Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units, , CoRR, abs/1606.08415; Hill, F., Cho, K., Korhonen, A., Learning distributed representations of sentences from unlabelled data (2016) Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, , Association for Computational Linguistics; Howard, J., Ruder, S., Universal language model fine-tuning for text classification (2018) ACL, , Association for Computational Linguistics; Hu, M., Peng, Y., Huang, Z., Qiu, X., Wei, F., Zhou, M., Reinforced mnemonic reader for machine reading comprehension (2018) IJCAI; Jernite, Y., Bowman, S.R., Sontag, D., (2017) Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning, , CoRR, abs/1705.00557; Joshi, M., Choi, E., Weld, D.S., Zettlemoyer, L., Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension (2017) ACL; Kiros, R., Zhu, Y., Salakhutdinov, R.R., Zemel, R., Urtasun, R., Torralba, A., Fidler, S., Skip-thought vectors (2015) Advances in Neural Information Processing Systems, pp. 3294-3302; Le, Q., Mikolov, T., Distributed representations of sentences and documents (2014) International Conference on Machine Learning, pp. 1188-1196; Levesque, H.J., Davis, E., Morgenstern, L., The winograd schema challenge (2011) Aaai Spring Symposium: Logical Formalizations of Commonsense Reasoning, 46, p. 47; Logeswaran, L., Lee, H., An efficient framework for learning sentence representations (2018) International Conference on Learning Representations; McCann, B., Bradbury, J., Xiong, C., Socher, R., Learned in translation: Contextualized word vectors (2017) NIPS; Melamud, O., Goldberger, J., Dagan, I., Context2Vec: Learning generic context embedding with bidirectional LSTM (2016) CoNLL; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, 26, pp. 3111-3119. , Curran Associates, Inc; Mnih, A., Hinton, G.E., A scalable hierarchical distributed language model (2009) Advances in Neural Information Processing Systems, 21, pp. 1081-1088. , D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Curran Associates, Inc; Parikh, A.P., Täckström, O., Das, D., Uszkoreit, J., A decomposable attention model for natural language inference (2016) EMNLP; Pennington, J., Socher, R., Manning, C.D., Glove: Global vectors for word representation (2014) Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543; Peters, M., Ammar, W., Bhagavatula, C., Power, R., Semi-supervised sequence tagging with bidirectional language models (2017) ACL; Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L., Deep contextualized word representations (2018) NAACL; Peters, M., Neumann, M., Zettlemoyer, L., Yih, W.-T., Dissecting contextual word embeddings: Architecture and representation (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1499-1509; Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., (2018) Improving Language Understanding with Unsupervised Learning, , Technical report, OpenAI; Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P., Squad: 100,000+ questions for machine comprehension of text (2016) Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 2383-2392; Seo, M., Kembhavi, A., Farhadi, A., Hajishirzi, H., Bidirectional attention flow for machine comprehension (2017) ICLR; Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.D., Ng, A., Potts, C., Recursive deep models for semantic compositionality over a sentiment tree-bank (2013) Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pp. 1631-1642; Sun, F., Li, L., Qiu, X., Liu, Y., (2018) U-Net: Machine Reading Comprehension with Unanswerable Questions; Taylor, W.L., Cloze procedure: A new tool for measuring readability (1953) Journalism Bulletin, 30 (4), pp. 415-433; Tjong Kim Sang, E.F., de Meulder, F., Introduction to the conll-2003 shared task: Language-independent named entity recognition (2003) CoNLL; Turian, J., Ratinov, L., Bengio, Y., Word representations: A simple and general method for semi-supervised learning (2010) Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL'10, pp. 384-394; Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., Attention is all you need (2017) Advances in Neural Information Processing Systems, pp. 6000-6010; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 1096-1103; Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S., Glue: A multi-task benchmark and analysis platform for natural language understanding (2018) Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pp. 353-355; Wang, W., Yan, M., Wu, C., Multigranularity hierarchical attention fusion networks for reading comprehension and question answering (2018) Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), , Association for Computational Linguistics; Warstadt, A., Singh, A., Bowman, S.R., (2018) Neural Network Acceptability Judgments; Williams, A., Nangia, N., Bowman, S.R., A broad-coverage challenge corpus for sentence understanding through inference (2018) NAACL; Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., Macherey, K., (2016) Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation; Yosinski, J., Clune, J., Bengio, Y., Lipson, H., How transferable are features in deep neural networks? (2014) Advances in Neural Information Processing Systems, pp. 3320-3328; Yu, A.W., Dohan, D., Luong, M.-T., Zhao, R., Chen, K., Norouzi, M., Le, Q.V., QaNet: Combining local convolution with global self-attention for reading comprehension (2018) ICLR; Zellers, R., Bisk, Y., Schwartz, R., Choi, Y., SWAG: A large-scale adversarial dataset for grounded commonsense inference (2018) Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP); Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., Fidler, S., Aligning books and movies: Towards story-like visual explanations by watching movies and reading books (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 19-27\", None, None, 'Amazon;ASAPP;Bloomberg Engineering;et al.;facebook;Google', 'Association for Computational Linguistics (ACL)', '2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2019', '2 June 2019 through 7 June 2019', None, 159851.0, None, '9781950737130', None, None, 'English', 'NAACL HLT - Conf. N. Am. Chapter Assoc. Comput. Linguistics: Hum. Lang. Technol. - Proc. Conf.', 'Conference Paper', 'Final', None, 'Scopus', '2-s2.0-85083815650', '')\n",
            "('Cho K., Van Merriënboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y.', '55722769200;57188495900;56006846900;57188434700;42061073000;7005072756;7003958245;', 'Learning phrase representations using RNN encoderdecoder for statistical machine translation', 2014, 'EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference', None, None, None, '1724', '1734', None, 8169, '10.3115/v1/d14-1179', 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961291190&doi=10.3115%2fv1%2fd14-1179&partnerID=40&md5=c2352cbf63baff24b33f2291e0016bad', 'Université de Montréal, Canada; Jacobs University, Germany; Université du Maine, France', 'Cho, K., Université de Montréal, Canada; Van Merriënboer, B., Université de Montréal, Canada; Gulcehre, C., Université de Montréal, Canada; Bahdanau, D., Jacobs University, Germany; Bougares, F., Université du Maine, France; Schwenk, H., Université du Maine, France; Bengio, Y., Université de Montréal, Canada', 'In this paper, we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases. © 2014 Association for Computational Linguistics.', None, 'Computational linguistics; Decoding; Natural language processing systems; Recurrent neural networks; Regression analysis; Signal encoding; Conditional probabilities; Loglinear model; Novel neural network; Recurrent neural network (RNN); Statistical machine translation; Statistical machine translation system; Target sequences; Vector representations; Computer aided language translation', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Auli, M., Galley, M., Quirk, C., Zweig, G., Joint language and translation modeling with recurrent neural networks (2013) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1044-1054. , Auli et al.2013; Axelrod, A., He, X., Gao, J., Domain adaptation via pseudo in-domain data selection (2011) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 355-362. , Axelrod et al.2011; Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I.J., Bergeron, A., Bouchard, N., Bengio, Y., Theano: New features and speed improvements (2012) Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop, , Bastien et al.2012; Bengio, Y., Ducharme, R., Vincent, P., Janvin, C., A neural probabilistic language model (2003) J. Mach. Learn. Res., 3, pp. 1137-1155. , [Bengio et al.2003], ., March; Bengio, Y., Boulanger-Lewandowski, N., Pascanu, R., Advances in optimizing recurrent networks (2013) Proceedings of the 38th International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2013), , [Bengio et al.2013], May; Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Bengio, Y., Theano: A CPU and GPU math expression compiler (2010) Proceedings of the Python for Scientific Computing Conference (SciPy), , [Bergstra et al.2010],June. Oral Presentation; Chandar, S., Lauly, S., Larochelle, H., Khapra, M., Ravindran, B., Raykar, V., Saha, A., (2014) An Autoencoder Approach to Learning Bilingual Word Representations, , [Chandar et al.2014], . arXiv:1402.1454 [cs.CL], February; Dahl, G.E., Yu, D., Deng, L., Acero, A., Context-dependent pretrained deep neural networks for large vocabulary speech recognition (2012) IEEE Transactions on Audio, Speech, and Language Processing, 20 (1), pp. 33-42. , Dahl et al.2012; Devlin, J., Zbib, R., Huang, Z., Lamar, T., Schwartz, R., Makhoul, J., Fast and robust neural network joint models for statistical machine translation (2014) Proceedings of the ACL 2014 Conference, ACL '14, pp. 1370-1380. , Devlin et al.2014; Gao, J., He, X., Tau Yih, W., Deng, L., Learning semantic representations for the phrase translation model (2013) Technical Report, Microsoft Research, , Gao et al.2013; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier neural networks (2011) AISTATS'2011, , Glorot et al.2011; Goodfellow, I.J., Warde-Farley, D., Mirza, M., Courville, A., Bengio, Y., Maxout networks (2013) ICML'2013, , Goodfellow et al.2013; Graves, A., Supervised sequence labelling with recurrent neural networks (2012) Studies in Computational Intelligence, , [Graves2012], . Springer; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780. , Hochreiter and Schmidhuber1997; Kalchbrenner, N., Blunsom, P., Two recurrent continuous translation models (2013) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1700-1709. , Kalchbrenner and Blunsom2013; Koehn, P., Josef Och, F., Marcu, D., Statistical phrase-based translation (2003) Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, NAACL '03, 1, pp. 48-54. , [Koehn et al.2003]; Koehn, P., Europarl: A parallel corpus for statistical machine translation (2005) Machine Translation Summit, 10, pp. 79-86. , [Koehn2005], .Phuket, Thailand; Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS'2012), 25. , Krizhevsky et al.2012; Marcu, D., Wong, W., A phrase-based, joint probability model for statistical machine translation (2002) Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing- EMNLP '02, 10, pp. 133-139. , [Marcu and Wong2002]; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems, 26, pp. 3111-3119. , Mikolov et al.2013; Moore, R.C., Lewis, W., Intelligent selection of language model training data (2010) Proceedings of the ACL 2010 Conference Short Papers, ACLShort '10, pp. 220-224. , [Moore and Lewis2010], Stroudsburg, PA, USA; Pascanu, R., Gulcehre, C., Cho, K., Bengio, Y., How to construct deep recurrent neural networks (2014) Proceedings of the Second International Conference on Learning Representations (ICLR 2014), , [Pascanu et al.2014], April; Saxe, A.M., McClelland, J.L., Ganguli, S., Exact solutions to the nonlinear dynamics of learning in deep linear neural networks (2014) Proceedings of the Second International Conference on Learning Representations (ICLR 2014), , [Saxe et al.2014], ., April; Schwenk, H., Costa-Jussa, M.R., Fonollosa, J.A.R., Continuous space language models for the iwslt 2006 task (2006) IWSLT, pp. 166-173. , Schwenk et al.2006; Schwenk, H., Continuous space language models (2007) Comput. Speech Lang., 21 (3), pp. 492-518. , [Schwenk2007], July; Schwenk, H., Continuous space translation models for phrase-based statistical machine translation (2012) Proceedings of the 24th International Conference on Computational Linguistics (COLIN), pp. 1071-1080. , [Schwenk2012], . In Martin Kay and Christian Boitet, editors; Socher, R., Huang, E.H., Pennington, J., Ng, A.Y., Manning, C.D., Dynamic pooling and unfolding recursive autoencoders for paraphrase detection (2011) Advances in Neural Information Processing Systems, p. 24. , Socher et al.2011; Hai Son, L., Allauzen, A., Yvon, F., Continuous space translation models with neural networks (2012) Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT '12, pp. 39-48. , Son et al.2012], ., Stroudsburg, PA, USA; Van Der Maaten, L., Barnes-hut-sne (2013) Proceedings of the First International Conference on Learning Representations (ICLR 2013), , van der Maaten2013], ., May; Vaswani, A., Zhao, Y., Fossum, V., Chiang, D., Decoding with large-scale neural language models improves translation (2013) Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 1387-1392. , Vaswani et al.2013; Zeiler, M.D., (2012) ADADELTA: An Adaptive Learning Rate Method, , [Zeiler2012], Technical report, arXiv 1212.5701; Zou, W.Y., Socher, R., Cer, D.M., Manning, C.D., Bilingual word embeddings for phrase-based machine translation (2013) Proceedings of the ACL Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1393-1398. , Zou et al.2013\", None, None, 'Carnegie Mellon University Qatar;Facebook;iHorizons;Qatar Computing Research Institute;Qatar National Research Fund (QNRF);Yandex', 'Association for Computational Linguistics (ACL)', '2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014', '25 October 2014 through 29 October 2014', None, 111414.0, None, '9781937284961', None, None, 'English', 'EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.', 'Conference Paper', 'Final', 'All Open Access, Green', 'Scopus', '2-s2.0-84961291190', '')\n",
            "('Pang B., Lee L., Vaithyanathan S.', '8644537200;7404389769;6603253116;', 'Thumbs up Sentiment Classification using Machine Learning Techniques', 2002, 'Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, EMNLP 2002', None, None, None, '79', '86', None, 5835, None, 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141803251&partnerID=40&md5=2540bafede5003618f9b2d3bd685f49a', 'Department of Computer Science, Cornell University, Ithaca, NY  14853, United States; IBM Almaden Research Center, 650 Harry Rd., San Jose, CA  95120, United States', 'Pang, B., Department of Computer Science, Cornell University, Ithaca, NY  14853, United States; Lee, L., Department of Computer Science, Cornell University, Ithaca, NY  14853, United States; Vaithyanathan, S., IBM Almaden Research Center, 650 Harry Rd., San Jose, CA  95120, United States', 'We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging. © 2002 Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, EMNLP 2002. All rights reserved.', None, 'Learning algorithms; Maximum entropy methods; Natural language processing systems; Machine learning techniques; Maximum-entropy; Movie reviews; Naive bayes; Sentiment classification; Standard machines; Support vectors machine; Three machine learning methods; Support vector machines', None, None, None, None, 'National Science Foundation,\\xa0NSF: IIS-0081334', 'We thank Joshua Goodman, Thorsten Joachims, Jon Kleinberg, Vikas Krishna, John Lafferty, Jussi Myllymaki, Phoebe Sengers, Richard Tong, Peter Turney, and the anonymous reviewers for many valuable comments and helpful suggestions, and Hubie Chen and Tony Faradjian for participating in our baseline experiments. Portions of this work were done while the first author was visiting IBM Almaden. This paper is based upon work supported in part by the National Science Foundation under ITR/IM grant IIS-0081334. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation.', 'We thank Joshua Goodman, Thorsten Joachims, Jon Kleinberg, Vikas Krishna, John Lafferty, Jussi Myl-lymaki, Phoebe Sengers, Richard Tong, Peter Turney, and the anonymous reviewers for many valuable comments and helpful suggestions, and Hubie Chen and Tony Faradjian for participating in our baseline experiments. Portions of this work were done while the first author was visiting IBM Almaden. This paper is based upon work supported in part by the National Science Foundation under ITR/IM grant IIS-0081334. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation.', None, None, None, None, None, None, None, None, 'Argamon-Engelson, Shlomo, Koppel, Moshe, Avneri, Galit, Style-based text categorization: What newspaper am I reading? (1998) Proc. of the AAAI Workshop on Text Categorization, pp. 1-4; Berger, Adam L., Della Pietra, Stephen A., Della Pietra, Vincent J., A maximum entropy approach to natural language processing (1996) Computational Linguistics, 22 (1), pp. 39-71; Biber, Douglas, (1988) Variation across Speech and Writing, , Cambridge University Press; Chen, Stanley, Rosenfeld, Ronald, A survey of smoothing techniques for ME models (2000) IEEE Trans. Speech and Audio Processing, 8 (1), pp. 37-50; Das, Sanjiv, Chen, Mike, Yahoo! for Amazon: Extracting market sentiment from stock message boards (2001) Proc. of the 8th Asia Pacific Finance Association Annual Conference (APFA 2001); Pietra, Stephen Della, Pietra, Vincent Della, Lafferty, John, Inducing features of random fields (1997) IEEE Transactions on Pattern Analysis and Machine Intelligence, 19 (4), pp. 380-393; Domingos, Pedro, Pazzani, Michael J., On the optimality of the simple Bayesian classifier under zero-one loss (1997) Machine Learning, 29 (2-3), pp. 103-130; Finn, Aidan, Kushmerick, Nicholas, Smyth, Barry, Genre classification and domain transfer for information filtering (2002) Proc. of the European Colloquium on Information Retrieval Research, pp. 353-362. , Glasgow; Hatzivassiloglou, Vasileios, McKeown, Kathleen, Predicting the semantic orientation of adjectives (1997) Proc. of the 35th ACL/8th EACL, pp. 174-181; Hatzivassiloglou, Vasileios, Wiebe, Janyce, Effects of adjective orientation and gradability on sentence subjectivity (2000) Proc. of COLING.; Hearst, Marti, Direction-based text interpretation as an information access refinement (1992) Text-Based Intelligent Systems, , Paul Jacobs, editor, Lawrence Erlbaum Associates; Huettner, Alison, Subasic, Pero, Fuzzy typing for document management (2000) ACL 2000 Companion Volume: Tutorial Abstracts and Demonstration Notes, pp. 26-27; Joachims, Thorsten, Text categorization with support vector machines: Learning with many relevant features (1998) Proc. of the European Conference on Machine Learning (ECML), pp. 137-142; Joachims, Thorsten, Making large-scale SVM learning practical (1999) Advances in Kernel Methods - Support Vector Learning, pp. 44-56. , Bernhard Schölkopf and Alexander Smola, editors, pages MIT Press; Karlgren, Jussi, Cutting, Douglass, Recognizing text genres with simple metrics using discriminant analysis (1994) Proc. of COLING.; Kessler, Brett, Nunberg, Geoffrey, Schütze, Hinrich, Automatic detection of text genre (1997) Proc. of the 35th ACL/8th EACL, pp. 32-38; Lewis, David D., Naive (Bayes) at forty: The independence assumption in information retrieval (1998) Proc. of the European Conference on Machine Learning (ECML), pp. 4-15. , Invited talk; McCallum, Andrew, Nigam, Kamal, A comparison of event models for Naive Bayes text classification (1998) Proc. of the AAAI-98 Workshop on Learning for Text Categorization, pp. 41-48; Mosteller, Frederick, Wallace, David L., (1984) Applied Bayesian and Classical Inference: The Case of the Federalist Papers, , Springer-Verlag; Nigam, Kamal, Lafferty, John, McCallum, Andrew, Using maximum entropy for text classification (1999) Proc. of the IJCAI-99 Workshop on Machine Learning for Information Filtering, pp. 61-67; Pedersen, Ted, A decision tree of bigrams is an accurate predictor of word sense (2001) Proc. of the Second NAACL, pp. 79-86; Sack, Warren, On the computation of point of view (1994) Proc. of the Twelfth AAAI, p. 1488. , page Student abstract; Spertus, Ellen, Smokey: Automatic recognition of hostile messages (1997) Proc. of Innovative Applications of Artificial Intelligence (IAAI), pp. 1058-1065; Tatemura, Junichi, Virtual reviewers for collaborative exploration of movie reviews (2000) Proc. of the 5th International Conference on Intelligent User Interfaces, pp. 272-275; Terveen, Loren, Hill, Will, Amento, Brian, McDonald, David, Creter, Josh, PHOAKS: A system for sharing recommendations (1997) Communications of the ACM, 40 (3), pp. 59-62; Tomokiyo, Laura Mayfield, Jones, Rosie, You’re not from round here, are you? Naive Bayes detection of non-native utterance text (2001) Proc. of the Second NAACL, pp. 239-246; Tong, Richard M., An operational system for detecting and tracking opinions in on-line discussion (2001) Workshop note, SIGIR 2001 Workshop on Operational Text Classification; Turney, Peter D., Littman, Michael L., (2002) Unsupervised learning of semantic orientation from a hundred-billion-word corpus, , Technical Report EGB-1094, National Research Council Canada; Turney, Peter, Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews (2002) Proc. of the ACL.; Wiebe, Janyce M., Wilson, Theresa, Bell, Matthew, Identifying collocations for recognizing opinions (2001) Proc. of the ACL/EACL Workshop on Collocation; Wilks, Yorick, Stevenson, Mark, The grammar of sense: Using part-of-speech tags as a first step in semantic disambiguation (1998) Journal of Natural Language Engineering, 4 (2), pp. 135-144', None, None, None, 'Association for Computational Linguistics (ACL)', '7th Conference on Empirical Methods in Natural Language Processing, EMNLP 2002', '6 July 2002 through 7 July 2002', None, 185794.0, None, None, None, None, 'English', 'Proc. Conf. Empir. Methods Nat. Lang. Process., EMNLP', 'Conference Paper', 'Final', None, 'Scopus', '2-s2.0-85141803251', '')\n",
            "('Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P.', '14064641400;8865128200;6701721644;25651854400;25646533000;57221708009;', 'Natural language processing almost from scratch', 2011, 'Journal of Machine Learning Research', '12', None, None, '2493', '2537', None, 5302, None, 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053558787&partnerID=40&md5=1b7772fde7b09dee07bd4731149fb1c8', 'NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States; Idiap Research Institute, Switzerland; Google, New York, NY, United States; Microsoft, Redmond, WA, United States; New York University, New York, NY, United States; Rutgers University, New Brunswick, NJ, United States', 'Collobert, R., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Idiap Research Institute, Switzerland; Weston, J., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Google, New York, NY, United States; Bottou, L., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Microsoft, Redmond, WA, United States; Karlen, M., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States; Kavukcuoglu, K., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, New York University, New York, NY, United States; Kuksa, P., NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States, Rutgers University, New Brunswick, NJ, United States', 'We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements. © 2011 Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu and Pavel Kuksa.', 'Natural language processing; Neural networks', 'Computational requirements; Input features; Internal representation; Named entity recognition; NAtural language processing; Part of speech tagging; Prior knowledge; Semantic role labeling; Tagging systems; Training data; Unified neural networks; Computational linguistics; Learning algorithms; Network architecture; Neural networks; Semantics; Speech recognition; Natural language processing systems', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, \"Ando, R.K., Zhang, T., A framework for learning predictive structures from multiple tasks and unlabeled data (2005) Journal of Machine Learning Research (JMLR), 6, pp. 1817-1953; Bell, R.M., Koren, Y., Volinsky, C., The BellKor solution to the netflix prize (2007) Technical Report, , http://www.research.att.com/~volinsky/netflix, AT&T Labs; Bengio, Y., Ducharme, R., A neural probabilistic language model (2001) Advances in Neural Information Processing Systems (NIPS 13); Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) Advances in Neural Information Processing Systems (NIPS 19); Bengio, Y., Louradour, J., Collobert, R., Weston, J., Curriculum learning (2009) International Conference on Machine Learning (ICML); Bottou, L., Stochastic gradient learning in neural networks (1991) Proceedings of Neuro-Nîmes, EC2; Bottou, L., Online algorithms and stochastic approximations (1998) Online Learning and Neural Networks, , David Saad, editor, Cambridge University Press, Cambridge, UK; Bottou, L., Gallinari, P., A framework for the cooperation of learning algorithms (1991) Advances in Neural Information Processing Systems (NIPS 3); Bottou, L., Le Cun, Y., Bengio, Y., Global training of document processing systems using graph transformer networks (1997) Conference on Computer Vision and Pattern Recognition (CVPR), pp. 489-493; Bridle, J.S., Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition (1990) Neurocomputing: Algorithms, Architectures and Applications, pp. 227-236. , F. Fogelman Soulié and J. Hérault, editors, NATO ASI Series; Brown, P.F., De Souza, P.V., Mercer, R.L., Pietra, V.J.D., Lai, J.C., Class-based n-gram models of natural language (1992) Computational Linguistics, 18 (4), pp. 467-479; Brown, P.F., Della Pietra, V.J., Mercer, R.L., Della Pietra, S.A., Lai, J.C., An estimate of an upper bound for the entropy of english (1992) Computational Linguistics, 18 (1), pp. 31-41; Burges, C.J.C., Ragno, R., Le, Q.V., Learning to rank with nonsmooth cost functions (2007) Advances in Neural Information Processing Systems (NIPS 19), pp. 193-200; Caruana, R., Multitask Learning (1997) Machine Learning, 28 (1), pp. 41-75; Chapelle, O., Schlkopf, B., Zien, A., Semi-supervised learning (2006) Adaptive Computation and Machine Learning, , MIT Press, Cambridge, Mass., USA, September; Charniak, E., A maximum-entropy-inspired parser (2000) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 132-139; Chieu, H.L., Named entity recognition with a maximum entropy approach (2003) Conference on Natural Language Learning (CoNLL), pp. 160-163; Chomsky, N., Three models for the description of language (1956) IRE Transactions on Information Theory, 2 (3), pp. 113-124. , September; Clémençon, S., Vayatis, N., Ranking the best instances (2007) Journal of Machine Learning Research (JMLR), 8, pp. 2671-2699; Cohen, W.W., Schapire, R.E., Singer, Y., Learning to order things (1999) Journal of Artificial Intelligence Research, 10, pp. 243-270; Cohn, T., Blunsom, P., Semantic role labelling with tree conditional random fields (2005) Conference on Computational Natural Language (CoNLL); Collins, M., (1999) Head-driven Statistical Models for Natural Language Parsing, , PhD thesis, University of Pennsylvania; Collobert, R., (2004) Large Scale Machine Learning, , PhD thesis, Université Paris VI; Collobert, R., Deep learning for efficient discriminative parsing (2011) International Conference on Artificial Intelligence and Statistics (AISTATS); Cover Thomas, M., King Roger, C., Convergent gambling estimate of the entropy of english (1978) IEEE Transactions on Information Theory, IT-24 (4), pp. 413-421; Florian, R., Ittycheriah, A., Jing, H., Zhang, T., Named entity recognition through classifier combination (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 168-171; Gildea, D., Jurafsky, D., Automatic labeling of semantic roles (2002) Computational Linguistics, 28 (3), pp. 245-288; Gildea, D., Palmer, M., The necessity of parsing for predicate argument recognition (2002) Meeting of the Association for Computational Linguistics (ACL), pp. 239-246; Giménez, J., Màrquez, L., SVMTool: A general POS tagger generator based on support vector machines (2004) Conference on Language Resources and Evaluation (LREC); Haghighi, A., Toutanova, K., Manning, C.D., A joint model for semantic role labeling (2005) Conference on Computational Natural Language Learning (CoNLL), , June; Harris, Z.S., (1968) Mathematical Structures of Language, , John Wiley & Sons Inc; Heckerman, D., Chickering, D.M., Meek, C., Rounthwaite, R., Kadie, C., Dependency networks for inference, collaborative filtering, and data visualization (2001) Journal of Machine Learning Research, 1 (1), pp. 49-75; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554. , http://www.mitpressjournals.org/doi/pdf/10.1162/neco.2006.18.7.1527, DOI 10.1162/neco.2006.18.7.1527; Hollingshead, K., Fisher, S., Roark, B., Comparing and combining finite-state and context-free parsers (2005) Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP), pp. 787-794; Huang, F., Yates, A., Distributional representations for handling sparsity in supervised sequencelabeling (2009) Meeting of the Association for Computational Linguistics (ACL), pp. 495-503; Jelinek, F., Continuous speech recognition by statistical methods (1976) Proceedings of the IEEE, 64 (4), pp. 532-556; Joachims, T., Transductive inference for text classification using support vector machines (1999) International Conference on Machine Learning (ICML); Klein, D., Manning, C.D., Natural language grammar induction using a constituent-context model (2002) Advances in Neural Information Processing Systems (NIPS 14), pp. 35-42; Koo, T., Carreras, X., Collins, M., Simple semi-supervised dependency parsing (2008) Meeting of the Association for Computational Linguistics (ACL), pp. 595-603; Koomen, P., Punyakanok, V., Roth, D., Yih, W., Generalized inference with multiple semantic role labeling systems (shared task paper) (2005) Conference on Computational Natural Language Learning (CoNLL), pp. 181-184; Kudo, T., Matsumoto, Y., Chunking with support vector machines (2001) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 1-8; Kudoh, T., Matsumoto, Y., Use of support vector learning for chunk identification (2000) Conference on Natural Language Learning (CoNLL) and Second Learning Language in Logic Workshop (LLL), pp. 142-144; Lafferty, J., McCallum, A., Pereira, F., Conditional random fields: Probabilistic models for segmenting and labeling sequence data (2001) International Conference on Machine Learning (ICML); Le Cun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient based learning applied to document recognition (1998) Proceedings of IEEE, 86 (11), pp. 2278-2324; Le Cun, Y., A learning scheme for asymmetric threshold networks (1985) Proceedings of Cognitiva, pp. 599-604. , Paris, France; LeCun, Y., Bottou, L., Orr, G.B., Mueller, K.-R., Efficient BackProp (1998) Lecture Notes in Computer Science, (1524), pp. 9-50. , Neural Networks: Tricks of the Trade; Lewis, D.D., Yang, Y., Rose, T.G., Li, F., Rcv1: A new benchmark collection for text categorization research (2004) Journal of Machine Learning Research (JMLR), 5, pp. 361-397; Liang, P., (2005) Semi-supervised Learning for Natural Language, , Master's thesis, Massachusetts Institute of Technology; Liang, P., Daumé III, H., Klein, D., Structure compilation: Trading structure for features (2008) International Conference on Machine Learning (ICML), pp. 592-599; Lin, D., Wu, X., Phrase clustering for discriminative learning (2009) Meeting of the Association for Computational Linguistics (ACL), pp. 1030-1038; Littlestone, N., Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm (1988) Machine Learning, pp. 285-318; McCallum, A., Li, W., Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 188-191; McClosky, D., Charniak, E., Johnson, M., Effective self-training for parsing (2006) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT); McDonald, R., Crammer, K., Pereira, F., Flexible text segmentation with structured multilabel classification (2005) Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP), pp. 987-994; Miller, S., Fox, H., Ramshaw, L., Weischedel, R., A novel use of statistical parsing to extract information from text (2000) Applied Natural Language Processing Conference (ANLP); Miller, S., Guinness, J., Zamanian, A., Name tagging with word clusters and discriminative training (2004) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 337-342; Mnih, A., Hinton, G.E., Three new graphical models for statistical language modelling (2007) International Conference on Machine Learning (ICML), pp. 641-648; Musillo, G., Merlo, P., Robust parsing of the proposition bank (2006) ROMAND 2006: Robust Methods in Analysis of Natural Language Data; Neal, R.M., (1996) Bayesian Learning for Neural Networks, , Number 118 in Lecture Notes in Statistics. Springer-Verlag, New York; Okanohara, D., Tsujii, J., A discriminative language model with pseudo-negative samples (2007) Meeting of the Association for Computational Linguistics (ACL), pp. 73-80; Palmer, M., Gildea, D., Kingsbury, P., The proposition bank: An annotated corpus of semantic roles (2005) Computational Linguistics, 31 (1), pp. 71-106; Pearl, J., (1988) Probabilistic Reasoning in Intelligent Systems, , Morgan Kaufman, San Mateo; Plaut, D.C., Hinton, G.E., Learning sets of filters using back-propagation (1987) Computer Speech and Language, 2, pp. 35-61; Porter, M.F., An algorithm for suffix stripping (1980) Program, 14 (3), pp. 130-137; Pradhan, S., Ward, W., Hacioglu, K., Martin, J., Jurafsky, D., Shallow semantic parsing using support vector machines (2004) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT); Pradhan, S., Hacioglu, K., Ward, W., Martin, J.H., Jurafsky, D., Semantic role chunking combining complementary syntactic views (2005) Conference on Computational Natural Language Learning (CoNLL), pp. 217-220; Punyakanok, V., Roth, D., Yih, W., The necessity of syntactic parsing for semantic role labeling (2005) International Joint Conference on Artificial Intelligence (IJCAI), pp. 1117-1123; Rabiner, L.R., A tutorial on hidden Markov models and selected applications in speech recognition (1989) Proceedings of the IEEE, 77 (2), pp. 257-286; Ratinov, L., Roth, D., Design challenges and misconceptions in named entity recognition (2009) Conference on Computational Natural Language Learning (CoNLL), pp. 147-155. , Association for Computational Linguistics; Ratnaparkhi, A., A maximum entropy model for part-of-speech tagging (1996) Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 133-142; Rosenfeld, B., Feldman, R., Using corpus statistics on entities to improve semi-supervised relation extraction from the web (2007) Meeting of the Association for Computational Linguistics (ACL), pp. 600-607; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning internal representations by backpropagating errors (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, 1, pp. 318-362. , D. E. Rumelhart and J. L. McClelland, editors, MIT Press; Schütze, H., Distributional part-of-speech tagging (1995) Meeting of the Association for Computational Linguistics (ACL), pp. 141-148; Schwenk, H., Gauvain, J.L., Connectionist language modeling for large vocabulary continuous speech recognition (2002) International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pp. 765-768; Sha, F., Pereira, F., Shallow parsing with conditional random fields (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 134-141; Shannon, C.E., Prediction and entropy of printed english (1951) Bell Systems Technical Journal, 30, pp. 50-64; Shen, H., Sarkar, A., Voting between multiple data representations for text chunking (2005) Advances in Artificial Intelligence, pp. 389-400; Shen, L., Satta, G., Joshi, A.K., Guided learning for bidirectional sequence classification (2007) Meeting of the Association for Computational Linguistics (ACL); Smith, N.A., Eisner, J., Contrastive estimation: Training log-linear models on unlabeled data (2005) Meeting of the Association for Computational Linguistics (ACL), pp. 354-362; Suddarth, S.C., Holden, A.D.C., Symbolic-neural systems and the use of hints for developing complex systems (1991) International Journal of Man-machine Studies, 35 (3), pp. 291-311; Sun, X., Morency, L.-P., Okanohara, D., Tsujii, J., Modeling latent-dynamic in shallow parsing: A latent conditional model with improved inference (2008) International Conference on Computational Linguistics (COLING), pp. 841-848; Sutton, C., McCallum, A., Joint parsing and semantic role labeling (2005) Conference on Computational Natural Language (CoNLL), pp. 225-228; Sutton, C., McCallum, A., Composition of conditional random fields for transfer learning (2005) Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP), pp. 748-754; Sutton, C., McCallum, A., Rohanimanesh, K., Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data (2007) Journal of Machine Learning Research, 8, pp. 693-723. , http://jmlr.csail.mit.edu/papers/volume8/sutton07a/sutton07a.pdf; Suzuki, J., Isozaki, H., Semi-supervised sequential labeling and segmentation using giga-word scale unlabeled data (2008) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT), pp. 665-673; Teahan, W.J., Cleary, J.G., The entropy of english using ppm-based models (1996) Data Compression Conference (DCC), pp. 53-62. , IEEE Computer Society Press; Toutanova, K., Klein, D., Manning, C.D., Singer, Y., Feature-rich part-of-speech tagging with a cyclic dependency network (2003) Conference of the North American Chapter of the Association for Computational Linguistics & Human Language Technologies (NAACL-HLT); Turian, J., Ratinov, L., Bengio, Y., Word representations: A simple and general method for semisupervised learning (2010) Meeting of the Association for Computational Linguistics (ACL), pp. 384-392; Ueffing, N., Haffari, G., Sarkar, A., Transductive learning for statistical machine translation (2007) Meeting of the Association for Computational Linguistics (ACL), pp. 25-32; Waibel, A., Hanazawa, T., Hinton, G., Shikano, K., Lang, K.J., Phoneme recognition using time-delay neural networks (1989) IEEE Transactions on Acoustics, Speech, and Signal Processing, 37 (3), pp. 328-339. , DOI 10.1109/29.21701; Weston, J., Ratle, F., Collobert, R., Deep learning via semi-supervised embedding (2008) International Conference on Machine Learning (ICML), pp. 1168-1175\", 'Collobert, R.; NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, United States; email: RONAN@COLLOBERT.COM', None, None, None, None, None, None, None, '15324435', None, None, None, 'English', 'J. Mach. Learn. Res.', 'Article', 'Final', None, 'Scopus', '2-s2.0-80053558787', '')\n"
          ]
        }
      ],
      "source": [
        "# Select all records from the 'data' table\n",
        "select_query = \"SELECT * FROM data limit 5;\"\n",
        "cursor = conn.execute(select_query)\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "# Print the records\n",
        "for row in rows:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0falMMadvxTq"
      },
      "source": [
        "#Hands on project for using SQLite in ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cduaz-mksuwP"
      },
      "source": [
        "Here's a tutorial on how to use the transformers library in Python to perform sentiment analysis on movie reviews stored in a SQLite database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ymaDKz8isvqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd70807-d1ba-4a17-9383-e6cfa1e8b28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers --q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzTwOJgxx3V8"
      },
      "source": [
        "###Step 1: Load the sentiment analysis model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "b70809a7396d4e3c9083ff8d55c15049",
            "e8090b658ca9464ca7daf71fa04debea",
            "dfda45b4614c4c38a51916a5e66fcf4f",
            "52c7fa2d9ca84bb4a4a9453972f52f8d",
            "96e3fcc9d8604ed1b87b50c0bfbc91b0",
            "2820e7297b3e41e39ed027385669e748",
            "2af8ce7f42854788b467eaadae4db5bc",
            "20662162563c421a9e310ad9b688c0bf",
            "be1d7e9f2efd4d2d8955eb75323190ae",
            "5cd61f50577e420580fac2c235e7729a",
            "b9f4c8a294e24fef9ab88c4492296bd6",
            "47ffae71322e4432871c29072d249c2d",
            "46e49fca700e4cdf8eb467344dd64951",
            "50d9cf5c61d8430ebb91a474759a9fa5",
            "42cc915f753e458995185e3d2a14f414",
            "14965949f7604facbb679c71c3f53e8d",
            "2395ec9f3eae490fbd6bae088d52284a",
            "9b381ee239114c34930acd8725b265de",
            "3b25d33f0e4b4408af6c12bf6a36e9e4",
            "c61c548a5cdb431e846dec6075fbc071",
            "2b3d181c9f4a425897a36af9d710a095",
            "65fa415437f94782bbec5c8e2eb0cbba",
            "277498dab9584fb58367a615788a19ad",
            "740272288c454dbeace3ab55b6a380e7",
            "a8dab4f8dfa94615a63b0ee93a6bbbdf",
            "f07ae585ab2f4d6e9a75e60bdfa23172",
            "764a13817bd24336bd2dfaa2b786bc02",
            "891d1e1e877e4b709e0ea4c4bed40009",
            "7cfd10fa6f2649d2a88bb3247a6e5e77",
            "9707b8389b374ccd8428f5dfd0f16e6c",
            "9acaadbf7fe843bdbc1aeff4f849fbdf",
            "554f49e76cf64637bf86b0e00e822d9e",
            "433c008995464a14a8acc38a492c5eeb",
            "cc190f52592d4a8d81c349cb8ba144ae",
            "96e2e2b342c9495a8c9a99f820eca012",
            "98ec4f5a89014c619bd9776363a683fe",
            "9a3935a96fd343038d8264dfe2184a3a",
            "2dd9ab51636e4a56a17873a96373df3d",
            "ae2bea83d13140d4ab1c7363a2e7ffef",
            "12d6690d72a1497dbdbbbd99334043ce",
            "079f8038eb694825be7fb27a45b5e09b",
            "ebe60203f321467a8a26a9c9ea23d517",
            "2739232b5e5a4acaac7623562238c99a",
            "07b51996ee394a30b02016ad03e0fe10",
            "710ed702f054467a8df9d481c9c8af4b",
            "c48be42638d54310813fdb9a44b33bf2",
            "a7a08499abdc49bf87b2b25315b35745",
            "a20d1fb53a5d43759c177dd5ef6a2a23",
            "a70def245fe149bc93bfb2fd975cd844",
            "70e200fd136148d1b910b32fe8bfc8b7",
            "84ccf9586f7c4ee2860365cbc7faf3ec",
            "933dd4f13e1f40aba6d3d905130024d3",
            "96bb174843bf4d6c95852cee3574ef21",
            "f5c79b4f9e024bd99687e0f4e4dd7ffb",
            "4444c1aad3ae40a3a6624d5d962fbafd"
          ]
        },
        "id": "x7XjnDCrsuLV",
        "outputId": "b3c986c6-fc40-42bf-bded-557cc5e63c77"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b70809a7396d4e3c9083ff8d55c15049"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47ffae71322e4432871c29072d249c2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "277498dab9584fb58367a615788a19ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc190f52592d4a8d81c349cb8ba144ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "710ed702f054467a8df9d481c9c8af4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the pre-trained text-summarization model\n",
        "summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU_GleUGx7rN"
      },
      "source": [
        "###Step 2: Extract text for movie reviews\n",
        "Next, we need to extract the movie reviews from our SQLite database and analyze their sentiment using the classifier pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4unW87qFx8EV"
      },
      "outputs": [],
      "source": [
        "# Extract sentiment reviews for the movie reviews\n",
        "abstracts = conn.execute('SELECT Abstract FROM data limit 10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z_Cm2ryypnz"
      },
      "source": [
        "Once we have extracted the movie reviews, we can iterate over them using a for loop and use the classifier pipeline to analyze their sentiment. We will also update the reviews table in our database with the sentiment label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fomc32lTs6Wh",
        "outputId": "0a14b678-1e38-48cf-dddb-7a5dd927f435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/tf_utils.py:745: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Iterate over the movie reviews and update the summary for each one\n",
        "for i, row in enumerate(abstracts):\n",
        "    # Extract the text of the current review\n",
        "    abstract = row[0]\n",
        "    \n",
        "    # Summarize the review using the pre-trained summarizer\n",
        "    summary = summarizer(abstract, max_length=30, min_length=0, do_sample=False)[0]['summary_text']\n",
        "    \n",
        "    # Update the 'summary' column in the 'reviews' table with the summary for the current review\n",
        "    conn.execute('UPDATE data SET summary = ? WHERE rowid = ?', (summary, i+1))\n",
        "    \n",
        "# Commit the changes to the database\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckM81pViNxHY",
        "outputId": "3e7a996c-ca85-48c4-c0d7-97d076a91251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "display.max_colwidth : int or None\n",
            "    The maximum width in characters of a column in the repr of\n",
            "    a pandas data structure. When the column overflows, a \"...\"\n",
            "    placeholder is embedded in the output. A 'None' value means unlimited.\n",
            "    [default: 50] [currently: 1000]\n"
          ]
        }
      ],
      "source": [
        "pd.set_option('max_colwidth', 1000)\n",
        "pd.describe_option('max_colwidth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BRz3jMbYvO_I"
      },
      "outputs": [],
      "source": [
        "# Define the SQL query\n",
        "query = 'SELECT * FROM data LIMIT 10'\n",
        "\n",
        "# Execute the query and convert the result to a DataFrame\n",
        "df_q = pd.read_sql_query(query, conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "N6XefZQkTVRY",
        "outputId": "2611d534-0174-403b-ae48-a676c1935924"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition. © 2014 Association for Computational Linguistics.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_q['Abstract'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "VXi3QRNoTWx9",
        "outputId": "eb6554cd-1325-4a1e-f579-b211bc6fbf91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a new global logbilinear regression model is developed . it combines the advantages of global matrix factorization and local context window methods'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_q['summary'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njQND0oKdqaF"
      },
      "source": [
        "# Grad.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1btrqTVSgb0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd1276a1-b9fa-4951-a3b5-270ecaff51bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio --q\n",
        "!pip install transformers --q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EzlEHkiyhJ0d"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import gradio as gr\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3U0MZTfkGJe"
      },
      "source": [
        "## Generate a summary of titles available in our Scopus Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avnM1Yj2s8ti"
      },
      "source": [
        "## TEST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dropdown options\n",
        "c = conn.cursor()\n",
        "c.execute(\"SELECT DISTINCT Title FROM data\")\n",
        "dropdown_options = [row[0] for row in c.fetchall()]"
      ],
      "metadata": {
        "id": "1fDcaEre1GXX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropdown_options"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kpTKB7R1JAi",
        "outputId": "3655c3a8-5f15-4795-8c74-348bdd4993a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GloVe Global vectors for word representation',\n",
              " 'BERT Pretraining of deep bidirectional transformers for language understanding',\n",
              " 'Learning phrase representations using RNN encoderdecoder for statistical machine translation',\n",
              " 'Thumbs up Sentiment Classification using Machine Learning Techniques',\n",
              " 'Natural language processing almost from scratch',\n",
              " 'The stanford CoreNLP natural language processing toolkit',\n",
              " 'FCM The fuzzy cmeans clustering algorithm',\n",
              " 'Recursive deep models for semantic compositionality over a sentiment treebank',\n",
              " 'Moses Open source toolkit for statistical machine translation',\n",
              " 'A unified architecture for natural language processing Deep neural networks with multitask learning',\n",
              " 'Survey over image thresholding techniques and quantitative performance evaluation',\n",
              " 'Show and tell A neural image caption generator',\n",
              " 'SMILES, a Chemical Language and Information System 1 Introduction to Methodology and Encoding Rules',\n",
              " 'Longterm recurrent convolutional networks for visual recognition and description',\n",
              " 'STRING v9.1 Proteinprotein interaction networks, with increased coverage and integration',\n",
              " 'Machine learning Trends, perspectives, and prospects',\n",
              " 'Effective approaches to attentionbased neural machine translation',\n",
              " 'Neural collaborative filtering',\n",
              " 'SRILM  An extensible language modeling toolkit',\n",
              " 'Sentiment analysis and opinion mining',\n",
              " 'TextRank Bringing order into texts',\n",
              " 'Factorization meets the neighborhood A multifaceted collaborative filtering model',\n",
              " 'Learning realistic human actions from movies',\n",
              " 'Verb semantics and lexical selection',\n",
              " 'IPython A system for interactive scientific computing',\n",
              " 'Fuzzy logic = computing with words',\n",
              " 'Statistical phrasebased translation',\n",
              " 'METEOR An automatic metric for mt evaluation with improved correlation with human judgments',\n",
              " 'Recent advances in convolutional neural networks',\n",
              " 'SQuad 100,000+ questions for machine comprehension of text',\n",
              " 'VQA Visual question answering',\n",
              " 'A Maximum Entropy Approach to Natural Language Processing',\n",
              " 'Deep learning Methods and applications',\n",
              " 'Featurerich partofspeech tagging with a cyclic dependency network',\n",
              " 'Incorporating nonlocal information into information extraction systems by Gibbs sampling',\n",
              " 'Accurate unlexicalized parsing',\n",
              " 'Exploring the limits of transfer learning with a unified texttotext transformer',\n",
              " 'LexRank Graphbased lexical centrality as salience in text summarization',\n",
              " 'CIDEr Consensusbased image description evaluation',\n",
              " 'Largescale automated synthesis of human functional neuroimaging data',\n",
              " 'Unsupervised learning by probabilistic Latent Semantic Analysis',\n",
              " 'A survey of deep neural network architectures and their applications',\n",
              " 'Neural architectures for named entity recognition',\n",
              " 'SentenceBERT Sentence embeddings using siamese BERTnetworks',\n",
              " 'A survey on visual surveillance of object motion and behaviors',\n",
              " 'A Comprehensive Survey on Graph Neural Networks',\n",
              " 'Teaching machines to read and comprehend',\n",
              " 'Recent trends in deep learning based natural language processing [Review Article]',\n",
              " 'OpenSMILE  The Munich versatile and fast opensource audio feature extractor',\n",
              " 'BART Denoising sequencetosequence pretraining for natural language generation, translation, and comprehension',\n",
              " 'The Berkeley FrameNet Project',\n",
              " 'Understanding of a convolutional neural network',\n",
              " 'Computing semantic relatedness using wikipediabased explicit semantic analysis',\n",
              " 'On the properties of neural machine translation Encoder–decoder approaches',\n",
              " 'Toward a mechanistic psychology of dialogue',\n",
              " 'A large annotated corpus for learning natural language inference',\n",
              " 'A sequential algorithm for training text classifiers',\n",
              " 'BioBERT A pretrained biomedical language representation model for biomedical text mining',\n",
              " 'Psychological Aspects of Natural Language Use Our Words, Our Selves',\n",
              " 'Principles of geographical information systems for land resources assessment.',\n",
              " 'Introduction to genetic algorithms',\n",
              " 'Geometric Deep Learning Going beyond Euclidean data',\n",
              " 'ChestXray8 Hospitalscale chest Xray database and benchmarks on weaklysupervised classification and localization of common thorax diseases',\n",
              " 'Large margin methods for structured and interdependent output variables',\n",
              " 'Unsupervised word sense disambiguation rivaling supervised methods',\n",
              " 'Cheap and fast  But is it good Evaluating nonexpert annotations for natural language tasks',\n",
              " 'Dorsal and ventral streams A framework for understanding aspects of the functional anatomy of language',\n",
              " 'Endtoend memory networks',\n",
              " 'Constraint Processing',\n",
              " 'Word representations A simple and general method for semisupervised learning',\n",
              " 'Effective mapping of biomedical text to the UMLS Metathesaurus the MetaMap program.',\n",
              " 'Discriminative Training Methods for Hidden Markov Models Theory and Experiments with Perceptron Algorithms',\n",
              " 'Attentionbased bidirectional long shortterm memory networks for relation classification',\n",
              " 'Improved semantic representations from treestructured long shortTerm memory networks',\n",
              " 'Powergraph Distributed graphparallel computation on natural graphs',\n",
              " 'Synchronous data flow',\n",
              " 'Relation classification via convolutional deep neural network',\n",
              " 'DualGAN Unsupervised Dual Learning for ImagetoImage Translation',\n",
              " 'A fast and accurate dependency parser using neural networks',\n",
              " 'Universal language model finetuning for text classification',\n",
              " 'CYC A LargeScale Investment in Knowledge Infrastructure',\n",
              " 'Mayo clinical Text Analysis and Knowledge Extraction System cTAKES Architecture, component evaluation and applications',\n",
              " 'Artificial intelligence in healthcare Past, present and future',\n",
              " 'Sentiment analysis and subjectivity',\n",
              " 'A guide to deep learning in healthcare',\n",
              " 'What aro ontologies, and why do we need them',\n",
              " 'Neural architecture search with reinforcement learning',\n",
              " 'Stacked attention networks for image question answering',\n",
              " 'Open information extraction from the web',\n",
              " 'Image captioning with semantic attention',\n",
              " 'Supervised learning of universal sentence representations from natural language inference data',\n",
              " 'Evaluating wordnetbased measures of lexical semantic relatedness',\n",
              " 'Statistical significance tests for machine translation evaluation',\n",
              " 'PhosphoSitePlus A comprehensive resource for investigating the structure and function of experimentally determined posttranslational modifications in man and mouse',\n",
              " 'Annotating expressions of opinions and emotions in language',\n",
              " 'Fairseq A fast, extensible toolkit for sequence modeling',\n",
              " 'Automatic evaluation of summaries using Ngram cooccurrence statistics',\n",
              " 'A neural attention model for sentence summarization',\n",
              " 'Deep learning based recommender system A survey and new perspectives',\n",
              " 'Optimizing semantic coherence in topic models',\n",
              " 'Domain adaptation with structural correspondence learning',\n",
              " 'Document modeling with gated recurrent neural network for sentiment classification',\n",
              " 'BabelNet The automatic construction, evaluation and application of a widecoverage multilingual semantic network',\n",
              " 'A survey of modern authorship attribution methods',\n",
              " 'Labeled LDA A supervised topic model for credit attribution in multilabeled corpora',\n",
              " 'Knowledge graph embedding via dynamic mapping matrix',\n",
              " 'ConceptNet  a practical commonsense reasoning toolkit',\n",
              " 'Semantic parsing on freebase from questionanswer pairs',\n",
              " 'Semantic compositionality through recursive matrixvector spaces',\n",
              " 'SentencePiece A simple and language independent subword tokenizer and detokenizer for neural text processing',\n",
              " 'Meteor universal Language specific translation evaluation for any target language',\n",
              " 'Cortical oscillations and speech processing Emerging computational principles and operations',\n",
              " 'Selfnormalizing neural networks',\n",
              " 'Extracting product features and opinions from reviews',\n",
              " 'Opinion spam and analysis',\n",
              " 'A survey of opinion mining and sentiment analysis',\n",
              " 'A survey of the recent architectures of deep convolutional neural networks',\n",
              " 'Man is to computer programmer as woman is to homemaker Debiasing word embeddings',\n",
              " 'Identifying relations for Open Information Extraction',\n",
              " 'VMeasure A conditional entropybased external cluster evaluation measure',\n",
              " 'Semisupervised recursive autoencoders for predicting sentiment distributions',\n",
              " 'Design challenges and misconceptions in named entity recognition',\n",
              " 'Abstractive text summarization using sequencetosequence RNNs and beyond',\n",
              " 'An approach for measuring semantic similarity between words using multiple information sources',\n",
              " 'Inductive Learning Algorithms and Representations for Text Categorization',\n",
              " 'From computing with numbers to computing with words  From manipulation of measurements to manipulation of perceptions',\n",
              " 'Estimating the helpfulness and economic impact of product reviews Mining text and reviewer characteristics',\n",
              " 'The cougar approach to innetwork query processing in sensor networks',\n",
              " 'Shallow parsing with conditional random fields',\n",
              " 'Named entity recognition in tweets An experimental study',\n",
              " 'Improving word representations via global context and multipleword prototypes',\n",
              " 'An overview of deep learning in medical imaging focusing on MRI',\n",
              " 'ViLBERT Pretraining taskagnostic visiolinguistic representations for visionandlanguage tasks',\n",
              " 'Graph convolutional networks for text classification',\n",
              " 'A survey on opinion mining and sentiment analysis Tasks, approaches and applications',\n",
              " 'The unreasonable effectiveness of data',\n",
              " 'Recurrent continuous translation models',\n",
              " 'Support vector machine learning for interdependent and structured output spaces',\n",
              " 'A Maximum Entropy Model for PartOfSpeech Tagging',\n",
              " 'Techniques for Automatically Correcting Words in Text',\n",
              " 'Largescale named entity disambiguation based on Wikipedia data',\n",
              " 'Testing equivalences for processes',\n",
              " 'Hybrid computing using a neural network with dynamic external memory',\n",
              " 'Geometric deep learning on graphs and manifolds using mixture model CNNs',\n",
              " 'miRTarBase 2016 Updates to the experimentally validated miRNAtarget interactions database',\n",
              " 'Implicit Learning and Tacit Knowledge An Essay on the Cognitive Unconscious',\n",
              " 'Deep learning for sentiment analysis A survey',\n",
              " 'Sentiment analysis Capturing favorability using natural language processing',\n",
              " 'Sentiment analysis Mining opinions, sentiments, and emotions',\n",
              " 'Big data deep learning Challenges and perspectives',\n",
              " 'GENIA corpus  A semantically annotated corpus for biotextmining',\n",
              " 'LongTerm Recurrent Convolutional Networks for Visual Recognition and Description',\n",
              " 'Review of deep learning concepts, CNN architectures, challenges, applications, future directions',\n",
              " 'BRAT AWebbased tool for NLPAssisted text annotation',\n",
              " 'Kernel Methods for Relation Extraction',\n",
              " 'Distant supervision for relation extraction via Piecewise Convolutional Neural Networks',\n",
              " 'NLTK The natural language toolkit',\n",
              " 'The rise of deep learning in drug discovery',\n",
              " 'Contextual string embeddings for sequence labeling',\n",
              " 'Cuttingplane training of structural SVMs',\n",
              " 'Supervised learning of semantic classes for image annotation and retrieval',\n",
              " 'SCIBERT A pretrained language model for scientific text',\n",
              " 'A decomposable attention model for natural language inference',\n",
              " 'Know what you don’t know Unanswerable questions for SQuAD',\n",
              " 'Inducing features of random fields',\n",
              " 'Applications of machine learning in drug discovery and development',\n",
              " 'Towards Answering Opinion Questions Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences',\n",
              " 'Generating sentences from a continuous space',\n",
              " '2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text',\n",
              " 'Robust disambiguation of named entities in text',\n",
              " 'A shortest path dependency kernel for relation extraction',\n",
              " 'TOBI A STANDARD FOR LABELING ENGLISH PROSODY',\n",
              " 'A stateoftheart survey on deep learning theory and architectures',\n",
              " 'A simple algorithm for identifying negated findings and diseases in discharge summaries',\n",
              " 'A machine learning approach to coreference resolution of noun phrases',\n",
              " 'MSRVTT A large video description dataset for bridging video and language',\n",
              " 'A review of affective computing From unimodal analysis to multimodal fusion',\n",
              " 'A survey on deep learning Algorithms, techniques, and applications',\n",
              " 'Enriching the Knowledge Sources Used in a Maximum Entropy PartofSpeech Tagger',\n",
              " 'Placing search in context The concept revisited',\n",
              " 'Learning information extraction rules for semistructured and free text',\n",
              " 'Improved Automatic Keyword Extraction Given More Linguistic Knowledge',\n",
              " 'Novelty and diversity in information retrieval evaluation',\n",
              " 'Deictic codes for the embodiment of cognition',\n",
              " 'Sentence similarity based on semantic nets and corpus statistics',\n",
              " 'Deep neural nets as a method for quantitative structureactivity relationships',\n",
              " 'Learning Extraction Patterns for Subjective Expressions',\n",
              " 'GOSemSim An R package for measuring semantic similarity among GO terms and gene products',\n",
              " 'A Survey on Hate Speech Detection using Natural Language Processing',\n",
              " 'How not to evaluate your dialogue system An empirical study of unsupervised evaluation metrics for dialogue response generation',\n",
              " 'An analysis of active learning strategies for sequence labeling tasks',\n",
              " 'WordNetSimilarity  measuring the relatedness of concepts',\n",
              " 'The hierarchical hidden Markov model Analysis and applications',\n",
              " 'Investigating semantic similarity measures across the gene ontology The relationship between sequence and annotation',\n",
              " 'BioPortal Ontologies and integrated data resources at the click of a mouse',\n",
              " 'Text classification algorithms A survey',\n",
              " 'Generating focused molecule libraries for drug discovery with recurrent neural networks',\n",
              " 'UIMA An architectural approach to unstructured information processing in the corporate research environment',\n",
              " 'The enterprise ontology',\n",
              " 'Rumor has it Identifying misinformation in microblogs',\n",
              " 'Bilateral brain processes for comprehending natural language',\n",
              " 'Structural joins A primitive for efficient XML query pattern matching',\n",
              " 'TransformerXL Attentive language models beyond a fixedlength context',\n",
              " 'Using encyclopedic knowledge for named entity disambiguation',\n",
              " 'FiniteState Transducers in Language and Speech Processing',\n",
              " 'The SIDER database of drugs and side effects',\n",
              " 'The future of manufacturing industry a strategic roadmap toward Industry 4.0',\n",
              " 'Advances in natural language processing',\n",
              " 'Extracting information from textual documents in the electronic health record a review of recent research.',\n",
              " 'Breast cancer histopathological image classification using Convolutional Neural Networks',\n",
              " 'Applying conditional random fields to Japanese morphological analysis',\n",
              " 'Adversarial examples for evaluating reading comprehension systems',\n",
              " 'Phase Patterns of Neuronal Responses Reliably Discriminate Speech in Human Auditory Cortex',\n",
              " 'Neural responding machine for shortText conversation',\n",
              " 'An introduction to conditional random fields',\n",
              " 'Serving the enterprise and beyond with informatics for integrating biology and the bedside i2b2',\n",
              " 'Interpreting TFIDF term weights as making relevance decisions',\n",
              " 'Jumping NLP curves A review of natural language processing research',\n",
              " 'Nonprojective dependency parsing using spanning tree algorithms',\n",
              " 'Natural language processing An introduction',\n",
              " 'Emotions from text Machine learning for textbased emotion prediction',\n",
              " 'Extended gloss overlaps as a measure of semantic relatedness',\n",
              " 'Statedependent computations Spatiotemporal processing in cortical networks',\n",
              " 'Open language learning for information extraction',\n",
              " 'Instance weighting for domain adaptation in NLP',\n",
              " 'Semantic similarity in biomedical ontologies',\n",
              " 'Domain adaptation for statistical classifiers',\n",
              " 'Multiinstance multilabel learning for relation extraction',\n",
              " 'Event extraction via dynamic multipooling convolutional neural networks',\n",
              " 'A survey of current work in biomedical text mining',\n",
              " 'Deep unordered composition rivals syntactic methods for text classification',\n",
              " 'LXMert Learning crossmodality encoder representations from transformers',\n",
              " 'Multimodal compact bilinear pooling for visual question answering and visual grounding',\n",
              " 'Multiword expressions A pain in the neck for NLP',\n",
              " 'Eventrelated brain potentials during natural speech processing effects of semantic, morphological and syntactic violations',\n",
              " 'Interaction with context during human sentence processing',\n",
              " 'Spectral voice conversion for texttospeech synthesis',\n",
              " 'CoNLLX shared task on multilingual dependency parsing',\n",
              " 'Natural language processing',\n",
              " 'Speakerlistener neural coupling underlies successful communication',\n",
              " 'Systematic comparison of phenomewide association study of electronic medical record data and genomewide association study data',\n",
              " 'A baseline for detecting misclassified and outofdistribution examples in neural networks',\n",
              " 'Review of Convolutional Neural Network',\n",
              " 'MaltParser A languageindependent system for datadriven dependency parsing',\n",
              " 'On the naturalness of software',\n",
              " 'METEOR An automatic metric for MT evaluation with high levels of correlation with human judgments',\n",
              " 'Aspect level sentiment classification with deep memory network',\n",
              " 'Semantically conditioned lstmbased Natural language generation for spoken dialogue systems',\n",
              " 'Learning word vectors for 157 languages',\n",
              " 'Deep fragment embeddings for bidirectional image sentence mapping',\n",
              " 'Bibliometric cartography of information retrieval research by using coword analysis',\n",
              " 'Simulation, situated conceptualization, and prediction',\n",
              " 'Learning to rank short text pairs with convolutional deep neural networks',\n",
              " 'Hotpotqa A dataset for diverse, explainable multihop question answering',\n",
              " 'Deep learning A primer for radiologists',\n",
              " 'Language as shaped by the brain',\n",
              " 'SemEval2017 Task 1 Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation',\n",
              " 'Learning surface text patterns for a question answering system',\n",
              " 'Language models as knowledge bases',\n",
              " 'Deep Sentence embedding using long shortterm memory networks Analysis and application to information retrieval',\n",
              " 'Deep convolutional neural network based regression approach for estimation of remaining useful life',\n",
              " 'Sensorimotor Integration in Speech Processing Computational Basis and Neural Organization',\n",
              " 'A deep relevance matching model for Adhoc retrieval',\n",
              " 'A new measure for functional similarity of gene products based on gene ontology',\n",
              " 'Text summarization with pretrained encoders',\n",
              " 'Pathway studio  The analysis and navigation of molecular networks',\n",
              " 'Recurrent neural network for text classification with multitask learning',\n",
              " 'Neural module networks',\n",
              " 'Advances in pretraining distributed word representations',\n",
              " \"The HUPO PSI's Molecular Interaction format  A community standard for the representation of protein interaction data\",\n",
              " 'Deep Learning With Edge Computing A Review',\n",
              " 'Largescale bayesian logistic regression for text categorization',\n",
              " 'Learning deep representations of finegrained visual descriptions',\n",
              " 'Grammar as a foreign language',\n",
              " 'WIKIQA A challenge dataset for opendomain question answering',\n",
              " 'A general naturallanguage text processor for clinical radiology',\n",
              " 'A primer on neural network models for natural language processing',\n",
              " 'Local and global algorithms for disambiguation to Wikipedia',\n",
              " 'Semantic parsing via staged query graph generation Question answering with knowledge base',\n",
              " 'Twitter catches the flu Detecting influenza epidemics using Twitter',\n",
              " 'Show and Tell Lessons Learned from the 2015 MSCOCO Image Captioning Challenge',\n",
              " 'Improving sentiment analysis via sentence type classification using BiLSTMCRF and CNN',\n",
              " 'Textpresso An ontologybased information retrieval and extraction system for biological literature',\n",
              " 'Latent aspect rating analysis on review text data A rating regression approach',\n",
              " 'The Penn Chinese TreeBank Phrase structure annotation of a large corpus',\n",
              " 'FCAMERGE Bottomup merging of ontologies',\n",
              " 'An adapted lesk algorithm for word sense disambiguation using wordnet',\n",
              " 'A brief survey of Web data extraction tools',\n",
              " 'A latent variable model for geographic lexical variation',\n",
              " 'Deep reinforcement learning for dialogue generation',\n",
              " 'Classifying relations via long short term memory networks along shortest dependency paths',\n",
              " 'Stanza A Python natural language processing toolkit for many human languages',\n",
              " 'Remaining useful life estimation of engineered systems using vanilla LSTM neural networks',\n",
              " 'Sentiment analyzer Extracting sentiments about a given topic using natural language processing techniques',\n",
              " 'Learning structured embeddings of knowledge bases',\n",
              " 'Toward Efficient MultiKeyword Fuzzy Search over Encrypted Outsourced Data with Accuracy Improvement',\n",
              " 'Information extraction',\n",
              " 'A Survey on Bias and Fairness in Machine Learning',\n",
              " 'Unified language model pretraining for natural language understanding and generation',\n",
              " 'EDA Easy data augmentation techniques for boosting performance on text classification tasks',\n",
              " 'Improving machine learning approaches to coreference resolution',\n",
              " 'Artificial intelligence and deep learning in ophthalmology',\n",
              " 'A survey on automatic detection of hate speech in text',\n",
              " 'Discriminating gender on Twitter',\n",
              " 'The CoNLL 2007 shared task on dependency parsing',\n",
              " 'Using social media to enhance emergency situation awareness',\n",
              " 'Representing word meaning and order information in a composite holographic lexicon',\n",
              " 'Sequence level training with recurrent neural networks',\n",
              " 'Measuring semantic similarity between words using web search engines',\n",
              " 'Model cards for model reporting',\n",
              " 'Annotation artifacts in natural language inference data',\n",
              " 'Learned in translation Contextualized word vectors',\n",
              " 'Referitgame Referring to objects in photographs of natural scenes',\n",
              " 'Datadriven response generation in social media',\n",
              " 'Statistical models for text segmentation',\n",
              " 'LTP A chinese language technology platform',\n",
              " \"Collecting image annotations using Amazon's Mechanical Turk\",\n",
              " 'CoNLL2012 shared task Modeling multilingual unrestricted coreference in OntoNotes',\n",
              " 'Survey on AspectLevel Sentiment Analysis',\n",
              " 'Encoding sentences with graph convolutional networks for semantic role labeling',\n",
              " 'A tutorial survey of architectures, algorithms, and applications for deep learning',\n",
              " 'Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations',\n",
              " 'Leveraging linguistic structure for open domain information extraction',\n",
              " 'The neural mechanisms of speech comprehension fMRI studies of semantic ambiguity',\n",
              " 'Statistical machine translation',\n",
              " 'Unsupervised learning of the morphology of a natural language',\n",
              " 'Universal sentence encoder for English',\n",
              " 'Deep learning new computational modelling techniques for genomics',\n",
              " 'Truth of varying shades Analyzing language in fake news and political factchecking',\n",
              " 'Learning subjective language',\n",
              " 'Speech database development at MIT Timit and beyond',\n",
              " 'Discontinuation of statins in routine care settings, A cohort study',\n",
              " 'Webawhere Geotagging Web content',\n",
              " 'Transitionbased dependency parsing with stack long shortterm memory',\n",
              " 'A comparative study of TF*IDF, LSI and multiwords for text classification',\n",
              " 'Seven principles of surface structure parsing in natural language',\n",
              " 'Detection and resolution of rumours in social media A survey',\n",
              " 'Graph convolution over pruned dependency trees improves relation extraction',\n",
              " 'Feature selection using Joint Mutual Information Maximisation',\n",
              " 'Personalizing PageRank for word sense disambiguation',\n",
              " 'Bidirectional LSTM with attention mechanism and convolutional layer for text classification',\n",
              " 'Endtoend neural coreference resolution',\n",
              " 'Dependencybased construction of semantic space models',\n",
              " 'A semantic matching energy function for learning with multirelational data Application to wordsense disambiguation',\n",
              " 'An iterative design methodology for userfriendly natural language office information applications',\n",
              " 'Unsupervised word embeddings capture latent knowledge from materials science literature',\n",
              " 'How do users like this feature A fine grained sentiment analysis of App reviews',\n",
              " \"More than words Social networks' text mining for consumer brand sentiments\",\n",
              " 'Random walk inference and learning in a large scale knowledge base',\n",
              " 'Entitybased crossdocument coreferencing using the Vector Space Model',\n",
              " 'Comprehensive survey of deep learning in remote sensing Theories, tools, and challenges for the community',\n",
              " 'MCTest A challenge dataset for the opendomain machine comprehension of text',\n",
              " 'Information Extraction',\n",
              " 'Digital technologies in the publichealth response to COVID19',\n",
              " 'Energy and policy considerations for deep learning in NLP',\n",
              " 'VisionandLanguage Navigation Interpreting VisuallyGrounded Navigation Instructions in Real Environments',\n",
              " 'How may I help you',\n",
              " 'ErniE Enhanced language representation with informative entities',\n",
              " 'MultiWoz  A largescale multidomain wizardofoz dataset for taskoriented dialogue modelling',\n",
              " 'Recent automatic text summarization techniques a survey',\n",
              " 'Tracking the mind during reading The influence of past, present, and future words on fixation durations',\n",
              " 'Measures of semantic similarity and relatedness in the biomedical domain',\n",
              " 'Targeted aspectbased sentiment analysis via embedding commonsense knowledge into an attentive LSTM',\n",
              " 'Extracting opinion targets in a single and crossdomain setting with Conditional Random Fields',\n",
              " 'Neurosurgeon Collaborative intelligence between the cloud and mobile edge',\n",
              " 'PRUF—a meaning representation language for natural languages',\n",
              " 'Bilingual word embeddings for phrasebased machine translation',\n",
              " 'RelEx  Relation extraction using dependency parse trees',\n",
              " 'Conversational agents in healthcare A systematic review',\n",
              " 'Positionaware attention and supervised data improve slot filling',\n",
              " 'A multiworld approach to question answering about realworld scenes based on uncertain input',\n",
              " 'Detection of duplicate defect reports using natural language processing',\n",
              " 'Automatically assessing review helpfulness',\n",
              " 'BERT rediscovers the classical NLP pipeline',\n",
              " 'Understanding backtranslation at scale',\n",
              " 'Neural Network Methods for Natural Language Processing',\n",
              " 'Intelligent technology for an aging population The use of AI to assist elders with cognitive impairment',\n",
              " 'Webscale information extraction in knowltAll preliminary results',\n",
              " 'DIRT  Discovery of inference rules from text',\n",
              " 'Boosting Image Captioning with Attributes',\n",
              " 'Sequencelevel knowledge distillation',\n",
              " 'Epidemiology of asthma in children and adults',\n",
              " 'OpenFst A general and efficient weighted finitestate transducer library',\n",
              " 'Visual indexes, preconceptual objects, and situated vision',\n",
              " 'On using very large target vocabulary for neural machine translation',\n",
              " 'New ranking algorithms for parsing and tagging Kernels over discrete structures, and the voted perceptron',\n",
              " 'RACE Largescale ReAding comprehension dataset from examinations',\n",
              " 'Keyvalue memory networks for directly reading documents',\n",
              " 'Ask your neurons A neuralbased approach to answering questions about images',\n",
              " 'A universal partofspeech tagset',\n",
              " 'The perfect search engine is not enough A study of orienteering behavior in directed search',\n",
              " 'Sentiment analysis using product review data',\n",
              " 'Representing text for joint embedding of text and knowledge bases',\n",
              " \"Don't give me the details, just the summary! Topicaware convolutional neural networks for extreme summarization\",\n",
              " 'A SICK cure for the evaluation of compositional distributional semantic models',\n",
              " 'Learning to map sentences to logical form Structured classification with probabilistic categorial grammars',\n",
              " 'Continuous distributed representation of biological sequences for deep proteomics and genomics',\n",
              " 'What can natural language processing do for clinical decision support',\n",
              " 'XNLI Evaluating crosslingual sentence representations',\n",
              " 'Fusedlayer CNN accelerators',\n",
              " 'STATISTICAL LANGUAGE MODELING USING THE CMUCAMBRIDGE TOOLKIT',\n",
              " 'A model of textual affect sensing using realworld knowledge',\n",
              " 'Automatically generating extraction patterns from untagged text',\n",
              " 'Towards a theory of communicative competence',\n",
              " 'Cerebral organization for language in deaf and hearing subjects Biological constraints and effects of experience',\n",
              " 'Machine learning and radiology',\n",
              " 'langid.py An offtheshelf language identification tool',\n",
              " 'The Web as a Parallel Corpus',\n",
              " 'NCBI disease corpus A resource for disease name recognition and concept normalization',\n",
              " 'Semisupervised recognition of sarcastic sentences in twitter and Amazon',\n",
              " 'On coreference resolution performance metrics',\n",
              " 'GENIES A naturallanguage processing system for the extraction of molecular pathways from journal articles',\n",
              " 'Sarcasm as contrast between a positive sentiment and negative situation',\n",
              " 'Ensemble of keyword extraction methods and classifiers in text classification',\n",
              " 'A stochastic model of humanmachine interaction for learning dialog strategies',\n",
              " 'Survey of the state of the art in natural language generation Core tasks, applications and evaluation',\n",
              " 'Training and testing lowdegree polynomial data mappings via linear SVM',\n",
              " 'Cotraining for crosslingual sentiment classification',\n",
              " 'Pretrained models for natural language processing A survey',\n",
              " 'Ontology learning and population from text Algorithms, evaluation and applications',\n",
              " 'BANNER An executable survey of advances in biomedical named entity recognition',\n",
              " 'Algorithms on strings',\n",
              " 'ClausIE Clausebased open information extraction',\n",
              " 'The CoNLL2009 shared task Syntactic and semantic dependencies in multiple languages',\n",
              " 'Use and misuse of the gene ontology annotations',\n",
              " 'Continuous space language models',\n",
              " 'Deep LearningBased Document Modeling for Personality Detection from Text',\n",
              " 'Speechlike cerebral activity in profoundly deaf people processing signed languages Implications for the neural basis of human language',\n",
              " 'Advertising content and consumer engagement on social media Evidence from Facebook',\n",
              " 'Pharmacovigilance from social media Mining adverse drug reaction mentions using sequence labeling with word embedding cluster features',\n",
              " 'Wizard of oz studieswhy and how',\n",
              " 'Visualizing the nonvisual spatial analysis and interaction with information from text documents',\n",
              " 'Attention is not explanation',\n",
              " 'Searching for grey literature for systematic reviews Challenges and benefits',\n",
              " 'Question answering with subgraph embeddings',\n",
              " 'Learning to parse database queries using inductive logic programming',\n",
              " 'Convolutional neural networks over tree structures for programming language processing',\n",
              " 'Machine learning in medicine a practical introduction',\n",
              " 'Automatic keyphrase extraction A survey of the state of the art',\n",
              " 'Large language models in machine translation',\n",
              " 'The metricFF planning system Translating \"ignoring delete lists\" to numeric state variables',\n",
              " 'Emotion recognition from speech A review',\n",
              " 'A Survey of the Usages of Deep Learning for Natural Language Processing',\n",
              " 'MedEx A medication information extraction system for clinical narratives',\n",
              " 'Open information extraction The second generation',\n",
              " 'Semantic parsing via paraphrasing',\n",
              " 'The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies',\n",
              " 'Get out the vote Determining support or opposition from Congressional floordebate transcripts',\n",
              " 'A Really Temporal Logic',\n",
              " 'FLAIR An easytouse framework for stateoftheart NLP',\n",
              " 'The Sunway TaihuLight supercomputer system and applications',\n",
              " 'Towards a theory of natural language interfaces to databases',\n",
              " 'Text matching as image recognition',\n",
              " 'Application of deep belief networks for natural language understanding',\n",
              " 'Information extraction over structured data Question answering with freebase',\n",
              " 'Artificial Intelligence in Surgery Promises and Perils',\n",
              " 'Enhancing deep learning sentiment analysis with ensemble techniques in social applications',\n",
              " 'The interaction of domain knowledge and linguistic structure in natural language processing Interpreting hypernymic propositions in biomedical text',\n",
              " 'Nouns are vectors, adjectives are matrices Representing adjectivenoun constructions in semantic space',\n",
              " 'Tokenizing, POS tagging, lemmatizing and parsing UD 2.0 with UDPipe',\n",
              " 'Deep learning for wireless physical layer Opportunities and challenges',\n",
              " 'KeyGraph Automatic indexing by cooccurrence graph based on building construction metaphor',\n",
              " 'A review of recent advances in global optimization',\n",
              " 'Image parsing Unifying segmentation, detection, and recognition',\n",
              " 'Clusterbased retrieval using language models',\n",
              " 'Question answering over freebase with multicolumn convolutional neural networks',\n",
              " 'ABNER An open source tool for automatically tagging genes, proteins and other entity names in text',\n",
              " 'Measures of distributional similarity',\n",
              " 'Domain adaptation via pseudo indomain data selection',\n",
              " 'Rapid adaptation to foreignaccented English',\n",
              " 'A review of uncertainty quantification in deep learning Techniques, applications and challenges',\n",
              " 'Adversarial learning for neural dialogue generation',\n",
              " 'MultiTask learning for multiple language translation',\n",
              " 'Text categorization with support vector machines. How to represent texts in input space',\n",
              " 'Evaluation methods for unsupervised word embeddings',\n",
              " 'Automatic OntologyBased Knowledge Extraction from Web Documents',\n",
              " 'A CacheBased Natural Language Model for Speech Recognition',\n",
              " 'Bottomup abstractive summarization',\n",
              " 'SNOMED RT A Reference Terminology for Health Care',\n",
              " 'Templatebased question answering over RDF data',\n",
              " 'Impact of rumors and misinformation on COVID19 in Social Media',\n",
              " 'SemEval2019 task 6 Identifying and categorizing offensive language in social media OffensEval',\n",
              " 'Clinical information extraction applications A literature review',\n",
              " 'Findings of the 2016 Conference on Machine Translation WMT16',\n",
              " 'Prosodybased automatic segmentation of speech into sentences and topics',\n",
              " 'Approaches to language identification using Gaussian mixture models and shifted delta cepstral features',\n",
              " 'Automatic identification of word translations from unrelated English and German corpora',\n",
              " 'Natural language object retrieval',\n",
              " 'Text classification improved by integrating bidirectional LSTM with twodimensional max pooling',\n",
              " 'Justifying recommendations using distantlylabeled reviews and finegrained aspects',\n",
              " 'What do you learn from context Probing for sentence structure in contextualized word representations',\n",
              " 'Transfer learning for lowresource neural machine translation',\n",
              " 'Two decdes of statistical language modeling where do we go form here Where do we go from here',\n",
              " 'Automatic classification of citation function',\n",
              " 'Contextsensitive information retrieval using implicit feedback',\n",
              " 'Quantifying Mental Health Signals in Twitter',\n",
              " 'MANULEX A gradelevel lexical database from French elementary school readers',\n",
              " 'The third PASCAL recognizing textual entailment challenge',\n",
              " 'A method for disambiguating word senses in a large corpus',\n",
              " 'Scene text recognition using higher order language priors',\n",
              " 'Automated identification of postoperative complications within an electronic medical record using natural language processing',\n",
              " 'Detecting adverse events using information technology',\n",
              " 'Improving efficiency and accuracy in multilingual entity extraction',\n",
              " 'Selecting good expansion terms for pseudorelevance feedback',\n",
              " 'Automated encoding of clinical documents based on natural language processing',\n",
              " 'Some advances in transformationbased part of speech tagging',\n",
              " 'A review of natural language processing techniques for opinion mining systems',\n",
              " 'Global evaluation of heavy metal content in surface water bodies A metaanalysis using heavy metal pollution indices and multivariate statistical analyses',\n",
              " 'Deep closest point Learning representations for point cloud registration',\n",
              " 'Brain potentials indicate immediate use of prosodic cues in natural speech processing',\n",
              " 'Automated analysis of free speech predicts psychosis onset in highrisk youths',\n",
              " 'An improved nonmonotonic transition system for dependency parsing',\n",
              " 'Sensing trending topics in twitter',\n",
              " 'Ontologybased semantic similarity A new featurebased approach',\n",
              " 'Jointly modeling aspects and opinions with a MaxEntLDA hybrid',\n",
              " \"Fast, cheap, and creative Evaluating translation quality using Amazon's Mechanical Turk\",\n",
              " 'Factored translation models',\n",
              " 'context2vec Learning generic context embedding with bidirectional LSTM',\n",
              " 'Deep learning for classification of malware system call sequences',\n",
              " 'A word at a time Computing word relatedness using temporal semantic analysis',\n",
              " 'What is the Jeopardy model A quasisynchronous grammar for QA',\n",
              " 'Topology of the conceptual network of language',\n",
              " 'The CoNLL2014 shared task on grammatical error correction',\n",
              " 'Bilingualism affects picture naming but not picture classification',\n",
              " 'Knowledge graph construction techniques',\n",
              " 'A fuzzy ontology and its application to news summarization',\n",
              " 'Statistical decisiontree models for parsing',\n",
              " 'Deep leakage from gradients',\n",
              " 'HASTIDS Learning Hierarchical SpatialTemporal Features Using Deep Neural Networks to Improve Intrusion Detection',\n",
              " 'Semantic parsing for singlerelation question answering',\n",
              " 'Evaluating the StateoftheArt in Automatic Deidentification',\n",
              " 'The evolution of sentiment analysis—A review of research topics, venues, and top cited papers',\n",
              " 'Extracting medication information from clinical text',\n",
              " 'Posterior regularization for structured latent variable models',\n",
              " 'Studying the history of ideas using topic models',\n",
              " 'Learning domain ontologies from document warehouses and dedicated web sites',\n",
              " 'Age of Acquisition Effects in Adult Lexical Processing Reflect Loss of Plasticity in Maturing Systems Insights from Connectionist Networks',\n",
              " 'Modeling relation paths for representation learning of knowledge bases',\n",
              " 'Commonsense knowledge aware conversation generation with graph attention',\n",
              " 'Localizing Moments in Video with Natural Language',\n",
              " 'Automating LinguisticsBased Cues for detecting deception in textbased asynchronous computermediated communication',\n",
              " 'Short text similarity with word embeddings',\n",
              " 'BioInfer A corpus for information extraction in the biomedical domain',\n",
              " 'SemEval2016 task 1 Semantic textual similarity, monolingual and crosslingual evaluation',\n",
              " 'Recent trends in the identification of incidental pulmonary nodules',\n",
              " 'Deep code comment generation',\n",
              " 'Arbitrariness, Iconicity, and Systematicity in Language',\n",
              " 'Automatic speech recognition for underresourced languages A survey',\n",
              " 'Automatic keyphrase extraction via topic decomposition',\n",
              " 'Avoiding monotony Improving the diversity of recommendation lists',\n",
              " 'Lowquality product review detection in opinion summarization',\n",
              " 'Arabic natural language processing Challenges and solutions',\n",
              " 'A comprehensive survey of deep learning for image captioning',\n",
              " 'Learning Temporal Information for BrainComputer Interface Using Convolutional Neural Networks',\n",
              " 'Learning to compose neural networks for question answering',\n",
              " 'Retrieval models for question and answer archives',\n",
              " 'The Vera am Mittag German audiovisual emotional speech database',\n",
              " 'Hownet and the computation of meaning',\n",
              " 'Multiperspective sentence similarity modeling with convolutional neural networks',\n",
              " 'Addressing the rare word problem in neural machine translation',\n",
              " 'Trust region Newton method for largescale logistic regression',\n",
              " 'QuickSet multimodal interaction for distributed applications',\n",
              " 'Polygenic prediction via Bayesian regression and continuous shrinkage priors',\n",
              " 'Exploring topic coherence over many models and many topics',\n",
              " 'A review on the attention mechanism of deep learning',\n",
              " 'Endogenous Cortical Rhythms Determine Cerebral Specialization for Speech Perception and Production',\n",
              " 'Combinators for bidirectional tree transformations A linguistic approach to the viewupdate problem',\n",
              " 'How can i improve my app Classifying user reviews for software maintenance and evolution',\n",
              " 'PATTY A taxonomy of relational patterns with semantic types',\n",
              " 'VERBOCEAN Mining the web for finegrained semantic verb relations',\n",
              " 'Bug report, feature request, or simply praise On automatically classifying app reviews',\n",
              " 'A dynamically configurable coprocessor for convolutional neural networks',\n",
              " 'Introduction to Arabic natural language processing',\n",
              " 'A Survey of Deep Learning and Its Applications A New Paradigm to Machine Learning',\n",
              " 'Using convolutional neural networks to classify hatespeech',\n",
              " 'Artificial Intelligence in Medical Practice The Question to the Answer',\n",
              " 'An overview of multitask learning',\n",
              " 'A PhraseBased, Joint Probability Model for Statistical Machine Translation',\n",
              " 'Zeroshot learning by convex combination of semantic embeddings',\n",
              " 'Corpusguided sentence generation of natural images',\n",
              " 'Overview of BioCreative II gene mention recognition',\n",
              " 'Fast dictionary attacks on passwords using timespace tradeoff',\n",
              " 'A Database Perspective on Knowledge Discovery',\n",
              " 'Classifying relations by ranking with Convolutional neural networks',\n",
              " 'Scalable comparisonshopping agent for the WorldWide Web',\n",
              " 'Cohort profile of the South London and Maudsley NHS Foundation Trust Biomedical Research Centre SLaM BRC Case Register Current status and recent enhancement of an Electronic Mental Health Recordderived data resource',\n",
              " 'Discovering relations among named entities from large corpora',\n",
              " 'Phonemic and phonetic factors in adult crosslanguage speech perception',\n",
              " 'SemEval2015 Task 2 Semantic Textual Similarity, English, Spanish and Pilot on Interpretability',\n",
              " 'Knowledge graph and text jointly embedding',\n",
              " 'A Survey on Explainable Artificial Intelligence XAI Toward Medical XAI',\n",
              " 'ABCDM An Attentionbased Bidirectional CNNRNN Deep Model for sentiment analysis',\n",
              " 'Realtime crisis mapping of natural disasters using social media',\n",
              " 'Sentence level discourse parsing using syntactic and lexical information',\n",
              " 'SenticNet 6 Ensemble Application of Symbolic and Subsymbolic AI for Sentiment Analysis',\n",
              " 'UNITER UNiversal ImageTExt Representation Learning',\n",
              " 'QUAC Question answering in context',\n",
              " 'Formulaic language in native and second language speakers Psycholinguistics, corpus linguistics, and TESOL',\n",
              " 'A comprehensive method for multilingual video text detection, localization, and extraction',\n",
              " 'Generalizing discriminant analysis using the generalized singular value decomposition',\n",
              " 'Big bird Transformers for longer sequences',\n",
              " 'A survey on sentiment analysis challenges',\n",
              " 'TweetMotif Exploratory search and topic summarization for Twitter',\n",
              " 'The BioScope corpus Biomedical texts annotated for uncertainty, negation and their scopes',\n",
              " 'Semisupervised learning with generative adversarial networks on digital signal modulation classification',\n",
              " 'Wikipediabased semantic interpretation for natural language processing',\n",
              " 'A Comparative Study on Transformer vs RNN in Speech Applications',\n",
              " 'Why people hate your App  Making sense of user feedback in a mobile app store',\n",
              " 'Improving stemming for Arabic information retrieval Light stemming and cooccurrence analysis',\n",
              " 'Phrasebased & neural unsupervised machine translation',\n",
              " 'HowTo100M Learning a textvideo embedding by watching hundred million narrated video clips',\n",
              " 'Evaluating and predicting answer quality in community QA',\n",
              " 'An Information Retrieval Approach for Automatically Constructing Software Libraries',\n",
              " 'Natural language processing in radiology A systematic review',\n",
              " 'Evaluating temporal relations in clinical text 2012 i2b2 Challenge',\n",
              " 'Revisiting readability A unified framework for predicting text quality',\n",
              " 'Music acquisition effects of enculturation and formal training on development',\n",
              " 'Using measures of semantic relatedness for word sense disambiguation',\n",
              " 'Integrating multiple knowledge sources to disambiguate word sense An exemplarbased approach',\n",
              " 'Event detection and domain adaptation with convolutional neural networks',\n",
              " 'SemEval2014 Task 10 Multilingual Semantic Textual Similarity',\n",
              " 'Wireless Network Intelligence at the Edge',\n",
              " 'Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence',\n",
              " 'The teachable language comprehender A simulation program and theory of language',\n",
              " 'Attention is not not explanation',\n",
              " 'SenticNet 5 Discovering conceptual primitives for sentiment analysis by means of context embeddings',\n",
              " 'Corpus annotation for mining biomedical events from literature',\n",
              " 'Spontaneous speech corpus of Japanese',\n",
              " 'Training deep neural networks on imbalanced data sets',\n",
              " 'WHYPER Towards automating risk assessment of mobile applications',\n",
              " 'Named Entity Recognition through Classifier Combination',\n",
              " 'Automatic text categorization in terms of genre and author',\n",
              " 'Learning syntactic patterns for automatic hypernym discovery',\n",
              " 'Spoken Dialogue Technology Enabling the Conversational User Interface',\n",
              " 'A review of approaches to identifying patient phenotype cohorts using electronic health records',\n",
              " 'Nonnegative matrix factorization An analytical and interpretive tool in computational biology',\n",
              " 'Visual word processing and experiential origins of functional selectivity in human extrastriate cortex',\n",
              " 'Improved Alignment Models for Statistical Machine Translation',\n",
              " 'Expert network Effective and efficient learning from human decisions in text categorization and retrieval',\n",
              " 'A centering approach to pronouns',\n",
              " 'Machine learning based phishing detection from URLs',\n",
              " 'Malware classification with recurrent networks',\n",
              " 'A multipass sieve for coreference resolution',\n",
              " 'A survey of paraphrasing and textual entailment methods',\n",
              " 'Document summarization using conditional random fields',\n",
              " 'Similarity of semantic relations',\n",
              " 'An overview of the BioASQ largescale biomedical semantic indexing and question answering competition',\n",
              " 'Online learning of relaxed CCG grammars for parsing to logical form',\n",
              " 'Online Recognition of Chinese Characters The StateoftheArt',\n",
              " 'Reading speech from still and moving faces The neural substrates of visible speech',\n",
              " 'Open mind common sense Knowledge acquisition from the general public',\n",
              " 'A long shortterm memory model for answer sentence selection in question answering',\n",
              " 'Bioontologies Current trends and future directions',\n",
              " 'Beto, Bentz, Becas The surprising crosslingual effectiveness of Bert',\n",
              " 'Sentiment Analysis Is a Big Suitcase',\n",
              " 'Toward an affectsensitive autotutor',\n",
              " 'ColBERT Efficient and Effective Passage Search via Contextualized Late Interaction over BERT',\n",
              " 'Unsupervised learning of sentence embeddings using compositional ngram features',\n",
              " 'TALL Temporal Activity Localization via Language Query',\n",
              " 'Profiling, whatif analysis, and costbased optimization of mapreduce programs',\n",
              " \"Broca's area and the language instinct\",\n",
              " 'TinyBERT Distilling BERT for natural language understanding',\n",
              " 'Learning to Reason EndtoEnd Module Networks for Visual Question Answering',\n",
              " 'Multilingual partofspeech tagging with bidirectional long shortterm memory models and auxiliary loss',\n",
              " 'EsPal Onestop shopping for Spanish word properties',\n",
              " 'Ontology learning from text A look back and into the future',\n",
              " 'A linear programming formulation for global inference in natural language tasks',\n",
              " 'Using semantic roles to improve question answering',\n",
              " 'A Bootstrapping Method for Learning Semantic Lexicons using Extraction Pattern Contexts',\n",
              " 'Characterizing the Propagation of Situational Information in Social Media during COVID19 Epidemic A Case Study on Weibo',\n",
              " 'Deception detection for news Three types of fakes',\n",
              " 'Translating video content to natural language descriptions',\n",
              " 'Current state of text sentiment analysis from opinion to emotion mining',\n",
              " 'Structural semantic interconnections A knowledgebased approach to word sense disambiguation',\n",
              " 'Massively parallel parsing A strongly interactive model of natural language interpretation',\n",
              " 'Acceleration of deep neural network training with resistive crosspoint devices Design considerations',\n",
              " 'Cognition in multiple sclerosis',\n",
              " 'A discriminative kernelbased approach to rank images from text queries',\n",
              " 'Generalized theory of uncertainty GTUprincipal concepts and ideas',\n",
              " 'Design AI so that its fair',\n",
              " 'Ranking sentences for extractive summarization with reinforcement learning',\n",
              " 'Men also like shopping Reducing gender bias amplification using corpuslevel constraints',\n",
              " 'Learning semantic representations of users and products for document level sentiment classification',\n",
              " 'Information retrieval perspective to nonlinear dimensionality reduction for data visualization',\n",
              " 'Biomedical ontologies in action role in knowledge management, data integration and decision support.',\n",
              " 'Multidimensional range queries in sensor networks',\n",
              " 'Semisupervised sequence tagging with bidirectional language models',\n",
              " 'Robotic grasp detection using deep convolutional neural networks',\n",
              " 'Challenges in datatodocument generation',\n",
              " 'Two/too simple adaptations of Word2Vec for syntax problems',\n",
              " 'Identifying argumentative discourse structures in persuasive essays',\n",
              " 'Ontologybased information extraction An introduction and a survey of current approaches',\n",
              " 'Toward a common component architecture for highperformance scientific computing',\n",
              " 'Simulating speech systems',\n",
              " 'Finding function in form Compositional character models for open vocabulary word representation',\n",
              " 'Contentrich biological network constructed by mining PubMed abstracts',\n",
              " 'Automatic construction of a hypernymlabeled noun hierarchy from text',\n",
              " 'Similaritybased models of word cooccurrence probabilities',\n",
              " 'UDPipe Trainable pipeline for processing CoNLLU files performing tokenization, morphological analysis, POS tagging and parsing',\n",
              " 'Deep learning for Chinese word segmentation and POS tagging',\n",
              " 'Meteor 1.3 Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems',\n",
              " 'Graphbased ranking algorithms for sentence extraction, applied to text summarization',\n",
              " 'Volcano optimizer generator Extensibility and efficient search',\n",
              " 'Materials Synthesis Insights from Scientific Literature via Text Extraction and Machine Learning',\n",
              " 'Mining meaning from Wikipedia',\n",
              " 'Clustering to find exemplar terms for keyphrase extraction',\n",
              " 'Ontology Learning and Its Application to Automated Terminology Translation',\n",
              " 'Measuring and Mitigating Unintended Bias in Text Classification',\n",
              " 'AraVec A set of Arabic Word Embedding Models for use in Arabic NLP',\n",
              " 'TextAttentional Convolutional Neural Network for Scene Text Detection',\n",
              " 'Crosslingual knowledge graph alignment via graph convolutional networks',\n",
              " 'Graph convolutional encoders for syntaxaware neural machine translation',\n",
              " 'Combining Search, Social Media, and Traditional Data Sources to Improve Influenza Surveillance',\n",
              " 'Learning from multiple partially observed views  An application to multilingual text categorization',\n",
              " 'Disease recognition by infrared and Raman spectroscopy',\n",
              " 'Automatic summarising The state of the art',\n",
              " 'EDGAR extraction of drugs, genes and relations from the biomedical literature.',\n",
              " 'Is BERT really robust A strong baseline for natural language attack on text classification and entailment',\n",
              " 'Multigrained attention network for aspectlevel sentiment classification',\n",
              " 'Portable automatic text classification for adverse drug reaction detection via multicorpus training',\n",
              " 'Intelligent tutoring systems with conversational dialogue',\n",
              " 'Knowledge graph embedding based question answering',\n",
              " 'Survey of review spam detection using machine learning techniques',\n",
              " 'Development and Evaluation of a ComputerAnimated Tutor for Vocabulary and Language Learning in Children with Autism',\n",
              " 'Are sixteen heads really better than one',\n",
              " 'Sentic patterns Dependencybased rules for conceptlevel sentiment analysis',\n",
              " 'Look, Imagine and Match Improving TextualVisual CrossModal Retrieval with Generative Models',\n",
              " 'EndToend learning of semantic role labeling using recurrent neural networks',\n",
              " 'PCT Point cloud transformer',\n",
              " 'Mol2vec Unsupervised Machine Learning Approach with Chemical Intuition',\n",
              " 'ITEM2VEC Neural item embedding for collaborative filtering',\n",
              " 'Document ranking and the vectorspace model',\n",
              " 'A survey on fake news and rumour detection techniques',\n",
              " 'DeepPath A reinforcement learning method for knowledge graph reasoning',\n",
              " 'Neural sentiment classification with user and product attention',\n",
              " 'Compositional semantic parsing on semistructured tables',\n",
              " 'Brain signatures of artificial language processing Evidence challenging the critical period hypothesis',\n",
              " 'Knowledge enhanced contextual word representations',\n",
              " 'Extracting principal diagnosis, comorbidity and smoking status for asthma research Evaluation of a natural language processing system',\n",
              " 'Efficient phrasebased document indexing for web document clustering',\n",
              " \"Supporting information retrieval from electronic health records A report of University of Michigan's nineyear experience in developing and using the Electronic Medical Record Search Engine EMERSE\",\n",
              " 'Named entity recognition in query',\n",
              " 'A structured vector space model for word meaning in context',\n",
              " 'Improving statistical machine translation using word sense disambiguation',\n",
              " 'Measuring the semantic similarity of texts',\n",
              " 'Polylingual topic models',\n",
              " 'Multidocument summarization via sentencelevel semantic analysis and symmetric matrix factorization',\n",
              " 'PARSER A Model for Word Segmentation',\n",
              " 'Multitask identification of entities, relations, and coreference for scientific knowledge graph construction',\n",
              " 'Gaussian LDA for topic models with word embeddings',\n",
              " 'Analysis of named entity recognition and linking for tweets',\n",
              " 'Soft similarity and soft cosine measure Similarity of features in vector space model',\n",
              " 'Paraphrasedriven learning for open question answering',\n",
              " 'Language, embodiment, and the cognitive niche',\n",
              " 'Talk to me Foundations for successful individualgroup interactions in online communities',\n",
              " 'Neuropsychology of multiple sclerosis',\n",
              " 'Probabilistic Constraints and Syntactic Ambiguity Resolution',\n",
              " 'Sentiment Analysis Detecting Valence, Emotions, and Other Affectual States from Text',\n",
              " 'Text mining and its potential applications in systems biology',\n",
              " 'LexPageRank Prestige in multidocument text summarization',\n",
              " 'Designing the user interface for multimodal speech and penbased gesture applications Stateoftheart systems and future research directions',\n",
              " 'Visualizing and understanding neural models in NLP',\n",
              " 'Learning from bullying traces in social media',\n",
              " 'Estimating aggregate consumer preferences from online product reviews',\n",
              " 'Automatically refining the wikipedia infobox ontology',\n",
              " 'From humor recognition to irony detection The figurative language of social media',\n",
              " 'Extracting lexical semantic knowledge from Wikipedia and Wiktionary',\n",
              " 'mT5 A Massively Multilingual Pretrained TexttoText Transformer',\n",
              " 'Emergent A novel dataset for stance classification',\n",
              " 'Finegrained entity recognition',\n",
              " 'Pattern for python',\n",
              " 'Chapter 8 Emotional and semantic networks in visual word processing insights from ERP studies',\n",
              " 'Automatic tagging of Arabic text From raw text to base phrase chunks',\n",
              " 'A bit of progress in language modeling',\n",
              " 'Pay less attention with lightweight and dynamic convolutions',\n",
              " 'From Twitter to detector Realtime traffic incident detection using social media data',\n",
              " 'Neural text generation from structured data with application to the biography domain',\n",
              " 'Lowfrequency cortical entrainment to speech reflects phonemelevel processing',\n",
              " 'Constructing an interactive natural language interface for relational databases',\n",
              " 'Robust Replication of GenotypePhenotype Associations across Multiple Diseases in an Electronic Medical Record',\n",
              " 'Integration of heterogeneous databases without common domains using queries based on textual similarity',\n",
              " 'Automatically constructing a dictionary for information extraction tasks',\n",
              " 'Developing a Natural Language Interface to Complex Data',\n",
              " 'Sentiment analysis using deep learning architectures a review',\n",
              " 'Representation learning using multitask deep neural networks for semantic classification and information retrieval',\n",
              " 'Polyglot Distributed word representations for multilingual NLP',\n",
              " 'Common sense reasoning for detection, prevention, and mitigation of cyberbullying',\n",
              " 'The lie detector Explorations in the automatic recognition of deceptive language',\n",
              " 'Toward conversational humancomputer interaction',\n",
              " 'Natural language processing systems for capturing and standardizing unstructured clinical information A systematic review',\n",
              " 'A Survey on Deep Learning for Named Entity Recognition',\n",
              " 'Exploiting cloze questions for few shot text classification and natural language inference',\n",
              " 'A review Knowledge reasoning over knowledge graph',\n",
              " 'Learning to respond with deep neural networks for retrievalbased humancomputer conversation system',\n",
              " 'Automatic generation of natural language summaries for Java classes',\n",
              " 'Recent advances in the utility and use of the General Practice Research Database as an example of a UK Primary Care Data resource',\n",
              " 'RT Delphi An efficient, \"roundless\" almost real time Delphi method',\n",
              " 'Ask me anything Freeform visual question answering based on knowledge from external sources',\n",
              " 'Code completion with statistical language models',\n",
              " 'Humancompetitive tagging using automatic keyphrase extraction',\n",
              " 'Shallow semantic parsing using support vector machines',\n",
              " 'How to train goodword embeddings for biomedical nlp',\n",
              " 'Automated deidentification of freetext medical records',\n",
              " 'Sentiment analysis Adjectives and adverbs are better than adjectives alone',\n",
              " 'Normalization of nonstandard words',\n",
              " 'A Survey on Contrastive SelfSupervised Learning',\n",
              " 'A Novel Neural Source Code Representation Based on Abstract Syntax Tree',\n",
              " 'SWAG A largescale adversarial dataset for grounded commonsense inference',\n",
              " 'Learning principled bilingual mappings of word embeddings while preserving monolingual invariance',\n",
              " 'Data exchange Getting to the core',\n",
              " 'Natural language description of human activities from video images based on concept hierarchy of actions',\n",
              " 'Development and analysis of an international speech test signal ISTS',\n",
              " 'Discourse segmentation of multiparty conversation',\n",
              " 'Building a question answering test collection',\n",
              " 'Predicting judicial decisions of the European court of human rights A natural language processing perspective',\n",
              " 'Transfer learning in biomedical natural language processing An evaluation of BERT and ELMo on ten benchmarking datasets',\n",
              " 'Structured sequence modeling with graph convolutional recurrent networks',\n",
              " 'A neural approach to automated essay scoring',\n",
              " 'A hierarchical neural Autoencoder for paragraphs and documents',\n",
              " 'A unified framework for multioriented text detection and recognition',\n",
              " 'Electronic medical records for genetic research Results of the eMERGE consortium',\n",
              " 'Finding predominant word senses in untagged text',\n",
              " 'Psychological Constraints on the Teachability of Languages',\n",
              " 'Using twitter to examine smoking behavior and perceptions of emerging tobacco products',\n",
              " 'Environmentstrategy coevolution and coalignment A staged model of Chinese SOEs under transition',\n",
              " 'Uniting the Tribes Using Text for Marketing Insight',\n",
              " 'A feature selection model based on genetic rank aggregation for text sentiment classification',\n",
              " 'Inducing crosslingual distributed representations of words',\n",
              " 'Crosslanguage information retrieval based on parallel texts and automatic mining of parallel texts from the Web',\n",
              " 'A survey on recent advances in named entity recognition from deep learning models',\n",
              " 'Reporting score distributions makes a difference Performance Study of LSTMnetworks for sequence tagging',\n",
              " 'Ask me anything Dynamic memory networks for natural language processing',\n",
              " 'A unified model for word sense representation and disambiguation',\n",
              " 'A short introduction to learning to rank',\n",
              " 'Making tree kernels practical for natural language learning',\n",
              " 'Catching the drift Probabilistic content models, with applications to generation and summarization',\n",
              " 'Sequencetosequence learning as beamsearch optimization',\n",
              " 'A literature review on the stateoftheart in patent analysis',\n",
              " 'Eye movements as a window into realtime spoken language comprehension in natural contexts',\n",
              " 'Fewrel A largescale supervised fewshot relation classification dataset with stateoftheart evaluation',\n",
              " 'Named entity recognition for Chinese social media with jointly trained embeddings',\n",
              " 'A method based on PSO and granular computing of linguistic information to solve group decision making problems defined in heterogeneous contexts',\n",
              " 'Identifying sources of opinions with conditional random fields and extraction patterns',\n",
              " 'Term identification in the biomedical literature',\n",
              " 'GCC Graph Contrastive Coding for Graph Neural Network PreTraining',\n",
              " 'Enhanced network anomaly detection based on deep neural networks',\n",
              " 'Concurrence of big data analytics and healthcare A systematic review',\n",
              " 'Modeling joint entity and relation extraction with table representation',\n",
              " 'Word cloud explorer Text analytics based on word clouds',\n",
              " 'A largescale classification of English verbs',\n",
              " 'Creating an academic landscape of sustainability science An analysis of the citation network',\n",
              " 'Bootstrapping parsers via syntactic projection across parallel texts',\n",
              " 'ERNIE 2.0 A continual pretraining framework for language understanding',\n",
              " 'Sentiment analysis leveraging emotions and word embeddings',\n",
              " 'Learning NATURAL coding conventions',\n",
              " 'ConText An algorithm for determining negation, experiencer, and temporal status from clinical reports',\n",
              " 'SemEval2010 task 8 Multiway classification of semantic relations between pairs of nominals',\n",
              " 'A maximum entropy approach to identifying sentence boundaries',\n",
              " 'Semantic context and word frequency effects in visual word recognition',\n",
              " 'Deep Learning on Graphs A Survey',\n",
              " 'Aspectbased sentiment classification with aspectspecific graph convolutional networks',\n",
              " 'Spider A largescale humanlabeled dataset for complex and crossdomain semantic parsing and texttoSQL task',\n",
              " 'ICDAR2017 Robust Reading Challenge on MultiLingual Scene Text Detection and Script Identification  RRCMLT',\n",
              " 'The Grammar of Words An Introduction to Linguistic Morphology',\n",
              " 'Lexical Ambiguity and Information Retrieval',\n",
              " 'Joint named entity recognition and disambiguation',\n",
              " 'A neural network for factoid question answering over paragraphs',\n",
              " 'Unlocking clinical data from narrative reports A study of natural language processing',\n",
              " 'Automated deepneuralnetwork surveillance of cranial images for acute neurologic events',\n",
              " 'Efficient nonparametric estimation of multiple embeddings perword in vector space',\n",
              " 'Relational learning of patternmatch rules for information extraction',\n",
              " 'Rethinking drug design in the artificial intelligence era',\n",
              " 'CDAS A crowdsourcing data analytics system',\n",
              " 'Annotating named entities in Twitter data with crowdsourcing',\n",
              " 'Text mining and ontologies in biomedicine Making sense of raw text',\n",
              " 'SENSEMBED Learning sense embeddings forword and relational similarity',\n",
              " 'Lymphopenia association with gross tumor volume and lung V5 and its effects on nonsmall cell lung cancer patient outcomes',\n",
              " 'Better kbest parsing',\n",
              " 'Automatic description generation from images A survey of models, datasets, and evaluation measures',\n",
              " 'Open question answering with weakly supervised embedding models',\n",
              " 'Preliminary toxicity analysis of 3dimensional conformal radiation therapy versus intensity modulated radiation therapy on the highdose arm of the Radiation Therapy Oncology Group 0126 prostate cancer trial',\n",
              " 'Optimizing Chinese word segmentation for machine translation performance',\n",
              " 'Identifying Patient Smoking Status from Medical Discharge Records',\n",
              " 'How nativelike is nonnative language processing',\n",
              " 'PANNs LargeScale Pretrained Audio Neural Networks for Audio Pattern Recognition',\n",
              " 'Joint entity recognition and relation extraction as a multihead selection problem',\n",
              " 'Joint learning of the embedding of words and entities for named entity disambiguation',\n",
              " 'Extracting key terms from noisy and multitheme documents',\n",
              " 'Coordinate descent method for largescale L2loss linear support vector machines',\n",
              " 'A simple and effective hierarchical phrase reordering model',\n",
              " 'Climbing towards NLU On meaning, form, and understanding in the age of data',\n",
              " 'A joint manytask model Growing a neural network for multiple NLP tasks',\n",
              " 'A deep architecture for semantic matching with multiple positional sentence representations',\n",
              " 'Monolingual and crosslingual information retrieval models based on bilingual word embeddings',\n",
              " 'The language that gets people to give Phrases that predict success on kickstarter',\n",
              " 'A Tale of Two Parsers Investigating and combining graphbased and transitionbased dependency parsing using beamsearch',\n",
              " 'PLANTS, FRACTALS, AND FORMAL LANGUAGES.',\n",
              " 'Language Technology is power A critical survey of ⇜bias” in NLP',\n",
              " 'Generating natural language adversarial examples through probability weighted word saliency',\n",
              " 'A survey of crosslingual word embedding models',\n",
              " 'Linguisticallyinformed selfattention for semantic role labeling',\n",
              " 'Opinion mining from online hotel reviews – A text summarization approach',\n",
              " 'Sentiment Embeddings with Applications to Sentiment Analysis',\n",
              " 'The DDI corpus An annotated corpus with pharmacological substances and drugdrug interactions',\n",
              " 'Literal and metaphorical sense identification through concrete and abstract context',\n",
              " 'Defining spoken language benchmarks and selecting measures of expressive language development for young children with autism spectrum disorders',\n",
              " 'Audible television and decreased adult words, infant vocalizations, and conversational turns A populationbased study',\n",
              " 'Generation that exploits corpusbased statistical knowledge',\n",
              " 'Constructing literature abstracts by computer Techniques and prospects',\n",
              " 'Point Transformer',\n",
              " 'Chatbots and the New World of HCI',\n",
              " 'Automatic evaluation of translation quality for distant language pairs',\n",
              " 'Conscious thought is for facilitating social and cultural interactions How mental simulations serve the animalculture interface',\n",
              " 'Crossmodal interactions in the perception of musical performance',\n",
              " 'An optimization criterion for generalized discriminant analysis on undersampled problems',\n",
              " 'GeneWays A system for extracting, analyzing, visualizing, and integrating molecular pathway data',\n",
              " 'Multimodal sentiment intensity analysis in videos Facial gestures and verbal messages',\n",
              " 'Big data in biomedicine',\n",
              " 'Affect analysis of text using fuzzy semantic typing',\n",
              " 'ERP effects of listening to speech compared to reading The P600/SPS to syntactic violations in spoken sentences and rapid serial visual presentation',\n",
              " 'Robust partofspeech tagging using a hidden Markov model',\n",
              " 'The Concept of Love Viewed From a Prototype Perspective',\n",
              " 'Green AI',\n",
              " 'A survey on security threats and defensive techniques of machine learning A data driven view',\n",
              " 'Long shortterm memory neural networks for Chinese word segmentation',\n",
              " 'Fact Checking Task definition and dataset construction',\n",
              " 'Improving lexical embeddings with semantic knowledge',\n",
              " 'An opensource toolkit for mining Wikipedia',\n",
              " 'An experimental study of graph connectivity for unsupervised word sense disambiguation',\n",
              " 'Towards internetage pharmacovigilance Extracting adverse drug reactions from user posts to healthrelated social networks',\n",
              " 'Dependency parsing',\n",
              " 'Allpaths graph kernel for proteinprotein interaction extraction with evaluation of crosscorpus learning',\n",
              " 'An Analysis of the AskMSR QuestionAnswering System',\n",
              " 'Winnowbased approach to contextsensitive spelling correction',\n",
              " 'Recognizing implicit discourse relations in the Penn Discourse Treebank',\n",
              " 'Flux An adaptive partitioning operator for continuous query systems',\n",
              " 'Resolving ambiguity for crosslanguage retrieval',\n",
              " 'Generating Natural Language Summaries from Multiple OnLine Sources',\n",
              " 'Reasoning about entailment with neural attention',\n",
              " 'Chinese poetry generation with recurrent neural networks',\n",
              " 'The Oxford Handbook of Computational Linguistics',\n",
              " 'Learning semantic correspondences with less supervision',\n",
              " 'Characterizing the errors of datadriven dependency parsing models',\n",
              " 'Broadening the horizon  Level 2.5 of the HUPOPSI format for molecular interactions',\n",
              " 'Comparison of STFT and wavelet transform methods in determining epileptic seizure activity in EEG signals for realtime application',\n",
              " 'Identifying word translations in nonparallel texts',\n",
              " 'Prefixtuning Optimizing continuous prompts for generation',\n",
              " 'How contextual are contextualized word representations Comparing the geometry of BERT, ELMO, and GPT2 embeddings',\n",
              " 'Fast and accurate entity recognition with iterated dilated convolutions',\n",
              " 'Towards a relevant and diverse search of social images',\n",
              " 'IRSTLM An open source toolkit for handling large scale language models',\n",
              " 'Mereotopology A theory of parts and boundaries',\n",
              " 'Tucker Tensor factorization for knowledge graph completion',\n",
              " 'Deep anomaly detection with outlier exposure',\n",
              " 'Web of Science use in published research and review papers 1997–2017 a selective, dynamic, crossdomain, contentbased analysis',\n",
              " 'Bilingual word representations with monolingual quality in mind',\n",
              " 'A failure of left temporal cortex to specialize for language is an early emerging and fundamental property of autism',\n",
              " 'Experimental support for a categorical compositional distributional model of meaning',\n",
              " 'Word sense disambiguation and information retrieval',\n",
              " 'Predicting process behaviour using deep learning',\n",
              " 'Pattern recognition using typeII fuzzy sets',\n",
              " 'A nonprojective dependency parser',\n",
              " 'Fuzzification of set inclusion Theory and applications',\n",
              " 'Defending against neural fake news',\n",
              " 'Conversational recommender system',\n",
              " 'Deep recursive neural networks for compositionality in language',\n",
              " 'Electronic medical records for discovery research in rheumatoid arthritis',\n",
              " 'Advancing translational research with the Semantic Web',\n",
              " 'Dependence language model for information retrieval',\n",
              " 'Cost and conflict in animal signals and human language',\n",
              " 'Transfer learning in natural language processing tutorial',\n",
              " 'Characterbased LSTMCRF with radicallevel features for chinese named entity recognition',\n",
              " 'Toward deep learning software repositories',\n",
              " 'Active Computerized Pharmacovigilance Using Natural Language Processing, Statistics, and Electronic Health Records A Feasibility Study',\n",
              " 'Discovering key concepts in verbose queries',\n",
              " 'Monolingual machine translation for paraphrase generation',\n",
              " 'Compoundprotein interaction prediction with endtoend learning of neural networks for graphs and sequences',\n",
              " 'The arithmetic of discrete Znumbers',\n",
              " 'An analysis of symbolic linguistic computing models in decision making',\n",
              " 'Exploitingwikipedia as external knowledge for named entity recognition',\n",
              " 'Linking lexicons and ontologies Mapping wordnet to the suggested upper merged ontology',\n",
              " 'CamemBERT A tasty French language model',\n",
              " 'A closer look at skipgram modelling',\n",
              " 'THE OGI MULTILANGUAGE TELEPHONE SPEECH CORPUS',\n",
              " 'A survey on deep learning and its applications',\n",
              " 'ScispaCy Fast and robust models for biomedical natural language processing',\n",
              " 'Frontiers of biomedical text mining Current progress',\n",
              " 'Support vector learning for semantic argument classification',\n",
              " 'Reading level assessment using support vector machines and statistical language models',\n",
              " 'Context in problem solving A survey',\n",
              " 'Word sense disambiguation A unified evaluation framework & empirical comparison',\n",
              " 'Building a semantic parser overnight',\n",
              " 'UTOPIAN Userdriven topic modeling based on interactive nonnegative matrix factorization',\n",
              " 'Image description using visual dependency representations',\n",
              " 'Annotated Gigaword',\n",
              " 'Data from clinical notes A perspective on the tension between structure and flexible documentation',\n",
              " 'Deep learning in ophthalmology The technical and clinical considerations',\n",
              " 'How artificial intelligence is changing drug discovery spotlight /631/45 /639/705/117 /631/154 /706/703/559 n/a',\n",
              " 'VQA Visual Question Answering www.visualqa.org',\n",
              " 'Recognizing stances in online debates',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summary(selected_option):\n",
        "    c.execute(\"SELECT Abstract FROM data WHERE Title = ?\", (selected_option,))\n",
        "    abstract = c.fetchone()[0]\n",
        "    summary = summarizer(abstract, max_length=30, min_length=0, do_sample=False)\n",
        "    return summary[0]['summary_text']"
      ],
      "metadata": {
        "id": "LPwwVxjR1Oa2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropdown_options[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZbfqxL4p3-tQ",
        "outputId": "7410433d-50bf-41e0-d222-48ebe3e38966"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GloVe Global vectors for word representation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(dropdown_options[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "Rzd2W-x_1SCJ",
        "outputId": "ce20c3cc-9658-425e-9618-5127f033cd25"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a new global logbilinear regression model is developed . it combines the advantages of global matrix factorization and local context window methods'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=summary,\n",
        "    inputs=gr.inputs.Dropdown(choices=dropdown_options, type=\"value\", label=\"Select a Title from Scopus\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Generated Summary\"),\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "AHYq6Yew9RXM",
        "outputId": "051b050d-df37-4b02-d8f8-0a6769eb46ed"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7876, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "TOY9CjHuf1tQ",
        "outputId": "f2eb3a39-dc12-4184-9816-a4c9ad409abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:217: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7872, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import sqlite3\n",
        "\n",
        "summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# Define the dropdown options\n",
        "c = conn.cursor()\n",
        "c.execute(\"SELECT DISTINCT Title FROM data\")\n",
        "dropdown_options = [row[0] for row in c.fetchall()]\n",
        "\n",
        "def summary(selected_option):\n",
        "    c.execute(\"SELECT Abstract FROM data WHERE Title = ?\", (selected_option,))\n",
        "    abstract = c.fetchone()[0]\n",
        "    summary = summarizer(abstract, max_length=30, min_length=0, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "# Create the Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=summary,\n",
        "    inputs=gr.inputs.Dropdown(choices=dropdown_options, label=\"Select a Title from Scopus\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Generated Summary\"),\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tpT500aj7-b"
      },
      "source": [
        "## Generate a summary of your own abstract/abstracts not available in our Scopus Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "jrm4fFSdgVbE",
        "outputId": "0a2c8f95-34e1-49be-96be-cf211361cff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline('summarization', model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
        "\n",
        "def summary(abstract):\n",
        "    summary = summarizer(abstract, max_length=30, min_length=0, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "examples = [\n",
        "    [\"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition. © 2014 Association for Computational Linguistics.\"],\n",
        "    [\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement). © 2019 Association for Computational Linguistics\"],\n",
        "    [\"In this paper, we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases. © 2014 Association for Computational Linguistics.\"],\n",
        "]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=summary,\n",
        "    inputs=gr.inputs.Textbox(lines=5, label=\"Input Abstract\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Generated Summary\"),\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Clean up\n",
        "\n",
        "In a new cell, close the database connection:"
      ],
      "metadata": {
        "id": "RHnLwin5yvSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "x_Bs4fzUyy4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b70809a7396d4e3c9083ff8d55c15049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8090b658ca9464ca7daf71fa04debea",
              "IPY_MODEL_dfda45b4614c4c38a51916a5e66fcf4f",
              "IPY_MODEL_52c7fa2d9ca84bb4a4a9453972f52f8d"
            ],
            "layout": "IPY_MODEL_96e3fcc9d8604ed1b87b50c0bfbc91b0"
          }
        },
        "e8090b658ca9464ca7daf71fa04debea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2820e7297b3e41e39ed027385669e748",
            "placeholder": "​",
            "style": "IPY_MODEL_2af8ce7f42854788b467eaadae4db5bc",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "dfda45b4614c4c38a51916a5e66fcf4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20662162563c421a9e310ad9b688c0bf",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be1d7e9f2efd4d2d8955eb75323190ae",
            "value": 1208
          }
        },
        "52c7fa2d9ca84bb4a4a9453972f52f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd61f50577e420580fac2c235e7729a",
            "placeholder": "​",
            "style": "IPY_MODEL_b9f4c8a294e24fef9ab88c4492296bd6",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 17.7kB/s]"
          }
        },
        "96e3fcc9d8604ed1b87b50c0bfbc91b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2820e7297b3e41e39ed027385669e748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2af8ce7f42854788b467eaadae4db5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20662162563c421a9e310ad9b688c0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1d7e9f2efd4d2d8955eb75323190ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cd61f50577e420580fac2c235e7729a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f4c8a294e24fef9ab88c4492296bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47ffae71322e4432871c29072d249c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46e49fca700e4cdf8eb467344dd64951",
              "IPY_MODEL_50d9cf5c61d8430ebb91a474759a9fa5",
              "IPY_MODEL_42cc915f753e458995185e3d2a14f414"
            ],
            "layout": "IPY_MODEL_14965949f7604facbb679c71c3f53e8d"
          }
        },
        "46e49fca700e4cdf8eb467344dd64951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2395ec9f3eae490fbd6bae088d52284a",
            "placeholder": "​",
            "style": "IPY_MODEL_9b381ee239114c34930acd8725b265de",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "50d9cf5c61d8430ebb91a474759a9fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b25d33f0e4b4408af6c12bf6a36e9e4",
            "max": 892146080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c61c548a5cdb431e846dec6075fbc071",
            "value": 892146080
          }
        },
        "42cc915f753e458995185e3d2a14f414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3d181c9f4a425897a36af9d710a095",
            "placeholder": "​",
            "style": "IPY_MODEL_65fa415437f94782bbec5c8e2eb0cbba",
            "value": " 892M/892M [00:06&lt;00:00, 161MB/s]"
          }
        },
        "14965949f7604facbb679c71c3f53e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2395ec9f3eae490fbd6bae088d52284a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b381ee239114c34930acd8725b265de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b25d33f0e4b4408af6c12bf6a36e9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c61c548a5cdb431e846dec6075fbc071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b3d181c9f4a425897a36af9d710a095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65fa415437f94782bbec5c8e2eb0cbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "277498dab9584fb58367a615788a19ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_740272288c454dbeace3ab55b6a380e7",
              "IPY_MODEL_a8dab4f8dfa94615a63b0ee93a6bbbdf",
              "IPY_MODEL_f07ae585ab2f4d6e9a75e60bdfa23172"
            ],
            "layout": "IPY_MODEL_764a13817bd24336bd2dfaa2b786bc02"
          }
        },
        "740272288c454dbeace3ab55b6a380e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891d1e1e877e4b709e0ea4c4bed40009",
            "placeholder": "​",
            "style": "IPY_MODEL_7cfd10fa6f2649d2a88bb3247a6e5e77",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "a8dab4f8dfa94615a63b0ee93a6bbbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9707b8389b374ccd8428f5dfd0f16e6c",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9acaadbf7fe843bdbc1aeff4f849fbdf",
            "value": 147
          }
        },
        "f07ae585ab2f4d6e9a75e60bdfa23172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554f49e76cf64637bf86b0e00e822d9e",
            "placeholder": "​",
            "style": "IPY_MODEL_433c008995464a14a8acc38a492c5eeb",
            "value": " 147/147 [00:00&lt;00:00, 6.80kB/s]"
          }
        },
        "764a13817bd24336bd2dfaa2b786bc02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "891d1e1e877e4b709e0ea4c4bed40009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cfd10fa6f2649d2a88bb3247a6e5e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9707b8389b374ccd8428f5dfd0f16e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9acaadbf7fe843bdbc1aeff4f849fbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "554f49e76cf64637bf86b0e00e822d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433c008995464a14a8acc38a492c5eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc190f52592d4a8d81c349cb8ba144ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96e2e2b342c9495a8c9a99f820eca012",
              "IPY_MODEL_98ec4f5a89014c619bd9776363a683fe",
              "IPY_MODEL_9a3935a96fd343038d8264dfe2184a3a"
            ],
            "layout": "IPY_MODEL_2dd9ab51636e4a56a17873a96373df3d"
          }
        },
        "96e2e2b342c9495a8c9a99f820eca012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae2bea83d13140d4ab1c7363a2e7ffef",
            "placeholder": "​",
            "style": "IPY_MODEL_12d6690d72a1497dbdbbbd99334043ce",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "98ec4f5a89014c619bd9776363a683fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_079f8038eb694825be7fb27a45b5e09b",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebe60203f321467a8a26a9c9ea23d517",
            "value": 791656
          }
        },
        "9a3935a96fd343038d8264dfe2184a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2739232b5e5a4acaac7623562238c99a",
            "placeholder": "​",
            "style": "IPY_MODEL_07b51996ee394a30b02016ad03e0fe10",
            "value": " 792k/792k [00:00&lt;00:00, 5.04MB/s]"
          }
        },
        "2dd9ab51636e4a56a17873a96373df3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2bea83d13140d4ab1c7363a2e7ffef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d6690d72a1497dbdbbbd99334043ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "079f8038eb694825be7fb27a45b5e09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe60203f321467a8a26a9c9ea23d517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2739232b5e5a4acaac7623562238c99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b51996ee394a30b02016ad03e0fe10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "710ed702f054467a8df9d481c9c8af4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c48be42638d54310813fdb9a44b33bf2",
              "IPY_MODEL_a7a08499abdc49bf87b2b25315b35745",
              "IPY_MODEL_a20d1fb53a5d43759c177dd5ef6a2a23"
            ],
            "layout": "IPY_MODEL_a70def245fe149bc93bfb2fd975cd844"
          }
        },
        "c48be42638d54310813fdb9a44b33bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e200fd136148d1b910b32fe8bfc8b7",
            "placeholder": "​",
            "style": "IPY_MODEL_84ccf9586f7c4ee2860365cbc7faf3ec",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "a7a08499abdc49bf87b2b25315b35745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_933dd4f13e1f40aba6d3d905130024d3",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96bb174843bf4d6c95852cee3574ef21",
            "value": 1389353
          }
        },
        "a20d1fb53a5d43759c177dd5ef6a2a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c79b4f9e024bd99687e0f4e4dd7ffb",
            "placeholder": "​",
            "style": "IPY_MODEL_4444c1aad3ae40a3a6624d5d962fbafd",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 7.65MB/s]"
          }
        },
        "a70def245fe149bc93bfb2fd975cd844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e200fd136148d1b910b32fe8bfc8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ccf9586f7c4ee2860365cbc7faf3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "933dd4f13e1f40aba6d3d905130024d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96bb174843bf4d6c95852cee3574ef21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5c79b4f9e024bd99687e0f4e4dd7ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4444c1aad3ae40a3a6624d5d962fbafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}