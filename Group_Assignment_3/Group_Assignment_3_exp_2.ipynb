{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKv0j0+TFw/3oz3XtPkqnD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaHolmlund/M6_Group_Assignments/blob/main/Group_Assignment_3/Group_Assignment_3_exp_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task"
      ],
      "metadata": {
        "id": "FjfxQospZmZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select one of your previous projects that includes a machine learning component and use MLflow to track and manage your machine learning experiments. The following tasks should be performed:\n",
        "\n",
        "- Train a machine learning model using the data from your previous project. You can use any machine learning model that is appropriate for your data and problem.\n",
        "\n",
        "- Use MLflow to track and manage your machine learning experiments. Log the hyperparameters, metrics, and artifacts of your machine learning experiments in MLflow. Save structured and unstructured information related to your trained model in SQLite within MLflow.\n",
        "\n",
        "- Optionally, prepare an ML app based on three layers (data, business, presentation) to provide a user-friendly interface for interacting with your machine learning model. This will involve creating a data layer that handles the data processing pipeline and provides functions for loading and preprocessing the data, a business layer that implements the machine learning model and its related functions, and a presentation layer that implements the user interface and connects it to the business layer."
      ],
      "metadata": {
        "id": "anXOXiWiZoE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "5K-7veNeZplA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow -q"
      ],
      "metadata": {
        "id": "Z2Gi51xOZnBz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "pd.set_option('max_colwidth', 1000)\n",
        "pd.describe_option('max_colwidth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5dz7VATZyPy",
        "outputId": "8109bdd1-6285-4d4c-d88e-2fbcf284d79c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "display.max_colwidth : int or None\n",
            "    The maximum width in characters of a column in the repr of\n",
            "    a pandas data structure. When the column overflows, a \"...\"\n",
            "    placeholder is embedded in the output. A 'None' value means unlimited.\n",
            "    [default: 50] [currently: 1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning the data"
      ],
      "metadata": {
        "id": "CyxRrYwQZ3Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the CSV files into Pandas Dataframes and merging them together based on player ID\n",
        "baseball_master = pd.read_csv('https://raw.githubusercontent.com/NadiaHolmlund/M6_Group_Assignments/main/Group_Assignment_3/Data/Master.csv', encoding=\"ISO-8859-1\")\n",
        "baseball_batting = pd.read_csv('https://raw.githubusercontent.com/NadiaHolmlund/M6_Group_Assignments/main/Group_Assignment_3/Data/Batting.csv', encoding=\"ISO-8859-1\")\n",
        "\n",
        "baseball = baseball_master.merge(baseball_batting, on = 'playerID')"
      ],
      "metadata": {
        "id": "AKM-NB3_oF-x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the DataFrame\n",
        "baseball.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "YJKI83uKZ6L5",
        "outputId": "748d79a0-78da-4a39-c45a-0338c80005d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   lahmanID   playerID managerID       hofID  birthYear  birthMonth  birthDay  \\\n",
              "0         1  aaronha01       NaN  aaronha01h     1934.0         2.0       5.0   \n",
              "1         1  aaronha01       NaN  aaronha01h     1934.0         2.0       5.0   \n",
              "2         1  aaronha01       NaN  aaronha01h     1934.0         2.0       5.0   \n",
              "3         1  aaronha01       NaN  aaronha01h     1934.0         2.0       5.0   \n",
              "4         1  aaronha01       NaN  aaronha01h     1934.0         2.0       5.0   \n",
              "\n",
              "  birthCountry birthState birthCity  ...   SB   CS    BB    SO   IBB  HBP  \\\n",
              "0          USA         AL    Mobile  ...  2.0  2.0  28.0  39.0   NaN  3.0   \n",
              "1          USA         AL    Mobile  ...  3.0  1.0  49.0  61.0   5.0  3.0   \n",
              "2          USA         AL    Mobile  ...  2.0  4.0  37.0  54.0   6.0  2.0   \n",
              "3          USA         AL    Mobile  ...  1.0  1.0  57.0  58.0  15.0  0.0   \n",
              "4          USA         AL    Mobile  ...  4.0  1.0  59.0  49.0  16.0  1.0   \n",
              "\n",
              "    SH   SF  GIDP  G_old  \n",
              "0  6.0  4.0  13.0  122.0  \n",
              "1  7.0  4.0  20.0  153.0  \n",
              "2  5.0  7.0  21.0  153.0  \n",
              "3  0.0  3.0  13.0  151.0  \n",
              "4  0.0  3.0  21.0  153.0  \n",
              "\n",
              "[5 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b36aa8c-e8d1-4e6b-9782-d15ab371ff56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lahmanID</th>\n",
              "      <th>playerID</th>\n",
              "      <th>managerID</th>\n",
              "      <th>hofID</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>birthMonth</th>\n",
              "      <th>birthDay</th>\n",
              "      <th>birthCountry</th>\n",
              "      <th>birthState</th>\n",
              "      <th>birthCity</th>\n",
              "      <th>...</th>\n",
              "      <th>SB</th>\n",
              "      <th>CS</th>\n",
              "      <th>BB</th>\n",
              "      <th>SO</th>\n",
              "      <th>IBB</th>\n",
              "      <th>HBP</th>\n",
              "      <th>SH</th>\n",
              "      <th>SF</th>\n",
              "      <th>GIDP</th>\n",
              "      <th>G_old</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>aaronha01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aaronha01h</td>\n",
              "      <td>1934.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>USA</td>\n",
              "      <td>AL</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>122.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>aaronha01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aaronha01h</td>\n",
              "      <td>1934.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>USA</td>\n",
              "      <td>AL</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>aaronha01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aaronha01h</td>\n",
              "      <td>1934.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>USA</td>\n",
              "      <td>AL</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>aaronha01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aaronha01h</td>\n",
              "      <td>1934.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>USA</td>\n",
              "      <td>AL</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>151.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>aaronha01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aaronha01h</td>\n",
              "      <td>1934.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>USA</td>\n",
              "      <td>AL</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 56 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b36aa8c-e8d1-4e6b-9782-d15ab371ff56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b36aa8c-e8d1-4e6b-9782-d15ab371ff56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b36aa8c-e8d1-4e6b-9782-d15ab371ff56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the DataFrame\n",
        "baseball.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLyxle25Z7Tf",
        "outputId": "c4312f62-b9a2-42a9-9c80-d85dc0ca85f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 96609 entries, 0 to 96608\n",
            "Data columns (total 56 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   lahmanID      96609 non-null  int64  \n",
            " 1   playerID      96609 non-null  object \n",
            " 2   managerID     6546 non-null   object \n",
            " 3   hofID         17793 non-null  object \n",
            " 4   birthYear     96294 non-null  float64\n",
            " 5   birthMonth    95759 non-null  float64\n",
            " 6   birthDay      95397 non-null  float64\n",
            " 7   birthCountry  96174 non-null  object \n",
            " 8   birthState    86389 non-null  object \n",
            " 9   birthCity     95844 non-null  object \n",
            " 10  deathYear     39107 non-null  float64\n",
            " 11  deathMonth    39096 non-null  float64\n",
            " 12  deathDay      39095 non-null  float64\n",
            " 13  deathCountry  38839 non-null  object \n",
            " 14  deathState    38415 non-null  object \n",
            " 15  deathCity     38804 non-null  object \n",
            " 16  nameFirst     96557 non-null  object \n",
            " 17  nameLast      96609 non-null  object \n",
            " 18  nameNote      2459 non-null   object \n",
            " 19  nameGiven     92778 non-null  object \n",
            " 20  nameNick      19995 non-null  object \n",
            " 21  weight        95317 non-null  float64\n",
            " 22  height        95353 non-null  float64\n",
            " 23  bats          94364 non-null  object \n",
            " 24  throws        94906 non-null  object \n",
            " 25  debut         96603 non-null  object \n",
            " 26  finalGame     84966 non-null  object \n",
            " 27  college       24348 non-null  object \n",
            " 28  lahman40ID    88232 non-null  object \n",
            " 29  lahman45ID    88232 non-null  object \n",
            " 30  retroID       96214 non-null  object \n",
            " 31  holtzID       88260 non-null  object \n",
            " 32  bbrefID       96394 non-null  object \n",
            " 33  yearID        96609 non-null  int64  \n",
            " 34  stint         96609 non-null  int64  \n",
            " 35  teamID        96609 non-null  object \n",
            " 36  lgID          95872 non-null  object \n",
            " 37  G             96609 non-null  int64  \n",
            " 38  G_batting     95203 non-null  float64\n",
            " 39  AB            90196 non-null  float64\n",
            " 40  R             90196 non-null  float64\n",
            " 41  H             90196 non-null  float64\n",
            " 42  2B            90196 non-null  float64\n",
            " 43  3B            90196 non-null  float64\n",
            " 44  HR            90196 non-null  float64\n",
            " 45  RBI           89772 non-null  float64\n",
            " 46  SB            88896 non-null  float64\n",
            " 47  CS            66742 non-null  float64\n",
            " 48  BB            90196 non-null  float64\n",
            " 49  SO            82358 non-null  float64\n",
            " 50  IBB           53632 non-null  float64\n",
            " 51  HBP           87376 non-null  float64\n",
            " 52  SH            83858 non-null  float64\n",
            " 53  SF            54163 non-null  float64\n",
            " 54  GIDP          64088 non-null  float64\n",
            " 55  G_old         92707 non-null  float64\n",
            "dtypes: float64(26), int64(4), object(26)\n",
            "memory usage: 42.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting columns to be included in the database\n",
        "baseball_db = baseball[['weight', 'height', 'G', 'AB', 'HR']]"
      ],
      "metadata": {
        "id": "CL79WZNjZ87h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping NaN values\n",
        "baseball_db = baseball_db.dropna()"
      ],
      "metadata": {
        "id": "dvvbTJ16Z-KJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the dataFrame\n",
        "baseball_db.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgdsK7HvZ_Yi",
        "outputId": "8a4ea4cd-c8d3-404a-9984-71b83228c1eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 88718 entries, 0 to 96604\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   weight  88718 non-null  float64\n",
            " 1   height  88718 non-null  float64\n",
            " 2   G       88718 non-null  int64  \n",
            " 3   AB      88718 non-null  float64\n",
            " 4   HR      88718 non-null  float64\n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 4.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the Dataframe as CSV\n",
        "baseball_db.to_csv('baseball_db.csv', index=False)"
      ],
      "metadata": {
        "id": "Sjsq7wNGlYKp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Data Layer"
      ],
      "metadata": {
        "id": "DjGIGipbaAof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a SQLite database for the baseball dataset\n",
        "\n",
        "In terminal: create a file named database.py and paste the code"
      ],
      "metadata": {
        "id": "gKxc8Sk7aB26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#database.py\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "def init_db():\n",
        "  # Load the Iris dataset into a Pandas DataFrame\n",
        "  url = \"https://github.com/NadiaHolmlund/M6_Group_Assignments/blob/main/Group_Assignment_3/Data/baseball_db.csv\"\n",
        "  df = pd.read_csv(url, header=None, names=[\"weight\", \"height\", \"G\", \"AB\", \"HR\"])\n",
        "\n",
        "  # Connect to the SQLite database\n",
        "  conn = sqlite3.connect(\"baseball.db\")\n",
        "\n",
        "  # Save the Pandas DataFrame to the SQLite database\n",
        "  df.to_sql(\"baseball\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "  # Close the connection to the SQLite database\n",
        "  conn.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_db()"
      ],
      "metadata": {
        "id": "tsIYEMZKmGhI",
        "outputId": "5574be7a-d234-466f-beef-beaf633ccb9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-45f105841024>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0minit_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-45f105841024>\u001b[0m in \u001b[0;36minit_db\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Load the Iris dataset into a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://github.com/NadiaHolmlund/M6_Group_Assignments/blob/main/Group_Assignment_3/Data/baseball_db.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"height\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"G\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# Connect to the SQLite database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 27, saw 367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Business Layer"
      ],
      "metadata": {
        "id": "LzHgbuMkaE1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Scikit-Learn library to train a machine learning model for HR prediction.\n",
        "\n",
        "The code also sets up an experiment named \"HR_Prediction\" and logs the model's parameters, performance metrics, and the trained model itself as an artifact in MLflow."
      ],
      "metadata": {
        "id": "euyFIs9oaHO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model ***with*** MLflow"
      ],
      "metadata": {
        "id": "WE98DVHfdmkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(\"baseball.db\")\n",
        "\n",
        "# Read data from a table using Pandas\n",
        "data_df = pd.read_sql(\"SELECT * FROM baseball\", conn)\n",
        "\n",
        "def train_model():\n",
        "    mlflow.set_experiment(\"HR_Prediction\")\n",
        "    X = data_df.drop('HR', axis=1)\n",
        "    y = data_df['HR']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    regr = RandomForestRegressor()\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        regr.fit(X_train, y_train)\n",
        "\n",
        "        # Log model parameters\n",
        "        mlflow.log_param(\"n_estimators\", regr.n_estimators)\n",
        "        mlflow.log_param(\"criterion\", regr.criterion)\n",
        "\n",
        "        # Log model performance metrics\n",
        "        train_score = regr.score(X_train, y_train)\n",
        "        test_score = regr.score(X_test, y_test)\n",
        "        mlflow.log_metric(\"train_score\", train_score)\n",
        "        mlflow.log_metric(\"test_score\", test_score)\n",
        "\n",
        "        # Save the model as an artifact\n",
        "        mlflow.sklearn.log_model(regr, \"model\")\n",
        "\n",
        "    return regr, test_score\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    regr, accuracy = train_model()\n",
        "    print(f\"Model trained with accuracy: {accuracy}\")\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.sklearn.log_model(regr, \"model\")\n",
        "    mlflow.sklearn.log_model(regr, \"model\", registered_model_name=\"HR_model\")\n",
        "    mlflow.sklearn.save_model(regr, \"HR_model\")\n",
        "\n",
        "    # Launch MLflow UI\n",
        "    import os\n",
        "    os.system(\"mlflow ui\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKp-MWM8aK6H",
        "outputId": "613bfcfd-9ded-40a4-84f6-3d849c32dea5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/04/16 18:54:58 INFO mlflow.tracking.fluent: Experiment with name 'HR_Prediction' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained with accuracy: 0.6505444769367961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Successfully registered model 'HR_model'.\n",
            "2023/04/16 18:55:42 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: HR_model, version 1\n",
            "Created version '1' of model 'HR_model'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view the MLflow UI, run the command \"mlflow ui\" in terminal"
      ],
      "metadata": {
        "id": "Tw5xDQoOcDPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model ***without*** MLflow"
      ],
      "metadata": {
        "id": "9aq70pKxdphq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terminal: create a file named model.py and paste the code"
      ],
      "metadata": {
        "id": "OGKaBlsoefNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pickle\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(\"baseball.db\")\n",
        "\n",
        "# Read data from a table using Pandas\n",
        "data_df = pd.read_sql(\"SELECT * FROM baseball\", conn)\n",
        "\n",
        "def train_model():\n",
        "    X = data_df.drop('HR', axis=1)\n",
        "    y = data_df['HR']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    regr = RandomForestRegressor()\n",
        "    regr.fit(X_train, y_train)\n",
        "\n",
        "    with open(\"model.pkl\", \"wb\") as f:\n",
        "        pickle.dump(regr, f)\n",
        "\n",
        "    return regr.score(X_test, y_test)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    accuracy = train_model()\n",
        "    print(f\"Model trained with accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "NqNDly56dbbb",
        "outputId": "8631b225-19aa-4458-b080-7d31ef7df955"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-db1dffd8ad32>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model trained with accuracy: {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-db1dffd8ad32>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     def __array_wrap__(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'weight'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Presentation Layer"
      ],
      "metadata": {
        "id": "bEcAiDxTaM35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using HTML and CSS to create and style the prediction app\n",
        "\n",
        "In terminal: create a folder named templates and create a file named index.html and paste the code"
      ],
      "metadata": {
        "id": "yCF5AMCpaN8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up HTML for the app\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>HR Prediction</title>\n",
        "    <link rel=\"stylesheet\" href=\"static/style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <h1>HR Prediction</h1>\n",
        "    <form action=\"/predict\" method=\"post\">\n",
        "        <label for=\"weight\">Weight:</label>\n",
        "        <input type=\"number\" step=\"10\" id=\"weight\" name=\"weight\" required><br><br>\n",
        "        <label for=\"height\">Height:</label>\n",
        "        <input type=\"number\" step=\"10\" id=\"heithg\" name=\"height\" required><br><br>\n",
        "        <label for=\"G\">Games Played:</label>\n",
        "        <input type=\"number\" step=\"1\" id=\"G\" name=\"G\" required><br><br>\n",
        "        <label for=\"AB\">At-bat:</label>\n",
        "        <input type=\"number\" step=\"1\" id=\"AB\" name=\"AB\" required><br><br>\n",
        "        <input type=\"submit\" value=\"Predict\">\n",
        "    </form>\n",
        "    {% if prediction %}\n",
        "    <h2>Prediction: {{ prediction }}</h2>\n",
        "    {% endif %}\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "K5uWNQeWaPoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terminal: create a folder named static and create a file named style.css and paste the code"
      ],
      "metadata": {
        "id": "CSP2Sigyc9nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up CSS for the app\n",
        "body {\n",
        "    font-family: Arial, sans-serif;\n",
        "    max-width: 600px;\n",
        "    margin: 0 auto;\n",
        "    padding: 20px;\n",
        "}\n",
        "\n",
        "input[type=number], input[type=submit] {\n",
        "    width: 100%;\n",
        "    padding: 5px;\n",
        "    margin: 5px 0;\n",
        "    box-sizing: border-box;\n",
        "}\n",
        "\n",
        "input[type=submit] {\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "    cursor: pointer;\n",
        "}"
      ],
      "metadata": {
        "id": "LychGU6_aRaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting the Data Layer, Business Layer and Presentation Layer using Flask"
      ],
      "metadata": {
        "id": "LVH3YFMUaS_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terminal: Create a file named app.py and paste the code"
      ],
      "metadata": {
        "id": "rqiVbHDEdFEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request, jsonify\n",
        "import pickle\n",
        "import sqlite3\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "with open(\"model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def index():\n",
        "    return render_template(\"index.html\", prediction=None)\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def classify():\n",
        "    sepal_length = float(request.form[\"weight\"])\n",
        "    sepal_width = float(request.form[\"height\"])\n",
        "    petal_length = float(request.form[\"G\"])\n",
        "    petal_width = float(request.form[\"AB\"])\n",
        "\n",
        "    data = [[weight, height, G, AB]]\n",
        "    prediction = model.predict(data)[0]\n",
        "\n",
        "    # Save the data to the database\n",
        "    connection = sqlite3.connect(\"baseball.db\")\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(\"INSERT INTO baseball (weight, height, G, AB, HR) VALUES (?, ?, ?, ?, ?)\",\n",
        "                   (weight, height, G, AB, prediction))\n",
        "    connection.commit()\n",
        "    connection.close()\n",
        "\n",
        "    return jsonify({\"prediction\": prediction})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, port=5002)"
      ],
      "metadata": {
        "id": "7vGQ2aXkaVBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run app.py and navigate to http://127.0.0.1:5000/ to see the HR Prediction app. The data is also be saved to the SQLite database."
      ],
      "metadata": {
        "id": "yPsABsILaWiR"
      }
    }
  ]
}